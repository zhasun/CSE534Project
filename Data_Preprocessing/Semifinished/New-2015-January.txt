###############################################################
yahoo search (bing) outage
###############################################################
  -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA1
 Does anyone have any insight into yahoo' search (bing) going dark?
 Any pointers will be great
 regards,
 /virendra
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: 0xC046119E.asc
 Type: application/pgp-keys
 Size: 3096 bytes
 Desc: not available
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150102/00fb4d87/attachment.bin>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA1
 On 01/02/2015 12:58 PM, virendra rode via Outages wrote:
 - ----------------
 slow but coming back to life
 regards,
 /virendra
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: 0xC046119E.asc
 Type: application/pgp-keys
 Size: 3096 bytes
 Desc: not available
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150102/37f969c5/attachment.bin>
###############################################################
END
###############################################################

###############################################################
GTT Peering issues
###############################################################
 Seeing awful peering issues with GTT today.  Specifically between Level3 in LA and their own network between Washington and Phoenix.  
 Seeing similar issues between a few US, Asia and EU sites. What I'm
 seeing is what appears to be a congested peering connection between GTT
 and NTT in Seattle as that is what all traceroutes have in common.
 Our graphs indicate this started Jan 1st, around ~ 15:00 utc.
 Example traceroute from Seattle (ntt) to Vancouver (gtt):
 HOST: rtr1-re0.sea                Loss%   Snt   Last   Avg  Best  Wrst StDev
   1. xe-0-0-0-34.r04.sttlwa01.us.  0.0%    60    4.1   8.3   0.8  23.9   6.5
   2. ae3.sea22.ip4.gtt.net        20.0%    60   44.6  41.9  33.6  60.3   6.0
   3. xe-1-2-0.van10.ip4.gtt.net   18.3%    60   48.9  51.6  38.0 129.1  17.3
   4. opendns-gw.ip4.gtt.net       20.0%    60   46.6  46.6  38.3  65.1   6.9
   5. rtr1.yvr.opendns.com         28.3%    60   44.8  47.5  38.6  74.2   8.9
 Cheers,
  Andree
 .-- My secret spy satellite informs me that at 2015-01-05 3:04 PM  Hugh
 Smallwood via Outages wrote:
 If you'd like to provide me details off-list, I'd be happy to take a look.
 On 1/5/15 6:04 PM, Hugh Smallwood via Outages wrote:
  <54AC3B97.4050706@toonk.nl>
 This issue was on the remote side of one of our peering sessions, and 
 has since been resolved.  Have a look again and feel free to contact me 
 off-list if you're still seeing any issues there. Thanks!
 On 1/6/15 2:46 PM, Andree Toonk via Outages wrote:
###############################################################
END
###############################################################

###############################################################
Watchguard.com - Security Vendor
###############################################################
 The website watchguard.com has been up and down the last two days that I've
 noticed.
 I just called their partner number and it sounds like they are saying a bad
 switch of some sort and are working to get that resolved.  I didn't speak
 with anyone technical on the matter.
 Not malicious or a DDoS, it sounds like, which is generally why sites go
 down nowdays ;).  No ETA, just wanted to report what I found.
 Thanks,
 Anthony Hook
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150106/8aac44e5/attachment.html>
###############################################################
END
###############################################################

###############################################################
bloomberg.com outage?
###############################################################
 For the past half hour, been getting: http://www.bloomberg.com/
  503 Service Unavailable
  No server is available to handle this request.
 This is from an AT&T connection in Charleston, SC.
 Also...  https://www.bloomberg.com/ gives a list of Bloomberg websites
 -- unformatted.
 Any clue what's up??
 JK
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150106/3e419f51/attachment.html>
 Well, this seems to point to the problem:
 Service Unavailable - DNS failure
 The server is temporarily unable to service your request. Please try again
 later.
 Reference #11.813919b8.1420581256.7c3fd98
 So... (one of the following)
 * Their single internal DNS server died
 * They lost connectivity to their DNS server(s)
 * Someone introduced bad data into a zone file
 And... (one of the following)
 * It's not being monitored
 * Their monitoring doesn't page
 * The person(s) being paged don't have service, don't care, or are napping
 On Tue, Jan 6, 2015 at 1:36 PM, J Kibler via Outages <outages at outages.org>
 wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150106/3dcb1fc1/attachment.html>
 I get
 Service Unavailable - DNS failure
 The server is temporarily unable to service your request. Please try again later.
 Reference #11.5835d417.1420581459.53b6d4f
 Looks like they are using Akamai.
 On Jan 6, 2015, at 3:36 PM, J Kibler via Outages <outages at outages.org<mailto:outages at outages.org>> wrote:
 For the past half hour, been getting:
 http://www.bloomberg.com/
 503 Service Unavailable
 No server is available to handle this request.
 This is from an AT&T connection in Charleston, SC.
 Also...  https://www.bloomberg.com/ gives a list of Bloomberg websites -- unformatted.
 Any clue what's up??
 JK
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 ---
 Keith Stokes
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150106/121c4b02/attachment.html>
 On 01/06/2015 02:36 PM, J Kibler via Outages wrote:
 Interesting - saw something similar just a bit ago with SpamCop.net - no 
 formatting and many pages broken with a 500 server error. Has since cleared 
 up and seems to be working.
 Chris
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150106/4770d5a9/attachment-0001.html>
 I see the same thing, too, for the https site, while the http site shows this:
 http://mobile.bloomberg.com works. =)
 Frank
 From: Outages [mailto:outages-bounces at outages.org] On Behalf Of J Kibler via Outages
 Sent: Tuesday, January 06, 2015 3:37 PM
 For the past half hour, been getting:
             http://www.bloomberg.com/
             503 Service Unavailable
             No server is available to handle this request.
 This is from an AT&T connection in Charleston, SC.
 Also...  https://www.bloomberg.com/ gives a list of Bloomberg websites -- unformatted.
 Any clue what's up??
 JK
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150106/a4ff6946/attachment-0001.html>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image001.png
 Type: image/png
 Size: 21664 bytes
 Desc: not available
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150106/a4ff6946/attachment-0001.png>
###############################################################
END
###############################################################

###############################################################
AAG SH1 cable segment cut in ASEAN.
###############################################################
 <http://www.thanhniennews.com/tech/transpacific-cable-snaps-slowing-down-internet-in-vietnam-37184.html>
 -----------------------------------
 Roland Dobbins <rdobbins at arbor.net>
###############################################################
END
###############################################################

###############################################################
Anyone seeing issues with Zayo this morning?
###############################################################
 Anyone else having issues?
 Specifically Omaha, Kansas City and Dallas areas?
 We have multiple 10Gs down through them currently.
 We had issues with Zayo not advertising our routes correctly over the part few weeks, but it was just resolved.  The issue caused blockage to MaxCDN from our campus.
 Thanks,
 ep
 On January 10, 2015 9:30:37 AM EST, Shamen Snyder via Outages <outages at outages.org> wrote:
 >Anyone else having issues?
 >Specifically Omaha, Kansas City and Dallas areas?
 >We have multiple 10Gs down through them currently.
 >_______________________________________________
 >Outages mailing list
 >Outages at outages.org
 >https://puck.nether.net/mailman/listinfo/outages
 -- 
 Brian Epstein <bepstein at ias.edu>                     +1 609-734-8179
 Manager, Network and Security           Institute for Advanced Study
 Key fingerprint = 128A 38F4 4CFA 5EDB 99CE  4734 6117 4C25 0371 C12A
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150110/c9653bf2/attachment.html>
###############################################################
END
###############################################################

###############################################################
Level 3 DNS 4.2.2.1/4.2.2.2 Atlanta Issues
###############################################################
 Level 3 appears to be having issues with 4.2.2.1 and 4.2.2.2 (The Atlanta 
 Anycasted ones). Appears to have Packet Loss (Seen in Below MTR's). As well 
 as having timeoutes resolving DNS against them.
  From me (AS36295)
   Host                                                      Loss%   Snt   
 Last   Avg  Best  Wrst StDev
  1. eth-vl0504-far1.coco-vr.flhsi.com                       0.0%   468    
 0.3   0.4   0.2   3.7   0.3
  2. eth-ge0007-car1.coco-vr.flhsi.com                       0.0%   468    
 0.5   0.4   0.2   2.0   0.2
  3. eth-ge0003-bar1.coco-vr.flhsi.com                       0.0%   468    
 0.4   0.5   0.3   2.5   0.3
  4. 66-194-200-17.static.twtelecom.net                      0.0%   467    
 4.3   4.5   4.1  40.2   2.4
  5. mia2-pr1-xe-1-3-0-0.us.twtelecom.net                    0.0%   467   
 11.1  14.9  10.9 103.2  12.5
  6. 4.68.71.97                                              3.4%   467   
 12.4  13.1  12.1  62.4   4.8
  7. ae-2-3015.ear1.Atlanta2.Level3.net                     97.4%   467  
 22153 22228 21002 23399 797.3
  8. b.resolvers.Level3.net                                 53.3%   467   
 38.5  36.4  31.0  42.4   2.0
  From another NLNOG Ring Participant (AS31939)
  Host                                                      Loss%   Snt   
 Last   Avg  Best  Wrst StDev
  1. c-65-50-1-69.ips.direcpath.com                          0.0%   179    
 0.5   0.7   0.4  16.9   1.3
  2. 172.24.0.13                                             0.0%   179    
 0.5   0.7   0.4   3.9   0.6
  3. 172.24.0.242                                            0.0%   179   
 15.3   9.1   0.5 188.7  28.7
  4. te0-3-0-5.ccr21.atl04.atlas.cogentco.com                0.0%   179    
 2.5   1.6   0.9   5.4   0.7
  5. level3.atl04.atlas.cogentco.com                         2.2%   179    
 0.6   1.7   0.5  48.0   5.3
  6. ae-2-3015.ear1.Atlanta2.Level3.net                     98.3%   178  
 22958 22009 20605 22958 1240.
  7. a.resolvers.level3.net                                 65.7%   178   
 20.8  18.4  15.2  20.9   1.2
  Nick Olsen
 Network Operations  (855) FLSPEED  x106
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150112/4114ce0e/attachment.html>
  <16347980.1034.1421164351806.JavaMail.root@benjamin.baylink.com>
 Seeing the same from Atlanta as well as others, this is a 12 hour view:
 http://i.imgur.com/wYbxUNy.png
 On Tue, Jan 13, 2015 at 10:52 AM, Jay Ashworth via Outages <
 outages at outages.org> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150113/8d410369/attachment.html>
  <16347980.1034.1421164351806.JavaMail.root@benjamin.baylink.com>
  <CAMMeA5XecM4sNFsezVTgJs2R09ivobJn3mfVUFG8hMqDacTawA@mail.gmail.com>
 If you're a L3 customer then I'd suggest reporting it to them via standard
 channels.
 If you're not a L3 customer, then why are you attempting to use their
 revolvers?  If you want a public resolver, use Google.  4.2.2.x are NOT
 intended for public use, and never have been.
   Scott
 On Tue, Jan 13, 2015 at 10:28 PM, Justin via Outages <outages at outages.org>
 wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150114/ba0f4f2e/attachment-0001.html>
  <16347980.1034.1421164351806.JavaMail.root@benjamin.baylink.com>
  <CAMMeA5XecM4sNFsezVTgJs2R09ivobJn3mfVUFG8hMqDacTawA@mail.gmail.com>
  <CACnPsNVdVXLQKgU=gOs7wT9x0ZYnj=28OSrx6NtKjGgOAzxQ2g@mail.gmail.com>
 On 1/14/15 6:27, Scott Howard via Outages wrote:
 +1
 And they have never, even for L3 customers, been advocated for use as an
 automated ping target to test if "the Internet is working" or to trigger
 a backup or failover scenario.
 --
 Jay Hennigan - CCIE #7880 - Network Engineering - jay at impulse.net
 Impulse Internet Service  -  http://www.impulse.net/
 Your local telephone and internet company - 805 884-6323 - WB6RDV
 Oh.  This wasn't my client's uplink.
 I saw this yesterday after 1600EST, but didn't have time then to run it down.  And
 that was over a 6 hop path from VDSL in Clearwater FL.
 This minute, traces to 4.2.2.1 aren't dropping any packets.  4.2.2.2 is, about 35%.
 Those appear to be the ATL machines for me as well:
 HOST: stanley                     Loss%   Snt   Last   Avg  Best  Wrst StDev
   1.|-- 192.168.141.1              0.0%    10    1.0   1.0   0.9   1.1   0.0
   2.|-- L100.TAMPFL-DSL-02.verizo  0.0%    10   27.4  27.8  27.1  29.1   0.6
   3.|-- P0-1-0-0.TAMPFL-LCR-21.ve  0.0%    10   32.0  31.0  28.1  32.7   1.8
   4.|-- 130.81.199.26              0.0%    10   28.7  35.5  28.7  86.4  17.9
   5.|-- 0.xe-5-0-0.BR3.ATL4.ALTER  0.0%    10   44.8  44.7  43.7  45.5   0.5
   6.|-- ???                       100.0    10    0.0   0.0   0.0   0.0   0.0
   7.|-- b.resolvers.Level3.net    70.0%    10   62.6  60.8  58.9  62.6   1.9
 ----- Original Message -----
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
 Still seeing it here as well. But also to both 4.2.2.1 and 4.2.2.2
   Host                                                      Loss%   Snt   
 Last   Avg  Best  Wrst StDev
  1. eth-vl0504-far1.coco-vr.flhsi.com                       0.0%   432    
 0.3   0.2   0.1   3.0   0.2
  2. eth-ge0007-car1.coco-vr.flhsi.com                       0.0%   432    
 0.3   0.3   0.2   9.6   0.6
  3. eth-ge0003-bar1.coco-vr.flhsi.com                       0.0%   431    
 0.4   0.3   0.2   3.9   0.2
  4. 66-194-200-17.static.twtelecom.net                      0.0%   431    
 3.2   3.3   2.9  54.8   2.7
  5. mia2-pr1-xe-1-3-0-0.us.twtelecom.net                    0.2%   431    
 9.8  13.5   9.7 103.1  12.2
  6. 4.68.71.97                                              0.5%   431   
 11.1  11.8  10.9  64.6   4.6
  7. ae-2-3015.ear1.Atlanta2.Level3.net                     97.4%   431  
 22139 22248 21053 23307 652.5
  8. a.resolvers.level3.net                                 38.6%   431   
 37.5  42.3  31.1  71.3   7.4
  Nick Olsen
 Network Operations  (855) FLSPEED  x106
 ----------------------------------------
  From: "Jay Ashworth via Outages" <outages at outages.org>
 Sent: Tuesday, January 13, 2015 12:51 PM
 Subject: Re: [outages] Level 3 DNS 4.2.2.1/4.2.2.2 Atlanta Issues   
 Oh. This wasn't my client's uplink.
 I saw this yesterday after 1600EST, but didn't have time then to run it 
 down. And
 that was over a 6 hop path from VDSL in Clearwater FL.
 This minute, traces to 4.2.2.1 aren't dropping any packets. 4.2.2.2 is, 
 about 35%.
 Those appear to be the ATL machines for me as well:
 HOST: stanley Loss% Snt Last Avg Best Wrst StDev
 1.|-- 192.168.141.1 0.0% 10 1.0 1.0 0.9 1.1 0.0
 2.|-- L100.TAMPFL-DSL-02.verizo 0.0% 10 27.4 27.8 27.1 29.1 0.6
 3.|-- P0-1-0-0.TAMPFL-LCR-21.ve 0.0% 10 32.0 31.0 28.1 32.7 1.8
 4.|-- 130.81.199.26 0.0% 10 28.7 35.5 28.7 86.4 17.9
 5.|-- 0.xe-5-0-0.BR3.ATL4.ALTER 0.0% 10 44.8 44.7 43.7 45.5 0.5
 6.|-- ??? 100.0 10 0.0 0.0 0.0 0.0 0.0
 7.|-- b.resolvers.Level3.net 70.0% 10 62.6 60.8 58.9 62.6 1.9
 ----- Original Message -----
 --
 Jay R. Ashworth Baylink jra at baylink.com
 Designer The Things I Think RFC 2100
 Ashworth & Associates http://www.bcp38.info 2000 Land Rover DII
 St Petersburg FL USA BCP38: Ask For It By Name! +1 727 647 1274
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150113/98808c99/attachment.html>
###############################################################
END
###############################################################

###############################################################
EDGE: Anyone seeing 100% CPU on Fortigate edge routers?
###############################################################
 Got a client whose FGT60D -- two of them; they have a hot spare -- is
 jamming to 100% continuous CPU full time, enough to impinge capacity sharply
 on their 90mb/s Road Runner line to Five9.
 Since their primary and hotspare boxes behave identically, end neither
 ever did before, I infer a pattern-file pooch-screwing at Fortigate, and 
 am looking for corroborating reports.
 Anybody?
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
 On 01/15/2015 09:44 AM, Jay Ashworth via Outages wrote:
 Have them in shop but haven't tested them yet.
 If UTM is on, check the options enabled. Turn off those options they 
 don't need. I've worked on blades that when using all of App Control, 
 spiked the CPU. We ended up disabling some of the options and that 
 brought down the CPU.
 --John
 On 15 Jan 2015, at 23:44, Jay Ashworth via Outages wrote:
 Is it possible they're being DDoSed?  Stateful devices don't generally 
 react well to DDoS attacks:
 <https://app.box.com/s/a3oqqlgwe15j8svojvzl>
 -----------------------------------
 Roland Dobbins <rdobbins at arbor.net>
  <9C109E66-5A9F-4AC4-9DA7-C688D4A65E63@arbor.net>
 On Thu, Jan 15, 2015 at 11:43 AM, Roland Dobbins via Outages
 <outages at outages.org> wrote:
 Did anyone else read that in a Sean Connery voice?
 https://www.youtube.com/watch?v=kt0sH1C_XBc
 -A
 FOLO: About 5 or 6 minutes after I posted this, the problem -- after being
 rock solid since about 0930EST this morning, "magically" went away.
 :-)
 Still interested in any reports from earlier.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
 Any chance they were under attack (DDoS)?
 On Jan 15, 2015, at 12:07 PM, Jay Ashworth via Outages <outages at outages.org> wrote:
 FOLO: About 5 or 6 minutes after I posted this, the problem -- after being
 rock solid since about 0930EST this morning, "magically" went away.
 :-)
 Still interested in any reports from earlier.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 We have a few dozen out there in the field and haven't seen anything today.
 If you see the issue again, get on the unit and run 'diag sys top' to 
 find the process that is burning CPU.  We have in the past seen ssl, imd 
 (instant messaging intercept daemon), cache etc cause issues.  That will 
 at least point you in the right direction to what is causing issues.
 You can then 'diag system kill <signal> <pid>' to restart it.  Google 
 the process name before doing that to make sure it's not something critical.
 On 01/15/2015 11:07 AM, Jay Ashworth via Outages wrote:
  <54B8518D.2020800@mbrez.com>
 Can we please move this thread to outages-discuss
 Thank you
 regards,
 /virendra
 ----- Original Message -----
 That had been my first thought, but Road Runner support said they didn't
 see any appreciable incoming traffic on the link; they were my first
 call.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
 ----- Original Message -----
 Thanks, Jeremy; it's not the answer I hoped for, but it's helpful.  :-)
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
 ----- Original Message -----
 If they did it was a *very* targeted attack, because Road Runner's 
 support guy said they didn't see any appreciable amount of inbound traffic
 at that time.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
 On 16 Jan 2015, at 3:38, Jay Ashworth wrote:
 We've seen hardware load-balancers rated at 10gb/sec taken down with 
 only 60kpps of HOIC for 60s (and require 45m to reboot), so 
 high-throughput/-banwidth isn't really necessary; stateful devices make 
 it a lot easier to DDoS a given target with far less traffic than would 
 be otherwise required.
 Just a thought - it might be worth having a gander at whatever telemetry 
 is available.
 -----------------------------------
 Roland Dobbins <rdobbins at arbor.net>
  <6744A46F-1991-490D-8771-47087C9CB425@arbor.net>
 Roland Dobbins via Outages wrote on 1/15/2015 2:42 PM:
 Similarly, stateless devices can often be overwhelmed when faced with 
 unexpected traffic types. For instance, a 7600 Sup720 can become 
 unresponsive due to a few Mbps of IP traffic with IP options hitting an 
 ACL that punts the traffic to the CPU.
 --Blake
  <6744A46F-1991-490D-8771-47087C9CB425@arbor.net> <54B83C7A.3030100@ispn.net>
 On 16 Jan 2015, at 5:17, Blake Hudson via Outages wrote:
 Yes, obsolete hardware generally has less TCAM resources than more 
 modern hardware, and fewer self-protection mechanisms.  There are ways 
 to choke input queues, cause traffic to be punted, etc. even on more 
 modern hardware (although more modern hardware has various 
 self-protection mechanisms which can be utilized to ameliorate the 
 effects of such traffic).  And even on older hardware, there are some 
 tricks one can do to limit this particular set of attack surfaces.
 But stateless filtering in front of servers isn't *conceptually* flawed; 
 stateful filtering in front of servers *is* conceptually flawed.
 Any further discussion of this topic in the context of the outages 
 community should probably take place on outages-discuss.
 -----------------------------------
 Roland Dobbins <rdobbins at arbor.net>
 ----- Original Message -----
 I had; the first time it was ipsmonitor or ipsengine (I forget which);
 the second and subsequent times, it was scanunitd.
 Both times, it settled down *just* before support got me off hold; it was
 slightly maddening.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates       http://www.bcp38.info          2000 Land Rover DII
 St Petersburg FL USA      BCP38: Ask For It By Name!           +1 727 647 1274
###############################################################
END
###############################################################

###############################################################
Level 3 call cuality issues
###############################################################
 Anybody else experiencing call quality issues with Level 3 SIP trunks?
 Termination and Orig?
 Thanks,
 -- 
 Mauricio Lizano
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150116/95b86721/attachment.html>
 We are seeing a ton of packet loss to the data center where our VoIP servers 
 are. This is only when traversing the Cogent -> L3 networks. I just rerouted 
 all to use only our direct L3 connection and all is fine.
 Don't know if this applies at all to your situation or not - I don't have 
 SIP trunks with L3 directly to test. The Fortrust data center has opened a 
 ticket with L3. The L3 ticket number, if it helps, is 8793514.
 Chris
 On 01/16/2015 08:54 AM, Mauricio Lizano via Outages wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150116/09a42202/attachment.html>
 We have seen packet loss on level3 all morning. 
  <54B939A4.5090308@axint.net>
 Thanks for all the replies. I saw the packet loss too. Which ended up being
 the cause. I too see it cleared about 10-15 minutes ago. Have tickets open
 with them. No Master ticket in their portal.
 Mauricio
 On Fri, Jan 16, 2015 at 10:17 AM, Chris Stone via Outages <
 outages at outages.org> wrote:
 -- 
 Mauricio Lizano
 8821-6575
 http://cr.linkedin.com/pub/mauricio-lizano/14/162/5b5
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150116/840b4136/attachment.html>
  <54B939A4.5090308@axint.net>
  <CAOc2wFZM35PcZHkpAaF2_PdGtjC3nmyB7NVZWGJ+GAf3S8Kpwg@mail.gmail.com>
 I'll confirm, at least for packets crossing Level3 in Dallas.  We were seeing issues starting about 7:30 AM CST this morning, but it looks good now.
 --Chris
  <54B939A4.5090308@axint.net>
  <CAOc2wFZM35PcZHkpAaF2_PdGtjC3nmyB7NVZWGJ+GAf3S8Kpwg@mail.gmail.com>
  <A58026A5-1806-44DD-A69D-D1649BF2474C@gizmopartners.com>
 We aren't on level3 but we've seen packet loss coming from Level3 to XO in DFW. 
 Joseph
 -----Original Message-----
 From: Outages [mailto:outages-bounces at outages.org] On Behalf Of Chris Boyd via Outages
 Sent: Friday, January 16, 2015 10:54 AM
 I'll confirm, at least for packets crossing Level3 in Dallas.  We were seeing issues starting about 7:30 AM CST this morning, but it looks good now.
 --Chris
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
###############################################################
END
###############################################################

###############################################################
dns cache flush request
###############################################################
 can you please flush cache for windowsmedia.com
 mehmet
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150116/ee915e22/attachment.html>
 Flushed.
 *Alex Forster*
 Network Engineer, Linode
 On 1/16/15 12:37 PM, Mehmet Akcin via Outages wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150116/e0a419c0/attachment.html>
 On Fri, Jan 16, 2015 at 09:37:37AM -0800, Mehmet Akcin via Outages wrote:
 Why?  What should the correct response be?
###############################################################
END
###############################################################

###############################################################
Qwest/Centurylink toll free
###############################################################
 Anyone seeing an issue with Centurylink (legacy Qwest) toll free
 originations? Around 1:20AM EST we see very poor quality / one-way audio.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150123/5c997d2a/attachment.html>
 Issue cleared 10:18AM EST. We're told an issue was identified with an SBC.
 No word yet on what exactly it was but the timing (started just after
 midnight) smells like maintenance.
 On Fri, Jan 23, 2015 at 8:23 AM, Pete E <peeip989 at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150123/3617fc9c/attachment.html>
###############################################################
END
###############################################################

###############################################################
AWS us-west-2 network issue?
###############################################################
 Anyone else seeing issues to and from us-west-2?
 Looks like routing between us-west-2 and us-west-1 are going though
 us-east-1 and eu-west-2 as well as a high packet loss from the SF bay area
 into us-west-2.
 -Grant
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150125/667bbe3e/attachment.html>
 I'm seeing the same.
 Graham Freeman
 Sent from my mobile
  <4C898413-D387-48D8-ADED-DB174F4C6479@sungevity.com>
 We are seeing a level3 10g private line into aws west down.
 On Sunday, January 25, 2015, Graham Freeman via Outages <outages at outages.org>
 wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150125/a0fec42c/attachment.html>
  <4C898413-D387-48D8-ADED-DB174F4C6479@sungevity.com>
 Same here
 Rafael Ribeiro 
 Sent by iPhone
  <4C898413-D387-48D8-ADED-DB174F4C6479@sungevity.com>
  <54456DA0-A6A0-4F3A-B081-8FDD8BA7480F@gmail.com>
 Appears to be a fiber cut
 https://twitter.com/olivergarraux/status/559516684260630529
 Packet loss is gone, but latencies are still slightly elevated.
 -Grant
 On Sun, Jan 25, 2015 at 1:15 PM, Rafael Ribeiro - iPhone <
 rafaelribeiro.sp at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150125/68efddc6/attachment.html>
###############################################################
END
###############################################################

###############################################################
Bell 100G card failure North Toronto
###############################################################
 Happened around 03:15 GMT-5.  We lost a 10G wave between their Don Mills CO and their Sheppard Ave. E CO.  They are currently dispatching transport folks.  Just trying to get clarification on exactly which CO the card was in.
###############################################################
END
###############################################################

###############################################################
East coast problems between TeliaSonera and Verizon
###############################################################
 Is anyone experiencing problems between Verizon and TeliaSonera? I'm in
 Pittsburgh, PA and anything that goes to TeliaSonera is 100+ ms and
 throughput is incredibly low. I apologize for the poor formatting below:
 |------------------------------------------------------------------------------------------|
 |                                      WinMTR statistics
                 |
 |                       Host              -   %  | Sent | Recv | Best |
 Avrg | Wrst | Last |
 |------------------------------------------------|------|------|------|------|------|------|
 |    L100.PITBPA-VFTTP-33.verizon-gni.net -    0 |    8 |    8 |    2 |
  3 |    4 |    4 |
 |  G0-4-1-3.PITBPA-LCR-21.verizon-gni.net -    0 |    8 |    8 |    6 |
  7 |    9 |    8 |
 |                   No response from host -  100 |    1 |    0 |    0 |
  0 |    0 |    0 |
 |           0.so-6-0-1.XL3.IAD8.ALTER.NET -    0 |    8 |    8 |   12 |
 27 |   85 |   14 |
 |       TenGigE0-6-0-1.GW1.IAD8.ALTER.NET -    0 |    8 |    8 |   13 |
 17 |   25 |   14 |
 |       teliasonera-gw.customer.alter.net -    0 |    8 |    8 |   97 |
  108 |  116 |  109 |
 |                  ash-bb3-link.telia.net -    0 |    8 |    8 |  100 |
  109 |  117 |  111 |
 |                  nyk-bb1-link.telia.net -    0 |    8 |    8 |  106 |
  122 |  151 |  114 |
 |                   nyk-b6-link.telia.net -    0 |    8 |    8 |  106 |
  112 |  120 |  113 |
 |digitalocean-ic-302450-nyk-b6.c.telia.net -   20 |    5 |    4 |  106 |
  116 |  122 |  122 |
 |                          198.211.112.36 -    0 |    8 |    8 |  106 |
  114 |  124 |  117 |
 |________________________________________________|______|______|______|______|______|______|
    WinMTR v0.92 GPL V2 by Appnor MSP - Fully Managed Hosting & Cloud
 Provider
                                                          Packets
     Pings
  Host                                                  Loss%   Snt   Last
 Avg  Best  Wrst StDev
  1. 104.131.0.253                                       0.0%   121    0.6
 1.8   0.3  12.5   2.5
  2. 162.243.188.221                                     0.0%   121    0.5
 1.3   0.3  27.1   3.7
  3. nyk-b3-link.telia.net                               0.0%   120    1.2
 2.0   0.9  48.1   5.5
  4. nyk-bb2-link.telia.net                              0.0%   120   59.3
  12.6   1.3 102.4  23.2
  5. nyk-b5-link.telia.net                               0.0%   120    1.9
 2.1   1.7  14.3   1.5
  6. GigabitEthernet1-0-0.GW1.NYC4.ALTER.NET             0.0%   120    1.7
 1.8   1.5   2.6   0.0
  7. ???
  8. pool-74-111-114-111.pitbpa.fios.verizon.net         0.0%   120  116.2
 115.5  95.9 124.2   6.4
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150128/050274ee/attachment.html>
###############################################################
END
###############################################################

###############################################################
Level 3 packet loss - Pittsburgh PA
###############################################################
 Is anyone seeing packet loss on level3 in the Pittsburgh PA area? It has been on and off. Started around 8:30pm ET.
 I have a ticket with them on which they just responded
 "The IP NOC advised that an issue was detected on a Border Gateway Protocol. The affected Border Gateway Protocol was shutdown, which resolved the issue."
 However, I am still seeing it:
 ?
 -----------------------------------------------------------------------------------------
 Reply from 4.69.135.242: bytes=32 time=22ms TTL=250
 Reply from 4.69.135.242: bytes=32 time=24ms TTL=250
 Reply from 4.69.135.242: bytes=32 time=23ms TTL=250
 Reply from 4.69.135.242: bytes=32 time=22ms TTL=250
 Ping statistics for 4.69.135.242:
     Packets: Sent = 499, Received = 498, Lost = 1 (0% loss),
 Approximate round trip times in milli-seconds:
     Minimum = 20ms, Maximum = 27ms, Average = 22ms
 ------------------------------------------------------------------------------------------
 Reply from 4.34.25.185: bytes=32 time=71ms TTL=250
 Request timed out.
 Request timed out.
 Reply from 4.34.25.185: bytes=32 time=681ms TTL=250
 Request timed out.
 Ping statistics for 4.34.25.185:
     Packets: Sent = 386, Received = 356, Lost = 30 (7% loss),
 Approximate round trip times in milli-seconds:
     Minimum = 23ms, Maximum = 1337ms, Average = 77ms??
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150129/e11f71e2/attachment.html>
 On 1/28/15 9:02 PM, John Pittavino via Outages wrote:
 there is a wdm maintenance in the region that could have impacted some
 circuits
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: signature.asc
 Type: application/pgp-signature
 Size: 243 bytes
 Desc: OpenPGP digital signature
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150128/8795d0db/attachment.sig>
###############################################################
END
###############################################################

###############################################################
Charter Voice outage
###############################################################
 Just got told by a charter rep that there is an issue affecting Charter 
 Voice in multiple US states.
 We are hearing from multiple Charter cable customers in California that 
 their Charter Voice service is not working at all.  A sub-set of those 
 customers also report no internet as well.
 Anyone have any more information?
 -Robert
 One place I work with has been down since noon.  This is in Madison WI. 
 Paul
  <E713B320-459D-420D-87BE-5C9F722056A4@yellowfog.org>
 Seeing them down here on SIX peering in Seattle, WA.  One of two
 routers is completely unresponsive, the other one actually just came
 up ~3 minutes ago.
 On Fri, Jan 30, 2015 at 3:23 PM, Paul Counsell via Outages
 <outages at outages.org> wrote:
 -- 
 "Genius might be described as a supreme capacity for getting its possessors
 into trouble of all kinds."
 -- Samuel Butler
  <E713B320-459D-420D-87BE-5C9F722056A4@yellowfog.org>
  <CAHDg04uGh1dtR+a0g-XKpmBjyKGTn3-zx0PJ+7ZAHC=Rznynsw@mail.gmail.com>
 And as I sent that both BGP sessions are back up...they were down for
 a bit over 30m.
 On Fri, Jan 30, 2015 at 3:41 PM, Michael Loftis <mloftis at wgops.com> wrote:
 >>> On Jan 30, 2015, at 16:58, Robert Glover via Outages <outages at outages.org> wrote:
 >>>
 >>> Just got told by a charter rep that there is an issue affecting Charter Voice in multiple US states.
 >>>
 >>> We are hearing from multiple Charter cable customers in California that their Charter Voice service is not working at all.  A sub-set of those customers also report no internet as well.
 >>>
 >>> Anyone have any more information?
 >>>
 >>> -Robert
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 -- 
 "Genius might be described as a supreme capacity for getting its possessors
 into trouble of all kinds."
 -- Samuel Butler
 Not a great news source, but more commentary on the issue:
 http://www.onlinesocialmedia.net/20150130/charter-internet-outage-today-jan-
 30-angers-users/
 Looks like things are back up, as of 9:30 pm Central:
 https://twitter.com/CharterCom/status/561365714720669696
 Frank
 -----Original Message-----
 From: Outages [mailto:outages-bounces at outages.org] On Behalf Of Robert
 Glover via Outages
 Sent: Friday, January 30, 2015 4:59 PM
 Just got told by a charter rep that there is an issue affecting Charter 
 Voice in multiple US states.
 We are hearing from multiple Charter cable customers in California that 
 their Charter Voice service is not working at all.  A sub-set of those 
 customers also report no internet as well.
 Anyone have any more information?
 -Robert
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 I am not seeing any issues with Charter SIP trunks or DOCIS MTA
 circuits in Michigan.
  - - Mitchell
 This appears to be impacting business lines delivered via a DOCIS MTA. It appears as if many (most?) MTAs were, at times, unable to register with the call managers.
 SIP trunks and PRI services (delivered via SIP) seem to be unaffected. 
 Any contradictions, reports of trouble with residential service, or IP service (for customers without the modem, router, MTA thing)?
  - - Mitchell
 >>> From: Robert Glover via Outages <outages at outages.org>
 >>> Date: January 30, 2015 at 17:58:34 EST
 >>> To: "outages at outages.org" <outages at outages.org>
 >>> Subject: [outages] Charter Voice outage
 >>> Reply-To: Robert Glover <robertg at garlic.com>
 >>> 
 >>> Just got told by a charter rep that there is an issue affecting Charter Voice in multiple US states.
 >>> 
 >>> We are hearing from multiple Charter cable customers in California that their Charter Voice service is not working at all.  A sub-set of those customers also report no internet as well.
 >>> 
 >>> Anyone have any more information?
 >>> 
 >>> -Robert
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150130/f504d79b/attachment-0001.html>
 Charter has been up/down all day. St. Louis, Mo.
 -----Original Message-----
 From: Michael Loftis via Outages [outages at outages.org]
 Sent: Friday, January 30, 2015 05:46 PM Central Standard Time
 Cc: outages at outages.org
 Seeing them down here on SIX peering in Seattle, WA.  One of two
 routers is completely unresponsive, the other one actually just came
 up ~3 minutes ago.
 On Fri, Jan 30, 2015 at 3:23 PM, Paul Counsell via Outages
 <outages at outages.org> wrote:
 --
 "Genius might be described as a supreme capacity for getting its possessors
 into trouble of all kinds."
 -- Samuel Butler
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150130/0c05f8e8/attachment.html>
 All my clients run VoIP over AT&T T1 lines, only been experiencing charter IP outages.
 -----Original Message-----
 From: Mitchell Kuch via Outages [outages at outages.org]
 Sent: Friday, January 30, 2015 06:10 PM Central Standard Time
 This appears to be impacting business lines delivered via a DOCIS MTA. It appears as if many (most?) MTAs were, at times, unable to register with the call managers.
 SIP trunks and PRI services (delivered via SIP) seem to be unaffected. 
 Any contradictions, reports of trouble with residential service, or IP service (for customers without the modem, router, MTA thing)?
  - - Mitchell 
 	From: Paul Counsell via Outages <outages at outages.org>
 	Date: January 30, 2015 at 18:23:28 EST
 	Cc: "outages at outages.org" <outages at outages.org>
 	Subject: Re: [outages] Charter Voice outage
 	Reply-To: Paul Counsell <counsell at yellowfog.org>
 	One place I work with has been down since noon.  This is in Madison WI. 
 	Paul
 		From: Mitchell Kuch via Outages <outages at outages.org>
 		Date: January 30, 2015 at 18:10:03 EST
 		Subject: Re: [outages] Charter Voice outage
 		Reply-To: Mitch at basejp.com
 		I am not seeing any issues with Charter SIP trunks or DOCIS MTA
 		circuits in Michigan.
 		- - Mitchell
 			From: Robert Glover via Outages <outages at outages.org>
 			Date: January 30, 2015 at 17:58:34 EST
 Subject: [outages] Charter Voice outage Reply-To: Robert Glover <robertg at garlic.com>
 			Just got told by a charter rep that there is an issue affecting Charter Voice in multiple US states.
 			We are hearing from multiple Charter cable customers in California that their Charter Voice service is not working at all.  A sub-set of those customers also report no internet as well.
 			Anyone have any more information?
 			-Robert
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20150130/199282fb/attachment.html>
###############################################################
END
###############################################################

