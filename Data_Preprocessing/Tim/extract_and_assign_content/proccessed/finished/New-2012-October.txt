###############################################################
Ebay dns record
###############################################################
  None of our ISPs' DNS servers can reach ebay.  Expanding on that list,
 it appears that the only DNS servers able to dig ebay are the ones that
 cache.  Is anyone else seeing this?
 -- Christina
 Christina Klam
 Network Administrator
 Institute for Advanced Study
 Email:  cklam at ias.edu
 Einstein Drive          Telephone: 609-734-8154
 Princeton, NJ 08540     Fax:  609-951-4418
 No issues here - testing from multiple locations/providers on the West
 coast.
 $ dig +trace www.ebay.com
 [...]
 www.ebay.com.           300     IN      A       66.135.210.61
 www.ebay.com.           300     IN      A       66.135.210.181
 www.ebay.com.           300     IN      A       66.211.181.161
 www.ebay.com.           300     IN      A       66.211.181.181
 www.ebay.com.           300     IN      A       66.135.200.161
 www.ebay.com.           300     IN      A       66.135.200.181
 ;; Received 126 bytes from 66.135.207.138#53(66.135.207.138) in 5 ms
   Scott
 On Mon, Oct 1, 2012 at 12:17 PM, Christina Klam <cklam at ias.edu> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121001/d70ca584/attachment.html>
 On 10/01/12?15:17?-0400, Christina Klam wrote:
 >None of our ISPs' DNS servers can reach ebay.  Expanding on that list,
 >it appears that the only DNS servers able to dig ebay are the ones that
 >cache.  Is anyone else seeing this?
 It's working for me:
 ~$ dig +trace ebay.com a
 ; <<>> DiG 9.8.1-P1 <<>> +trace ebay.com a
 ;; global options: +cmd
 .                       16932   IN      NS      b.root-servers.net.
 .                       16932   IN      NS      c.root-servers.net.
 .                       16932   IN      NS      d.root-servers.net.
 .                       16932   IN      NS      e.root-servers.net.
 .                       16932   IN      NS      f.root-servers.net.
 .                       16932   IN      NS      g.root-servers.net.
 .                       16932   IN      NS      h.root-servers.net.
 .                       16932   IN      NS      i.root-servers.net.
 .                       16932   IN      NS      j.root-servers.net.
 .                       16932   IN      NS      k.root-servers.net.
 .                       16932   IN      NS      l.root-servers.net.
 .                       16932   IN      NS      m.root-servers.net.
 .                       16932   IN      NS      a.root-servers.net.
 ;; Received 449 bytes from 10.0.1.10#53(10.0.1.10) in 8 ms
 com.                    172800  IN      NS      i.gtld-servers.net.
 com.                    172800  IN      NS      c.gtld-servers.net.
 com.                    172800  IN      NS      e.gtld-servers.net.
 com.                    172800  IN      NS      b.gtld-servers.net.
 com.                    172800  IN      NS      d.gtld-servers.net.
 com.                    172800  IN      NS      g.gtld-servers.net.
 com.                    172800  IN      NS      l.gtld-servers.net.
 com.                    172800  IN      NS      m.gtld-servers.net.
 com.                    172800  IN      NS      h.gtld-servers.net.
 com.                    172800  IN      NS      k.gtld-servers.net.
 com.                    172800  IN      NS      j.gtld-servers.net.
 com.                    172800  IN      NS      a.gtld-servers.net.
 com.                    172800  IN      NS      f.gtld-servers.net.
 ;; Received 498 bytes from 192.36.148.17#53(192.36.148.17) in 124 ms
 ebay.com.               172800  IN      NS      sjc-dns1.ebaydns.com.
 ebay.com.               172800  IN      NS      sjc-dns2.ebaydns.com.
 ebay.com.               172800  IN      NS      smf-dns1.ebaydns.com.
 ebay.com.               172800  IN      NS      smf-dns2.ebaydns.com.
 ;; Received 190 bytes from 192.52.178.30#53(192.52.178.30) in 132 ms
 ebay.com.               3600    IN      A       66.135.205.13
 ebay.com.               3600    IN      A       66.135.205.14
 ebay.com.               3600    IN      A       66.211.160.87
 ebay.com.               3600    IN      A       66.211.160.88
 ;; Received 90 bytes from 66.135.215.5#53(66.135.215.5) in 36 ms
 -- 
 Dan White
 OpenDNS works.  4.2.2.2 works.  8.8.8.8 works.
 Sure it isn't just your ISP's?
 Josh Luthman
 Office: 937-552-2340
 Direct: 937-552-2343
 1100 Wayne St
 Suite 1337
 Troy, OH 45373
 On Mon, Oct 1, 2012 at 3:17 PM, Christina Klam <cklam at ias.edu> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121001/aa8e84cc/attachment.html>
  <CAPC+kK7zPc_frNgSQZBo1kSeSLadwsx+fLRmnCsegfkSxwB58g@mail.gmail.com>
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121001/83b6633a/attachment.html>
  <CAPC+kK7zPc_frNgSQZBo1kSeSLadwsx+fLRmnCsegfkSxwB58g@mail.gmail.com>
  <CAPC+kK7KMPpx+eJiDpAZN7afwJ71X8TWU3_UncAYB0Uou2zCnw@mail.gmail.com>
 Have you tried from the C:> drive?  The L: Drive is intermittently lossy.
 On a more serious note, working fine for me.  They are filtering icmp echo.
 -Chris
 On Mon, Oct 1, 2012 at 3:24 PM, Mitch <mitpatterson at gmail.com> wrote:
 >>> None of our ISPs' DNS servers can reach ebay.  Expanding on that list,
 >>> it appears that the only DNS servers able to dig ebay are the ones that
 >>> cache.  Is anyone else seeing this?
 >>>
 >>>
 >>> -- Christina
 >>> Christina Klam
 >>> Network Administrator
 >>> Institute for Advanced Study
 >>> Email:  cklam at ias.edu
 >>>
 >>> Einstein Drive          Telephone: 609-734-8154
 >>> Princeton, NJ 08540     Fax:  609-951-4418
 >>>
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 >>>
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121001/232518b2/attachment.html>
 Can't reproduce issue from a Comcast residential connection in Silicon
 Valley, nor from a co-located server in San Diego.
 $ dig @SJC-DNS1.EBAYDNS.COM a www.ebay.com.
 ; <<>> DiG 9.8.3-P3 <<>> @SJC-DNS1.EBAYDNS.COM a www.ebay.com.
 ; (1 server found)
 ;; global options: +cmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 34271
 ;; flags: qr aa rd; QUERY: 1, ANSWER: 6, AUTHORITY: 0, ADDITIONAL: 0
 ;; WARNING: recursion requested but not available
 ;; QUESTION SECTION:
 ;www.ebay.com.                  IN      A
 ;; ANSWER SECTION:
 www.ebay.com.           300     IN      A       66.211.181.161
 www.ebay.com.           300     IN      A       66.211.181.181
 www.ebay.com.           300     IN      A       66.135.200.161
 www.ebay.com.           300     IN      A       66.135.200.181
 www.ebay.com.           300     IN      A       66.135.210.61
 www.ebay.com.           300     IN      A       66.135.210.181
 ;; Query time: 17 msec
 ;; SERVER: 66.135.207.137#53(66.135.207.137)
 ;; WHEN: Mon Oct  1 12:24:09 2012
 ;; MSG SIZE  rcvd: 126
 $ dig @SJC-DNS2.EBAYDNS.COM a www.ebay.com.
 ; <<>> DiG 9.8.3-P3 <<>> @SJC-DNS2.EBAYDNS.COM a www.ebay.com.
 ; (1 server found)
 ;; global options: +cmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 60185
 ;; flags: qr aa rd; QUERY: 1, ANSWER: 6, AUTHORITY: 0, ADDITIONAL: 0
 ;; WARNING: recursion requested but not available
 ;; QUESTION SECTION:
 ;www.ebay.com.                  IN      A
 ;; ANSWER SECTION:
 www.ebay.com.           300     IN      A       66.135.210.181
 www.ebay.com.           300     IN      A       66.211.181.161
 www.ebay.com.           300     IN      A       66.211.181.181
 www.ebay.com.           300     IN      A       66.135.200.161
 www.ebay.com.           300     IN      A       66.135.200.181
 www.ebay.com.           300     IN      A       66.135.210.61
 ;; Query time: 17 msec
 ;; SERVER: 66.135.207.138#53(66.135.207.138)
 ;; WHEN: Mon Oct  1 12:24:12 2012
 ;; MSG SIZE  rcvd: 126
 $ dig @SMF-DNS1.EBAYDNS.COM a www.ebay.com.
 ; <<>> DiG 9.8.3-P3 <<>> @SMF-DNS1.EBAYDNS.COM a www.ebay.com.
 ; (1 server found)
 ;; global options: +cmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 23132
 ;; flags: qr aa rd; QUERY: 1, ANSWER: 6, AUTHORITY: 0, ADDITIONAL: 0
 ;; WARNING: recursion requested but not available
 ;; QUESTION SECTION:
 ;www.ebay.com.                  IN      A
 ;; ANSWER SECTION:
 www.ebay.com.           300     IN      A       66.211.181.161
 www.ebay.com.           300     IN      A       66.211.181.181
 www.ebay.com.           300     IN      A       66.135.200.161
 www.ebay.com.           300     IN      A       66.135.200.181
 www.ebay.com.           300     IN      A       66.135.210.61
 www.ebay.com.           300     IN      A       66.135.210.181
 ;; Query time: 37 msec
 ;; SERVER: 66.135.223.137#53(66.135.223.137)
 ;; WHEN: Mon Oct  1 12:24:15 2012
 ;; MSG SIZE  rcvd: 126
 $ dig @SMF-DNS2.EBAYDNS.COM a www.ebay.com.
 ; <<>> DiG 9.8.3-P3 <<>> @SMF-DNS2.EBAYDNS.COM a www.ebay.com.
 ; (1 server found)
 ;; global options: +cmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 10577
 ;; flags: qr aa rd; QUERY: 1, ANSWER: 6, AUTHORITY: 0, ADDITIONAL: 0
 ;; WARNING: recursion requested but not available
 ;; QUESTION SECTION:
 ;www.ebay.com.                  IN      A
 ;; ANSWER SECTION:
 www.ebay.com.           300     IN      A       66.135.200.161
 www.ebay.com.           300     IN      A       66.135.200.181
 www.ebay.com.           300     IN      A       66.135.210.61
 www.ebay.com.           300     IN      A       66.135.210.181
 www.ebay.com.           300     IN      A       66.211.181.161
 www.ebay.com.           300     IN      A       66.211.181.181
 ;; Query time: 34 msec
 ;; SERVER: 66.135.215.5#53(66.135.215.5)
 ;; WHEN: Mon Oct  1 12:24:17 2012
 ;; MSG SIZE  rcvd: 126
 Nameserver list:
 ;; QUESTION SECTION:
 ;ebay.com.                      IN      NS
 ;; ANSWER SECTION:
 ebay.com.               70893   IN      NS      smf-dns2.ebaydns.com.
 ebay.com.               70893   IN      NS      sjc-dns1.ebaydns.com.
 ebay.com.               70893   IN      NS      smf-dns1.ebaydns.com.
 ebay.com.               70893   IN      NS      sjc-dns2.ebaydns.com.
 ;; ADDITIONAL SECTION:
 sjc-dns1.ebaydns.com.   65373   IN      A       66.135.207.137
 smf-dns1.ebaydns.com.   64711   IN      A       66.135.223.137
 sjc-dns2.ebaydns.com.   64216   IN      A       66.135.207.138
 smf-dns2.ebaydns.com.   66428   IN      A       66.135.215.5
 SOA for ebay.com does indicate, assuming serial is to be interpreted in
 the usual YYYYMMDDnn format, that they haven't changed anything in ~2
 days.
 ;; ANSWER SECTION:
 ebay.com.               3600    IN      SOA     sjc-dns1.ebaydns.com.  hostmaster.ebay.com. 2012092800 3600 1800 604800 86400
 Traceroute to any of the above DNS servers is worthless, as they appear
 to drop ICMP at the immediate borders of their networks.
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
 On Mon, Oct 01, 2012 at 03:17:33PM -0400, Christina Klam wrote:
  <CAN9qwJ_sLueDqdFG=nyvejNKKRLj+QZ=iHGqQA8CLOMyk8PdJg@mail.gmail.com>
 For the time being we are using  google and OpenDNS as DNS forwarders. 
 I am opening a ticket with Cogent now.
 Thank you everyone,
 Christina
 On 10/01/2012 03:23 PM, Josh Luthman wrote:
 -- 
 Christina Klam
 Network Administrator
 Institute for Advanced Study
 Email:  cklam at ias.edu
 Einstein Drive          Telephone: 609-734-8154
 Princeton, NJ 08540     Fax:  609-951-4418
  <CAPC+kK7zPc_frNgSQZBo1kSeSLadwsx+fLRmnCsegfkSxwB58g@mail.gmail.com>
  <CAPC+kK7KMPpx+eJiDpAZN7afwJ71X8TWU3_UncAYB0Uou2zCnw@mail.gmail.com>
 eBay drops ICMP at their network borders.
 Furthermore, ping != DNS.
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
 On Mon, Oct 01, 2012 at 03:24:22PM -0400, Mitch wrote:
  <CAPC+kK7zPc_frNgSQZBo1kSeSLadwsx+fLRmnCsegfkSxwB58g@mail.gmail.com>
  <CAPC+kK7KMPpx+eJiDpAZN7afwJ71X8TWU3_UncAYB0Uou2zCnw@mail.gmail.com>
  <20121001193055.GA30287@icarus.home.lan>
 I was more just commenting that I was able to resolve(DNS) but not ping.
 On Mon, Oct 1, 2012 at 3:30 PM, Jeremy Chadwick <jdc at koitsu.org> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121001/996a03fb/attachment-0001.html>
 ----- Original Message -----
 Looking good from FiOS St Pete:
 =============================================================
 jra at princeton:~/.ssh> dig +trace www.ebay.com
 ; <<>> DiG 9.8.3-P3 <<>> +trace www.ebay.com
 ;; global options: +cmd
 .                       3600    IN      NS      FWDR-8.FWDR-8.FWDR-8.FWDR-8.
 .                       3600    IN      NS      FWDR-4.FWDR-4.FWDR-8.FWDR-8.
 .                       3600    IN      NS      FWDR-8.FWDR-8.FWDR-8.FWDR-8.
 .                       3600    IN      NS      FWDR-4.FWDR-4.FWDR-4.FWDR-4.
 ;; Received 309 bytes from 192.168.0.1#53(192.168.0.1) in 336 ms
 www.ebay.com.           57      IN      A       66.135.200.161
 www.ebay.com.           57      IN      A       66.135.200.181
 www.ebay.com.           57      IN      A       66.135.210.61
 www.ebay.com.           57      IN      A       66.135.210.181
 www.ebay.com.           57      IN      A       66.211.181.161
 www.ebay.com.           57      IN      A       66.211.181.181
 ;; Received 126 bytes from 8.8.8.8#53(8.8.8.8) in 47 ms
 jra at princeton:~/.ssh> dig +trace @a.root-servers.net www.ebay.com
 ; <<>> DiG 9.8.3-P3 <<>> +trace @a.root-servers.net www.ebay.com
 ; (1 server found)
 ;; global options: +cmd
 .                       518400  IN      NS      m.root-servers.net.
 .                       518400  IN      NS      a.root-servers.net.
 .                       518400  IN      NS      f.root-servers.net.
 .                       518400  IN      NS      c.root-servers.net.
 .                       518400  IN      NS      d.root-servers.net.
 .                       518400  IN      NS      b.root-servers.net.
 .                       518400  IN      NS      i.root-servers.net.
 .                       518400  IN      NS      j.root-servers.net.
 .                       518400  IN      NS      k.root-servers.net.
 .                       518400  IN      NS      h.root-servers.net.
 .                       518400  IN      NS      e.root-servers.net.
 .                       518400  IN      NS      g.root-servers.net.
 .                       518400  IN      NS      l.root-servers.net.
 ;; Received 512 bytes from 198.41.0.4#53(198.41.0.4) in 1174 ms
 com.                    172800  IN      NS      a.gtld-servers.net.
 com.                    172800  IN      NS      b.gtld-servers.net.
 com.                    172800  IN      NS      c.gtld-servers.net.
 com.                    172800  IN      NS      d.gtld-servers.net.
 com.                    172800  IN      NS      e.gtld-servers.net.
 com.                    172800  IN      NS      f.gtld-servers.net.
 com.                    172800  IN      NS      g.gtld-servers.net.
 com.                    172800  IN      NS      h.gtld-servers.net.
 com.                    172800  IN      NS      i.gtld-servers.net.
 com.                    172800  IN      NS      j.gtld-servers.net.
 com.                    172800  IN      NS      k.gtld-servers.net.
 com.                    172800  IN      NS      l.gtld-servers.net.
 com.                    172800  IN      NS      m.gtld-servers.net.
 ;; Received 490 bytes from 199.7.83.42#53(199.7.83.42) in 1357 ms
 ebay.com.               172800  IN      NS      sjc-dns1.ebaydns.com.
 ebay.com.               172800  IN      NS      sjc-dns2.ebaydns.com.
 ebay.com.               172800  IN      NS      smf-dns1.ebaydns.com.
 ebay.com.               172800  IN      NS      smf-dns2.ebaydns.com.
 ;; Received 194 bytes from 192.55.83.30#53(192.55.83.30) in 589 ms
 www.ebay.com.           300     IN      A       66.135.210.61
 www.ebay.com.           300     IN      A       66.135.210.181
 www.ebay.com.           300     IN      A       66.211.181.161
 www.ebay.com.           300     IN      A       66.211.181.181
 www.ebay.com.           300     IN      A       66.135.200.161
 www.ebay.com.           300     IN      A       66.135.200.181
 ;; Received 126 bytes from 66.135.207.138#53(66.135.207.138) in 86 ms
 =============================================================
 I note that Google's DNS servers, which my router seems to be pointed at,
 seem to be authoritative for *everything*; I'm not sure what I think about
 that.  Forcing a.root did show the results I expected, though.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates     http://baylink.pitas.com         2000 Land Rover DII
 St Petersburg FL USA               #natog                      +1 727 647 1274
 ----- Original Message -----
 Hmmm.  Let me phrase it differently: 
 When I dig +trace, I do not expect GDNS to be the first hop, and the end 
 records to be the second.  I'm not sure what is causing that, but I'm 
 relatively sure it's something doubleplus ungood.  See the two traces in
 my original posting, if it's not clear what I'm complaining about.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates     http://baylink.pitas.com         2000 Land Rover DII
 St Petersburg FL USA               #natog                      +1 727 647 1274
###############################################################
END
###############################################################

###############################################################
Level3 taking the Southern Route from Boston to Poughkeepsie
###############################################################
 Hi,
 Bard College at Simon's Rock (simons-rock.edu) is a small college in  
 Southwestern Mass, with our parent campus, Bard (bard.edu), in the  
 Hudson Valley near Rhinebeck, NY.
 We use a database hosted on the main campus, and poor database  
 performance here is often correlated with Level3 / Global Crossing  
 issues in New York city. Today my users are complaining about slow  
 database response, and I find that traceroutes from here, and from  
 Level3's Looking Glass Boston page now go from NYC to Poughkeepsie via  
 Washington, Atlanta, and Miami. This is a new routing; traces from  
 past months went directly from NYC to Poughkeepsie.
 I've reported this to our provider, who has presumably passed it along  
 to Level3, but I'm wondering if these goofy routes are part of a work- 
 around of some bigger issue in NYC, or just a screw up, or perhaps  
 there is some valid business reason for this routing change?
 Anyone else seeing strangeness via Level3 from NYC to the Hudson?
 Here's Level3's traceroute, from http://lg.level3.net/traceroute/traceroute.cgi?site=bos1&target=hyphen.bard.edu 
   :
 Show Level 3 (Boston, MA) Traceroute to hyphen.bard.edu (192.246.235.1)
   1 ae-2-7.bar1.Boston1.Level3.net (4.69.132.242) 0 msec 0 msec 0 msec
   2 ae-0-11.bar2.Boston1.Level3.net (4.69.140.90) 0 msec 0 msec 4 msec
   3 ae-8-8.ebr1.NewYork1.Level3.net (4.69.140.98) 32 msec 32 msec 36  
 msec
   4 ae-10-10.ebr2.Washington12.Level3.net (4.69.148.50) 32 msec 32  
 msec 36 msec
   5 ae-1-100.ebr1.Washington12.Level3.net (4.69.143.213) 36 msec 44  
 msec 44 msec
   6 ae-6-6.ebr1.Atlanta2.Level3.net (4.69.148.105) 72 msec 36 msec 36  
 msec
   7 ae-1-100.ebr2.Atlanta2.Level3.net (4.69.132.34) 32 msec 36 msec 44  
 msec
   8 ae-2-2.ebr2.Miami1.Level3.net (4.69.140.141) 36 msec 40 msec 36 msec
   9 ae-2-52.edge1.Miami2.Level3.net (4.69.138.107) 32 msec 36 msec 36  
 msec
   10 64.209.106.214 36 msec 36 msec 36 msec
   11 10gigabitethernet1-1.core1.atl1.he.net (72.52.92.53) [AS6939  
 {HURRICANE}] 40 msec 36 msec 40 msec
   12 10gigabitethernet6-4.core1.ash1.he.net (184.105.213.109) [AS6939  
 {HURRICANE}] 40 msec 40 msec 52 msec
   13 10gigabitethernet1-2.core1.nyc4.he.net (72.52.92.85) [AS6939  
 {HURRICANE}] 40 msec 48 msec 48 msec
   14 10gigabitethernet4-1.core1.nyc5.he.net (184.105.213.218) [AS6939  
 {HURRICANE}] 40 msec 48 msec 48 msec
   15 * lightower-fiber-networks.10gigabitethernet3-2.core1.nyc5.he.net  
 (216.66.50.106) [AS6939 {HURRICANE}] 208 msec 204 msec
   16 xe-0-3-0.pghknyshj42.lightower.net (72.22.160.150) [AS46887  
 {LIGHTOWER}] 208 msec * 220 msec
   17 ae0-pghknyshj91.lightower.net (72.22.160.158) [AS46887  
 {LIGHTOWER}] 92 msec 64 msec 44 msec
   18 xe-7-2-0.kgtnnykgj91.lightower.net (72.22.160.107) [AS46887  
 {LIGHTOWER}] 196 msec 128 msec 312 msec
   19 BardCollege-cust.customer.hvdata.net (64.72.66.234) [AS46887  
 {LIGHTOWER}] 164 msec * *
 (In the past, we sometimes got a nice short route directly from Level3  
 in Boston to Lightower.net in Boston, as Lightower seems to have a  
 direct link Poughkeepsie to Boston. However, when Level3 merged with  
 Global Crossing, our route to Bard started going through NYC to reach  
 Lightower, which has been more troublesome.)
 Thanks for any hints you can offer.
 Steve Bohrer
 Network Admin
 Bard College at Simon's Rock
 413-528-7645	
 This is my trace from Summer St. in Boston:
 traceroute 192.246.235.1
 Type escape sequence to abort.
 Tracing the route to hyphen.bard.edu (192.246.235.1)
    2 ae-2-7.bar1.Boston1.Level3.net (4.69.132.242) [AS 3356] [MPLS: 
 Label 302944 Exp 0] 0 msec 0 msec 4 msec
    3 ae-0-11.bar2.Boston1.Level3.net (4.69.140.90) [AS 3356] [MPLS: 
 Label 302944 Exp 0] 0 msec 0 msec 4 msec
    4 ae-8-8.ebr1.NewYork1.Level3.net (4.69.140.98) [AS 3356] [MPLS: 
 Label 1268 Exp 0] 4 msec 4 msec 24 msec
    5 ae-81-81.csw3.NewYork1.Level3.net (4.69.134.74) [AS 3356] [MPLS: 
 Label 1325 Exp 0] 8 msec
      ae-71-71.csw2.NewYork1.Level3.net (4.69.134.70) [AS 3356] [MPLS: 
 Label 1325 Exp 0] 4 msec 8 msec
    6 ae-1-60.edge4.NewYork1.Level3.net (4.69.155.20) [AS 3356] 60 msec 8 
 msec
      ae-2-70.edge4.NewYork1.Level3.net (4.69.155.84) [AS 3356] 4 msec
    7 4.68.111.242 [AS 3356] 4 msec
      64.215.195.229 [AS 3549] 4 msec 4 msec
    8 
 HURRICANE-ELECTRIC-LLC-New-York.TenGigabitEthernet1-3.ar5.NYC1.gblx.net 
 (64.209.92.98) [AS 3549] 24 msec 4 msec 4 msec
    9 10gigabitethernet4-1.core1.nyc5.he.net (184.105.213.218) [AS 6939] 
 8 msec 4 msec 8 msec
   10 lightower-fiber-networks.10gigabitethernet3-2.core1.nyc5.he.net 
 (216.66.50.106) [AS 6939] 8 msec 4 msec 8 msec
   11 xe-0-3-0.pghknyshj42.lightower.net (72.22.160.150) [AS 46887] 28 
 msec 12 msec 8 msec
   12 ae0-pghknyshj91.lightower.net (72.22.160.158) [AS 46887] 8 msec 8 
 msec 8 msec
   13 xe-7-2-0.kgtnnykgj91.lightower.net (72.22.160.107) [AS 46887] 28 
 msec 8 msec 8 msec
   14 BardCollege-cust.customer.hvdata.net (64.72.66.234) [AS 46887] 8 
 msec *  284 msec
 I don't see it going down to DC or ATL or Miami.
 --John
 On 10/04/2012 01:35 PM, Steve Bohrer wrote:
  <506DDCED.1060207@gmail.com>
 This could be an NNI or peering disconnect between light tower and Level3.  Light tower has been doing maintenance on different nodes... They have been know to forget to notify their peers . 
 Regards,
  Joe Sanchez
 ( please excuse the brevity of this email as it was sent via a mobile device.  Please excuse misspelled words or sentence structure.) 
 On Oct 4, 2012, at 3:01 PM, John Barbieri <tenpin784 at gmail.com> wrote:
 Steve,
 And what about a traceroute from hyphen.bard.edu to wherever that L3
 looking glass is?  Since the source (of the looking glass) doesn't
 appear to be shown, I would say a traceroute from hyphen.bard.edu to
 4.69.132.242 would be the 2nd best thing to have (and ignore any packet
 loss you see at that destination; it's a router not a machine).
 Just last week on the mailing list I covered the importance of having
 traceroutes from both directions, re: asymmetrical routing.  The PDF
 I've linked should be read in full:
 https://puck.nether.net/pipermail/outages/2012-September/004466.html
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
 On Thu, Oct 04, 2012 at 02:35:07PM -0400, Steve Bohrer wrote:
  <20121004190247.GA13047@icarus.home.lan>
 Thanks Jeremy,
 I saw your post last week, and found it very useful. In fact the route  
 is asymmetrical: traces from Bard back to us go from Lightower's  
 Poughkeepsie location directly to Boston, and skip NYC altogether -- I  
 wish we could get that route both directions!
 My concern is that the traceroute from here to Bard was suddenly much  
 longer than in past months, and I got the same results directly from  
 Level3, so that made me think it wasn't something goofy with our last  
 mile. But, as John noted above, now it works as expected now from  
 Level3's page, and also from our site. I don't know if the timing of  
 this fix shortly after my post was just coincidental, or if the ticket  
 I filed with my provider at 12:30 finally trickled through the system,  
 or if perhaps the act of posting to Outages got someone at Level3 to  
 notice.
 In any case, it works again now the way it did yesterday, so I'm all  
 set.
 Steve Bohrer
 ITS, Bard College at Simon's Rock
 413-528-7645
 On Oct 4, 2012, at 3:02 PM, Jeremy Chadwick wrote:
###############################################################
END
###############################################################

###############################################################
BT international links
###############################################################
 Looks Like BT are suffering a national issue with accessing sites outside
 of the UK
 Affects broadband and leased line customers.
 Trying to call them results in an automated message saying as such and v
 long wait times (over 30mins and still no-one to talk to ..)
 Broadband status page
 http://btbusiness.custhelp.com/app/service_status/also shows this
 issue.
 -- 
 Martin Hepworth, CISSP
 Oxford, UK
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/a8dd0f94/attachment.html>
 On Fri, 5 Oct 2012, Martin Hepworth wrote:
 We have been seeing a lot of latency and packetloss via their GBLX links 
 today.
 Traceroutes as of around 15 mins ago to the sites I've been testing 
 to/from now traverse Level(3) instead with no loss.
 regards
###############################################################
END
###############################################################

###############################################################
Godaddy / Premium DNS outage?
###############################################################
  <CB326BE2-8F75-40B2-BE26-83A6E39DEF40@puck.nether.net>
  <CAEE+rGr3zaCoHkF3WH6nnXYnwnav+kU9j2+jT4zGUoGcT=gRgg@mail.gmail.com>
  <C7ED1475-ABA8-47A8-917A-B5EC037A5E4E@seanharlow.info>
  <CAB+BaiOcTsqTQgtyvQgL67-M8J_Xvq2477QbqgQaOMS0aHbn6g@mail.gmail.com>
  <1147829205.210004.1347385186951@150a5ad9285b45219553b50e696ea1b3.nuevasync.com>
  <504F794D.1050403@rollernet.us>
  <C010040A9601D24CB336337E19A02006032A8A66D1@MBX14.bell.corp.bce.ca>
  <A527E5F0-81E2-4641-A86F-A0F6E2F97513@sequestered.net>
  <296779DF1E244043BFB3D40794639EAAB6032E@mta-e2k10.pickmta.com>
 I made a commitment to get everyone on here the RFO.  Its presented in
 layman's terms:
 http://inside.godaddy.com/inside-story-happened-godaddy-com-sept-10-2012/
 Regards,
 Jason LeBlanc
 Network Engineering
 (480)505-8800 x7202
 Please contact my direct supervisor mdob at godaddy.com?with any feedback.
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Cary Smith
 Sent: Tuesday, September 11, 2012 1:40 PM
 Cc: outages at outages.org
 I'm not surprised Go-Daddy went in the direction of "internal network events
 that corrupted router data tables". It is definitely the lesser of the two
 evils. To come out and admit they were hacked or experienced a DDOS would
 make Customers feel their information on Go-Daddy servers was potentially
 compromised. Hence the CEO's statement, " At no time was any customer data
 at risk or were any of our systems compromised."
 Unless there's a government investigation, which is doubtful, none of us
 will really ever know what truly happened.
 Cary W. Smith
 MTA
 1567 East 93rd. Avenue
 Merrillville, IN 46410
 Office - 219-750-1803
 Cell - 219-765-1251
 e-mail - cary at pickmta.com
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Corey Quinn
 Sent: Tuesday, September 11, 2012 1:02 PM
 Cc: outages at outages.org
 Frankly, "we were ddos'd" is a much better sell than "we screwed up our
 internal systems horribly because we're idiots.". Surprised they went this
 direction.
 On Sep 11, 2012, at 10:53 AM, "francis.daigneault at bell.ca"
 <francis.daigneault at bell.ca> wrote:
 explain something or you don't want to admit something blame it on
 "corruption"
 it.. how could that happen.. coincidence ?
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 ________________________________
 DISCLAIMER: The information in this message is considered confidential and
 may be legally privileged. It is intended solely for the addressee. Access
 to this message by anyone else is unauthorized. If you are not the intended
 recipient, any disclosure, copying, or distribution of the message, or any
 action or omission taken by you in reliance on it, is prohibited and may be
 unlawful. Please immediately contact the sender if you have received this
 message in error.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 Obviously the explanation of the incident had to be consumed by the general public, however we encountered an unknown bug that was found which started the domino effect. Aside from this group, that level of detail wouldn't be understood by a majority of the recipients.
 With that said, please feel free to take this off list with Jason or Myself.
 Mike Dob
 Manager, Network Engineering
 -------- Original Message--------
 Subject:: Re: [outages] Godaddy / Premium DNS outage?
 From: ryanL <ryan.landry at gmail.com>
 Date: Oct 5, 2012 11:32 AM
 To:: "Jason LeBlanc" <jleblanc at godaddy.com>
 We encountered a new bug when we executed our change.
 -------- Original Message--------
 Subject:: Re: [outages] Godaddy / Premium DNS outage?
 From: ryanL <ryan.landry at gmail.com>
 Date: Oct 5, 2012 11:32 AM
 To:: "Jason LeBlanc" <jleblanc at godaddy.com>
 so, redistributed eBGP into IGP? how does one 210x their routing table? i
 appreciate the openness, but it doesn't sound like a "perfect storm" to me.
 it sounds like someone screwed up.
 On Fri, Oct 5, 2012 at 10:18 AM, Jason LeBlanc <jleblanc at godaddy.com> wrote:
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 Mike,
 My two cents here, anyone in Operations who does not understand that s$%t
 happens and that any company can be taken down by a set of circumstances
 that they were not prepared for either does not really "work" in Operations
 or is just harping on this to take a shot at GoDaddy. I have seen "perfect
 storm" circumstances that set off long term outages that no one could have
 predicted. I respect that fact that you spoke out on this list and
 appreciate  what you could share and based on past and present experience
 believe that your teams did a good the public announcement and your
 comments on this list.
 Thank You
 Tony Pasqualini
 Ops Director
 On Fri, Oct 5, 2012 at 11:49 AM, <mdob at godaddy.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/d52b49b0/attachment.html>
###############################################################
END
###############################################################

###############################################################
Call Centric Sip outage
###############################################################
 Call centric is reporting they are experiencing a DDOS style attack using
 the SIP protocol. My registrations are just timing out.
 There twitter is being updated: https://twitter.com/Callcentric They are
 also posting updates to customers when the log in. According to the first
 post regarding this issue on their twitter this is going on hour 17 or so.
 My logs for asterisk are just filling with registration time outs.
 Here is the latest update when I log into my account:
 *Investigation into current problems:*
 For the past two days we have been experiencing a sophisticated type of
 attack. As soon we noticed the first attempt we commenced an immediate
 physical upgrade to all of our servers increasing capacity and CPU power by
 a factor of four in addition to other precautions. Unfortunately even
 though this is similar to a "typical" DDoS attack it is targeted
 specifically at the SIP protocol and causes server load to increase to 100%
 within 1 minute of initiation. As such, standard and extraordinary
 prevention measures were unable to prevent it. We do not know the specific
 methodology of the attack but are aware that it is *similar* in effect to a
 DNS TRASH flood attack. We are performing forensic analysis on the data we
 have and are capturing traffic to find an exact reason and solution.
 We would like to clarify that there was no intrusion into our network and
 all of our servers switches and internet connections have been functioning
 *normally* throughout the entirety of this concern. None of our equipment
 or interlinks were disconnected or went down. Additionally please note that
 all of your information is encrypted, safe and secure; and that NO customer
 data was stolen NOR destroyed.
 We have experienced attempted *unsuccessful* attacks in the past and have
 made changes in real-time to stop them as well as to prevent future similar
 attacks. Many of our security documentation guidelines and features have
 been geared towards these changes. Unfortunately this is an entirely new
 type of attack, the mechanics of which are still coming to light.
 We sincerely apologize for the inconvenience this has caused. We are
 committed to further protecting our network and for this reason we will
 continue working with our engineers to implement a proper solution to
 provide a comprehensive resolution.
 If you have any questions/concerns regarding this message or if you need
 assistance in updating your configuration our Support Staff are available
 to answer your questions in as timely a manner as possible.
 Upon achieving a resolution, we will be providing as detailed an
 explanation as possible regarding this issue as well as the resolution.
 Again, we sincerely apologize for any inconvenience that you have
 experienced as a result of this matter and we appreciate your understanding
 during this process.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/20b0effd/attachment.html>
 On 10/05/2012 02:38 PM, Mitch wrote:
 They say in a later tweet that they posted "instructions" to customers regarding changes to make.  Have you seen anything like this on your dashboard?
  <506F42E9.7020802@netsville.com>
 Closest thing to instructions is what I pasted
 On Oct 5, 2012 4:30 PM, "Micah Brandon" <brandon at netsville.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/dcd3adc0/attachment.html>
  <506F42E9.7020802@netsville.com>
  <CAPC+kK5hyN5cyAnJV_s8URnsJo+Ocz_6vC7JyZpxoukaW4=K5g@mail.gmail.com>
 Ok, well new update while I was gone, not sure when they posted it:
 *Investigation into current problems:*
 Hello,
 For the past two days we have been experiencing a sophisticated type of
 attack. As soon we noticed the first attempt we commenced an immediate
 physical upgrade to all of our servers increasing capacity and CPU power by
 a factor of four in addition to other precautions. Unfortunately even
 though this is similar to a "typical" DDoS attack it is targeted
 specifically at the SIP protocol and causes server load to increase to 100%
 within 1 minute of initiation. As such, standard and extraordinary
 prevention measures were unable to prevent it. We do not know the specific
 methodology of the attack but are aware that it is *similar* in effect to a
 DNS TRASH flood attack. We are performing forensic analysis on the data we
 have and are capturing traffic to find an exact reason and solution.
 We would like to clarify that there was no intrusion into our network and
 all of our servers switches and internet connections have been functioning
 *normally* throughout the entirety of this concern. None of our equipment
 or interlinks were disconnected or went down. Additionally please note that
 all of your information is encrypted, safe and secure; and that NO customer
 data was stolen NOR destroyed.
 We have been working as aggressively as possible throughout the day/night
 and we have found a short term work-around which will provide immediate
 relief and allow calls to function normally. This will require updating
 your configuration slightly. Please re-configure your software/hardware
 with the following information:
 *UPDATED*
 Your registrar and Domain should remain as is:
 callcentric.com
 Outbound proxy:
 sip.callcentric.com - For clients *ONLY* able to use A records
 srv.callcentric.com - For clients able to use DNS SRV
 bypass.callcentric.com - For clients able to use DNS SRV
 *UPDATED*
 Asterisk users need the following:
 host = sip.callcentric.com OR srv.callcentric.com
 outboundproxy = sip.callcentric.com OR srv.callcentric
 register => 1777MYCCID:SUPERSECRET at sip.callcentric.com OR
 1777MYCCID:SUPERSECRET at srv.callcentric.com
 *UPDATED*
 3CX users need the following:
 Outbound proxy hostname or IP: sip.callcentric.com
 Outbound proxy port (default is 5060): 5060
 *UPDATED*
 PAP2/Linksys/Cisco users should be logged into their device in
 admin/advanced mode and use the following settings:
 Proxy - Enter callcentric.com in this field
 Outbound Proxy - Enter srv.callcentric.com in this field
 Use Outbound Proxy - yes
 Use DNS SRV - yes
 DNS SRV Auto Prefix - yes
 *UPDATED*
 Obihai users please make sure the following is configured:
 Service Providers > ITSP Profile > SIP
 ProxyServer: callcentric.com
 RegistrarServer: srv.callcentric.com
 UserAgentDomain: callcentric.com
 OutboundProxy: srv.callcentric.com
 X_ProxyServerRedundancy: Checked
 Please update this information as soon as possible to restore your calling
 ability and make sure to *REBOOT* or *RESTART* your device or software.
 We have experienced attempted *unsuccessful* attacks in the past and have
 made changes in real-time to stop them as well as to prevent future similar
 attacks. Many of our security documentation guidelines and features have
 been geared towards these changes. Unfortunately this is an entirely new
 type of attack, the mechanics of which are still coming to light.
 We sincerely apologize for the inconvenience this has caused. We are
 committed to further protecting our network and for this reason we will
 continue working with our engineers to implement a proper solution to
 provide a comprehensive resolution.
 If you have any questions/concerns regarding this message or if you need
 assistance in updating your configuration our Support Staff are available
 to answer your questions in as timely a manner as possible.
 Upon achieving a resolution, we will be providing as detailed an
 explanation as possible regarding this issue as well as the resolution.
 Again, we sincerely apologize for any inconvenience that you have
 experienced as a result of this matter and we appreciate your understanding
 during this process.
 On Fri, Oct 5, 2012 at 4:42 PM, Mitch <mitpatterson at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/476eeb05/attachment-0001.html>
  <506F42E9.7020802@netsville.com>
  <CAPC+kK5hyN5cyAnJV_s8URnsJo+Ocz_6vC7JyZpxoukaW4=K5g@mail.gmail.com>
  <CAPC+kK6keNmsSyUcOY+fxof-h9KfVBKhEjK85AmvSD4TUMJ9GA@mail.gmail.com>
  <CAPC+kK6H_9a00XLPOZOaqyFJ-TPxshA-xWDLzirU368nRm7XPg@mail.gmail.com>
 Well, that's just weak.  Let's publish information for some of our clients.  Yeah, the Internets will never find out...  However, they do appear to have a handle on things right now.  But the botnet is probably at reduced strength over the weekend.  They are going to have a serious case of the Mondays if they don't dial it up and get ahead of this thing.
 On 10/06/2012 12:25 PM, Mitch wrote:
  <506F42E9.7020802@netsville.com>
  <CAPC+kK5hyN5cyAnJV_s8URnsJo+Ocz_6vC7JyZpxoukaW4=K5g@mail.gmail.com>
  <CAPC+kK6keNmsSyUcOY+fxof-h9KfVBKhEjK85AmvSD4TUMJ9GA@mail.gmail.com>
  <CAPC+kK6H_9a00XLPOZOaqyFJ-TPxshA-xWDLzirU368nRm7XPg@mail.gmail.com>
  <5070B2F2.2010900@netsville.com>
 Latest update(I didn't bother pasting the whole thing):
 *Investigation into current problems:*
 Hello,
 *UPDATED 10/06 4:00 PM EST*
 The second attack against our new servers has been suppressed.
 sip.callcentric.com and srv.callcentric.com should provide better quality
 and functionality and they are being continually monitored. We are still
 committed to answering questions and will continue to provide as
 timely/detailed support as possible.
 With this in mind, we recommend subscribing/following our official Twitter
 page (http://www.twitter.com/Callcentric) as we will be posting updates and
 additional information as available.
 The original attack is still ongoing and we are returning to this issue in
 order to attempt to restore normal service across the board. This
 investigation process involves deep packet inspection and analysis to
 properly diagnose and prevent any other damage.
 We sincerely appreciate your patience with us and again apologize for the
 inconvenience.
 On Sat, Oct 6, 2012 at 6:38 PM, Micah Brandon <brandon at netsville.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121006/1338fb53/attachment.html>
###############################################################
END
###############################################################

###############################################################
clear.com website/authentication outage
###############################################################
 http://www.clear.com has been down for at least the last hour. They've also sent two emails during the last hour that my service with them has been disconnected due to a billing problem (they recently charged me, seemed to go through okay). One already connected device is still working okay, but my other device hangs trying to authenticate.
 If you're using Clear for connectivity, i'd suggest not disconnecting until they get this worked out. :)
 On Fri, Oct 5, 2012 at 2:11 PM, Kevin Day <toasty at dragondata.com> wrote:
 Customer service phone number is overloaded as well, and will disconnect
 after several seconds of being connected.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/fdba118d/attachment-0001.html>
 I got one of these emails(we can't bill you and have turned off your
 service), and I am an ex-customer( by over a year and half). I got through
 to the customer support line, and they mention that a large number of
 emails were sent out by mistake, and that there shouldn't be anything wrong
 with your account.
 On Fri, Oct 5, 2012 at 3:11 PM, Kevin Day <toasty at dragondata.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/072756b1/attachment.html>
 I haven't used their service in over two years and they've been sending out
 emails hourly about billing issues.  Their chat support line is currently
 slammed with people that I assume are having issues.
 On Fri, Oct 5, 2012 at 2:11 PM, Kevin Day <toasty at dragondata.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/9707f847/attachment.html>
 On Fri, Oct 5, 2012 at 1:11 PM, Kevin Day <toasty at dragondata.com> wrote:
 Oh the irony -- just got a marketing email from Clear saying "Are you
 missing your 4G Internet?"
 --Jaren
  <CAGkwwuPC5q2s5Zdz8FJW8Wz-r=1gbH5Gc4Qpw0eA2QwZfnjkaw@mail.gmail.com>
 Check:  http://wimaxsatx.com/?p=1631
 On 10/05/2012 01:43 PM, Jaren Angerbauer wrote:
  <CAGkwwuPC5q2s5Zdz8FJW8Wz-r=1gbH5Gc4Qpw0eA2QwZfnjkaw@mail.gmail.com>
  <506F3FA2.5090301@axint.net>
 And the irony continues.  I opened a Clear account back in 2010 and
 closed it after one month.  Since closing it, I haven't receive any
 emails at all (marketing or account related) until now - TWO YEARS
 LATER, and for an account closed for that period.  Clearly a mess up
 on Clear's side on multiple levels.
 --Jaren
 On Fri, Oct 5, 2012 at 2:14 PM, Chris Stone <cstone at axint.net> wrote:
 >>>
 >>> http://www.clear.com has been down for at least the last hour. They've
 >>> also sent two emails during the last hour that my service with them has been
 >>> disconnected due to a billing problem (they recently charged me, seemed to
 >>> go through okay). One already connected device is still working okay, but my
 >>> other device hangs trying to authenticate.
###############################################################
END
###############################################################

###############################################################
Level3 IPv4 and IPv6 sessions bouncing in Denver, CO
###############################################################
 Seeing my Level3 BGP sessions bouncing since 15:13:48 MDT and tracing in 
 from a CenturyLink circuit, dies with lots of packetloss on the 2nd to last 
 hop. Have ticket open with Level3 - waiting to hear something back.
 HOST: orion.axint.net             Loss%   Snt   Last   Avg  Best Wrst StDev
    1.|-- 10.10.100.1                0.0%    50    0.5   0.5   0.4 0.7   0.0
    2.|-- 207.225.112.1              0.0%    50   41.0  50.0  39.4 181.7  27.6
    3.|-- 71.217.188.1               0.0%    50   39.9  41.5  39.3 87.4   6.8
    4.|-- 67.14.24.118               0.0%    50   40.7  44.4  39.7 100.5  12.0
    5.|-- 63.146.26.134              0.0%    50   59.6  60.8  58.7 92.8   5.3
    6.|-- 4.69.147.67               86.0%    50   84.2 277.0  73.0 1084. 366.3
    7.|-- ???                       100.0    50    0.0   0.0   0.0 0.0   0.0
 Anyone else seeing L3 problems in Denver?
 Chris
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/7b3000a3/attachment.html>
 I've not been able to access ipv6.level3.com since 4:11 pm Central . gets
 stuck in Kansas
 nagios:/home/fbulk# tcptraceroute6 ipv6.level3.com
 traceroute to ipv6.test.Level3.com (2001:1900:2018:3000::105) from xxxxxxx,
 port 80, from port 43472, 30 hops max, 60 bytes packets
 1  router-core.mtcnet.net (2607:fe28:0:1000::1)  0.328 ms  0.302 ms  0.254
 ms
 2  sxct.sxcy.mtcnet.net (2607:fe28:11:1002::197)  0.312 ms  0.131 ms  0.105
 ms
 3  v6-premier.sxcy-mlx.fbnt.netins.net (2001:5f8:7f0a:2::1)  5.529 ms  5.545
 ms  5.478 ms
 4  v6-ins-db1-te-13-2-219.desm.netins.net (2001:5f8:1:1::1)  9.515 ms
 10.254 ms  9.524 ms
 5  v6-ins-dc1-et-8-2.desm.netins.net (2001:5f8::1:1)  10.914 ms  11.119 ms
 10.884 ms
 6  te-3-3.car2.KansasCity1.Level3.net (2001:1900:2100::e2d)  17.358 ms
 17.101 ms  17.128 ms
 7  * * *
 8  * * *
 9  * * *
 Frank
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Chris Stone
 Sent: Friday, October 05, 2012 5:08 PM
 Seeing my Level3 BGP sessions bouncing since 15:13:48 MDT and tracing in
 from a CenturyLink circuit, dies with lots of packetloss on the 2nd to last
 hop. Have ticket open with Level3 - waiting to hear something back.
 HOST: orion.axint.net             Loss%   Snt   Last   Avg  Best  Wrst StDev
   1.|-- 10.10.100.1                0.0%    50    0.5   0.5   0.4   0.7   0.0
   2.|-- 207.225.112.1              0.0%    50   41.0  50.0  39.4 181.7  27.6
   3.|-- 71.217.188.1               0.0%    50   39.9  41.5  39.3  87.4   6.8
   4.|-- 67.14.24.118               0.0%    50   40.7  44.4  39.7 100.5  12.0
   5.|-- 63.146.26.134              0.0%    50   59.6  60.8  58.7  92.8   5.3
   6.|-- 4.69.147.67               86.0%    50   84.2 277.0  73.0 1084. 366.3
   7.|-- ???                       100.0    50    0.0   0.0   0.0   0.0   0.0
 Anyone else seeing L3 problems in Denver?
 Chris
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/274e4d12/attachment.html>
  <000501cda348$ff8f0bf0$fead23d0$@iname.com>
 Access to ipv6.level3.com came up minutes after I sent the message, at 5:32
 pm Central.
 >From the complete trace I see that the next hop after Kansas City is Denver.
 nagios:/home/fbulk# tcptraceroute6 ipv6.level3.com
 traceroute to ipv6.test.Level3.com (2001:1900:2018:3000::105) from
 xxxxxxxxx, port 80, from port 39309, 30 hops max, 60 bytes packets
 1  router-core.mtcnet.net (2607:fe28:0:1000::1)  0.253 ms  0.317 ms  0.192
 ms
 2  sxct.sxcy.mtcnet.net (2607:fe28:11:1002::197)  0.192 ms  0.139 ms  0.135
 ms
 3  v6-premier.sxcy-mlx.fbnt.netins.net (2001:5f8:7f0a:2::1)  5.526 ms  5.508
 ms  5.488 ms
 4  v6-ins-db1-te-13-2-219.desm.netins.net (2001:5f8:1:1::1)  9.829 ms  9.606
 ms  9.635 ms
 5  v6-ins-dc1-et-8-2.desm.netins.net (2001:5f8::1:1)  10.934 ms  10.868 ms
 10.864 ms
 6  te-3-3.car2.KansasCity1.Level3.net (2001:1900:2100::e2d)  17.140 ms
 17.085 ms  17.168 ms
 7  vl-4062.car2.Denver1.Level3.net (2001:1900:4:1::382)  30.076 ms  30.091
 ms  30.036 ms
 8  vl-51.car1.Denver1.Level3.net (2001:1900:13:1::3)  35.225 ms  39.585 ms
 30.033 ms
 9  Level3-MOSS.vl-956.car1.Denver1.Level3.net (2001:1900:4:2::fa)  30.552 ms
 30.699 ms  30.779 ms
 10  2001:1900:2018:f000:1:0:1:202 (2001:1900:2018:f000:1:0:1:202)  31.697 ms
 31.685 ms  31.453 ms
 11  ipv6.test.Level3.com (2001:1900:2018:3000::105)  32.317 ms [open]
 32.400 ms  31.888 ms
 nagios:/home/fbulk#
 Frank
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Frank Bulk
 Sent: Friday, October 05, 2012 5:30 PM
 I've not been able to access ipv6.level3.com since 4:11 pm Central . gets
 stuck in Kansas
 nagios:/home/fbulk# tcptraceroute6 ipv6.level3.com
 traceroute to ipv6.test.Level3.com (2001:1900:2018:3000::105) from xxxxxxx,
 port 80, from port 43472, 30 hops max, 60 bytes packets
 1  router-core.mtcnet.net (2607:fe28:0:1000::1)  0.328 ms  0.302 ms  0.254
 ms
 2  sxct.sxcy.mtcnet.net (2607:fe28:11:1002::197)  0.312 ms  0.131 ms  0.105
 ms
 3  v6-premier.sxcy-mlx.fbnt.netins.net (2001:5f8:7f0a:2::1)  5.529 ms  5.545
 ms  5.478 ms
 4  v6-ins-db1-te-13-2-219.desm.netins.net (2001:5f8:1:1::1)  9.515 ms
 10.254 ms  9.524 ms
 5  v6-ins-dc1-et-8-2.desm.netins.net (2001:5f8::1:1)  10.914 ms  11.119 ms
 10.884 ms
 6  te-3-3.car2.KansasCity1.Level3.net (2001:1900:2100::e2d)  17.358 ms
 17.101 ms  17.128 ms
 7  * * *
 8  * * *
 9  * * *
 Frank
 From: outages-bounces at outages.org <mailto:outages-bounces at outages.org>
 [mailto:outages-bounces at outages.org] On Behalf Of Chris Stone
 Sent: Friday, October 05, 2012 5:08 PM
 Seeing my Level3 BGP sessions bouncing since 15:13:48 MDT and tracing in
 from a CenturyLink circuit, dies with lots of packetloss on the 2nd to last
 hop. Have ticket open with Level3 - waiting to hear something back.
 HOST: orion.axint.net             Loss%   Snt   Last   Avg  Best  Wrst StDev
   1.|-- 10.10.100.1                0.0%    50    0.5   0.5   0.4   0.7   0.0
   2.|-- 207.225.112.1              0.0%    50   41.0  50.0  39.4 181.7  27.6
   3.|-- 71.217.188.1               0.0%    50   39.9  41.5  39.3  87.4   6.8
   4.|-- 67.14.24.118               0.0%    50   40.7  44.4  39.7 100.5  12.0
   5.|-- 63.146.26.134              0.0%    50   59.6  60.8  58.7  92.8   5.3
   6.|-- 4.69.147.67               86.0%    50   84.2 277.0  73.0 1084. 366.3
   7.|-- ???                       100.0    50    0.0   0.0   0.0   0.0   0.0
 Anyone else seeing L3 problems in Denver?
 Chris
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/24f00bc5/attachment-0001.html>
###############################################################
END
###############################################################

###############################################################
Level3 problems in Denver
###############################################################
 Master ticket information:
 Network Event Summary: 	A router issue in Denver, CO is affecting IP services.
 Event Ticket ID: 	5990581
 Market Area Affected: 	Denver, CO
 Ticket Create Date: 	10/5/12 9:52:52 PM GMT
 Impacted For: 	*1 hour 24 minutes*
 Event Status: 	Active
 Resolve Date: 	
 Time Since Last Update: 	*27 minutes*
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121005/50e5661f/attachment.html>
###############################################################
END
###############################################################

###############################################################
Froniter/Paetec(Windstream) Indiana fiber cut
###############################################################
 Just got off the phone with our CLEC for 2 sites there with Bonded T1's and
 they said the ILEC(Frontier) has a massive fiber cut in the area.
 CLEC told me they are in the process of opening a Master TT with them to
 get more info.
 These sites are in *Kokomo IN*
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121006/7e64f9df/attachment.html>
###############################################################
END
###############################################################

###############################################################
DSL/Broadband reports down?? Again?
###############################################################
 I'm getting the following error: 504 Gateway Time-out
 ------------------------------
 nginx
 Down for everyoneorjustme is reporting its down as well:It's not just you!
 http://www.dslreports.com looks down from here.
 Their twitter doesn't report anything right now:
 https://twitter.com/DSLReports
 Can anyone else confirm?
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121006/1a56a5a4/attachment.html>
 Confirmed; it's been down for a while now.
 I'm sure Karl and nil will be doing something about it, if they aren't
 already engaged and working the issue.  It sounds like something on the
 back-end may have crashed/broke.  I'm certain Karl will disclose details
 on the site once it's back up.
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
 On Sat, Oct 06, 2012 at 12:30:30PM -0400, Mitch wrote:
 On 10/6/2012 9:30 AM, Mitch wrote:
 Confirmed.  I'm on the US West Coast, tried from my Covad/Megapath home 
 connection, as well as our Cogent and Charter links at the office.
 -Bobby
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121006/9e95ed0f/attachment.html>
###############################################################
END
###############################################################

###############################################################
Sprint Outage?
###############################################################
 Is anyone having a Sprint WAN outage as of 9:30 AM?  Can anyone
 provide anymore information on this?  Their support line is being
 hammered.
 Yup, I've gotten reports from multiple cities around the Twin Cities, MN area. (Internet on Cell phones)
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Mike McRill
 Sent: Monday, October 08, 2012 10:00 AM
 Is anyone having a Sprint WAN outage as of 9:30 AM?  Can anyone provide anymore information on this?  Their support line is being hammered.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 Yes, major issues in Green Bay, WI. After waiting on hold for 25 minutes, we are being told multiple DS3's are affected. The information we received from Sprint is a fiber cut in Portland, OR and Kenosha, WI.
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Mike McRill
 Sent: Monday, October 08, 2012 10:00 AM
 Is anyone having a Sprint WAN outage as of 9:30 AM?  Can anyone
 provide anymore information on this?  Their support line is being
 hammered.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <E59273FEF713494087092911E9E8F751DA620ABF87@LO-Exchange.LOGIS.ORG>
 I have a virgin mobile cell phone that runs on the sprint network and it is
 working fine in the Toledo Ohio area.
 On Mon, Oct 8, 2012 at 11:34 AM, Justin Maloney <jmaloney at logis.org> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121008/22a9ba4b/attachment.html>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 On 10/08/2012 08:00 AM, Mike McRill wrote:
 - -------------------
 I have a vague report about sprint issue (?) in boston area...waiting
 for more information.
 regards,
 /virendra
  <EBB44338F636BC48B525CA28E49254B41B1C9C0A@CH1PRD0810MB395.namprd08.prod.outlook.com>
 I heard a railroad company cut fiber between IL and WI.  They said its
 an all day outage, they had a digging crew starting to trench at
 around 10:20 AM CST
 On Oct 8, 2012, at 10:37 AM, Aaron Schroeder <aaron at schroederwi.com> wrote:
 On 10/8/12 8:00 AM, Mike McRill wrote:
 My Sprint circuits in Nevada are working. I'm trying to log in to
 sprint.net to see if there is a master issue but it's being
 exceptionally slow.
 ~Seth
  <E59273FEF713494087092911E9E8F751DA620ABF87@LO-Exchange.LOGIS.ORG>
 We are getting multiple reports of data not working for several police departments we support in the Twin Cities also.
 Mark Mayfield
 City of Roseville
 Network Systems Engineer
 Roseville, MN 55113
 651-792-7098    Office
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Justin Maloney
 Sent: Monday, October 08, 2012 10:35 AM
 Yup, I've gotten reports from multiple cities around the Twin Cities, MN area. (Internet on Cell phones)
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Mike McRill
 Sent: Monday, October 08, 2012 10:00 AM
 Is anyone having a Sprint WAN outage as of 9:30 AM?  Can anyone provide anymore information on this?  Their support line is being hammered.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 Confidentiality Statement: The documents accompanying this transmission contain confidential information that is legally privileged.  This information is intended only for the use of the individuals or entities listed above.  If you are not the intended recipient, you are hereby notified that any disclosure, copying, distribution, or action taken in reliance on the contents of these documents is strictly prohibited.  If you have received this information in error, please notify the sender immediately and arrange for the return or destruction of these documents.
  <EBB44338F636BC48B525CA28E49254B41B1C9C0A@CH1PRD0810MB395.namprd08.prod.outlook.com>
  <1323013283569741945@unknownmsgid>
 I've heard reports of 90 DS3 circuits affected, with the majority being
 in the northwest U.S.
 Anyone else have any details?
 Thanks,
 Bill
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org]
 On Behalf Of Mike McRill
 Sent: Monday, October 08, 2012 10:39 AM
 Cc: outages at outages.org
 I heard a railroad company cut fiber between IL and WI.  They said its
 an all day outage, they had a digging crew starting to trench at around
 10:20 AM CST
 On Oct 8, 2012, at 10:37 AM, Aaron Schroeder <aaron at schroederwi.com>
 wrote:
 minutes, we are being told multiple DS3's are affected. The information
 we received from Sprint is a fiber cut in Portland, OR and Kenosha, WI.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <EBB44338F636BC48B525CA28E49254B41B1C9C0A@CH1PRD0810MB395.namprd08.prod.outlook.com>
  <1323013283569741945@unknownmsgid>
  <972EE2ECC5BFF44CA991510B8EDA469C10325C2F@S4USJVSYAIC.ts-na.t-systems.com>
 There are Verizon outages in various Wisconsin service areas conincidental 
 with the timing of the Sprint DS3 outages.
 Former Alltel service areas in Waupaca and New London confirmed, possibly 
 others.
 On Mon, 8 Oct 2012, Bill.Ingrum at t-systems.com wrote:
 What we're seeing from central florida is connectivity to a few select 
 major content providers (...google) via sprint being troublesome....
 --
 david raistrick        http://www.netmeister.org/news/learn2quote.html
 drais at icantclick.org       ascii ribbon campaign - stop html mail
                                  http://www.asciiribbon.org/
 Looks like the fiber theory was correct
 http://www.alaskaair.com/content/travel-info/before-your-trip/travel-tips/travel-advisories.aspx
 At 7:30 a.m. PST, Sprint, Alaska Airlines' Internet provider, went down
 On Mon, Oct 8, 2012 at 8:00 AM, Mike McRill <mikemcrill at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121008/2d8a0d3b/attachment.html>
  <EBB44338F636BC48B525CA28E49254B41B1C9C0A@CH1PRD0810MB395.namprd08.prod.outlook.com>
  <1323013283569741945@unknownmsgid>
  <972EE2ECC5BFF44CA991510B8EDA469C10325C2F@S4USJVSYAIC.ts-na.t-systems.com>
  <alpine.LRH.2.02.1210081147160.13661@mailman.thedacare.org>
 Updates from our Sprint rep.
 Milwaukee, WI fiber cut
 Cable splicing has started on one side of the trench and it will be at
 least 4 more hours before they get to the other side of the trench.
 Seattle, WA fiber cut
 Tech dispatch 17:10 Zulu and pending updates at this time.
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org]
 On Behalf Of outages at mailman.thedacare.org
 Sent: Monday, October 08, 2012 11:50 AM
 There are Verizon outages in various Wisconsin service areas
 conincidental with the timing of the Sprint DS3 outages.
 Former Alltel service areas in Waupaca and New London confirmed,
 possibly others.
 On Mon, 8 Oct 2012, Bill.Ingrum at t-systems.com wrote:
 Kenosha, WI.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <CAO3ab4SdE7onaOfNxcj_QdEZ4X97eNCHbis9ihaZPx4uzm7yTw@mail.gmail.com>
 Alaska Air is really not multihomed?
 "Question everything, assume nothing, discuss all, and resolve quickly."
 -- Alex Rubenstein, AR97, K2AHR, alex at nac.net<mailto:alex at nac.net>, latency, Al Reuben --
 --    Net Access Corporation, 800-NET-ME-36, http://www.nac.net   --
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Levi Jennings
 Sent: Monday, October 08, 2012 2:12 PM
 Looks like the fiber theory was correct
 http://www.alaskaair.com/content/travel-info/before-your-trip/travel-tips/travel-advisories.aspx
 At 7:30 a.m. PST, Sprint, Alaska Airlines' Internet provider, went down after a fiber network cable was cut in Wisconsin. Sprint provides the airline with connectivity to SABRE, the system used for reservations, check-in and to purchase tickets. The outage is preventing customers from checking in and has caused significant systemwide delays in all cities Alaska Airlines serves.
 On Mon, Oct 8, 2012 at 8:00 AM, Mike McRill <mikemcrill at gmail.com<mailto:mikemcrill at gmail.com>> wrote:
 Is anyone having a Sprint WAN outage as of 9:30 AM?  Can anyone
 provide anymore information on this?  Their support line is being
 hammered.
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121008/7f6ea0a2/attachment-0001.html>
  <CAO3ab4SdE7onaOfNxcj_QdEZ4X97eNCHbis9ihaZPx4uzm7yTw@mail.gmail.com>
  <2D0AF14BA6FB334988BC1F5D4FC38CB81ACFE25357@EXCHMBX.hq.nac.net>
 http://www.alaskaair.com/content/travel-info/before-your-trip/travel-tips/travel-advisories.aspx
 lol?
 On Mon, Oct 8, 2012 at 2:26 PM, Alex Rubenstein <alex at corp.nac.net> wrote:
  <EBB44338F636BC48B525CA28E49254B41B1C9C0A@CH1PRD0810MB395.namprd08.prod.outlook.com>
  <1323013283569741945@unknownmsgid>
  <972EE2ECC5BFF44CA991510B8EDA469C10325C2F@S4USJVSYAIC.ts-na.t-systems.com>
  <alpine.LRH.2.02.1210081147160.13661@mailman.thedacare.org>
  <972EE2ECC5BFF44CA991510B8EDA469C10325DE5@S4USJVSYAIC.ts-na.t-systems.com>
 Looks like the Seattle, WA cut was between Tacoma and Portland:
 http://www.dispatch.com/content/stories/business/2012/10/09/sprint-service-o
 utage-also-affects-alaska-airlines.html
 Frank
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Bill.Ingrum at t-systems.com
 Sent: Monday, October 08, 2012 1:43 PM
 Updates from our Sprint rep.
 Milwaukee, WI fiber cut
 Cable splicing has started on one side of the trench and it will be at
 least 4 more hours before they get to the other side of the trench.
 Seattle, WA fiber cut
 Tech dispatch 17:10 Zulu and pending updates at this time.
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org]
 On Behalf Of outages at mailman.thedacare.org
 Sent: Monday, October 08, 2012 11:50 AM
 There are Verizon outages in various Wisconsin service areas
 conincidental with the timing of the Sprint DS3 outages.
 Former Alltel service areas in Waupaca and New London confirmed,
 possibly others.
 On Mon, 8 Oct 2012, Bill.Ingrum at t-systems.com wrote:
 Kenosha, WI.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 I can 100% confirm the Alaska air delays. Here at seatac airport with current delays of 2-3 hours they say. And they might cancel flights this afternoon. Which I am currently waiting for a connecting flight that was to leave at 2:00 pm pdt to DC(REAGAN)
 As I type this 3 flights to San diego and LA area were cancelled. And now they just said the system looks to be up. So there may be hope!
 Mark
 ----- Original Message -----
 From: Levi Jennings <levithedegu at gmail.com>
 Sent: Mon, 08 Oct 2012 11:12:16 -0700 (PDT)
 Looks like the fiber theory was correct
 http://www.alaskaair.com/content/travel-info/before-your-trip/travel-tips/travel-advisories.aspx
 At 7:30 a.m. PST, Sprint, Alaska Airlines' Internet provider, went down
 On Mon, Oct 8, 2012 at 8:00 AM, Mike McRill <mikemcrill at gmail.com> wrote:
###############################################################
END
###############################################################

###############################################################
TW Ohio area
###############################################################
 Hello all,
 Any of you in the ohio area been seeing downtime at night lately? Woke up
 to the cable modem being disconnected 3 nights in a row throwing my tunnel
 broker for a loop
 Thanks
 Brian
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121009/8e492b5c/attachment.html>
 None of the fiber or cable connections have any issues in south west Ohio.
  Assuming TWC not TWT.
 One cable connection in one area having issues every night sounds like a
 last mile issue, not regional at all.
 Josh Luthman
 Office: 937-552-2340
 Direct: 937-552-2343
 1100 Wayne St
 Suite 1337
 Troy, OH 45373
 On Tue, Oct 9, 2012 at 10:01 PM, Brian Henson <marine64 at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121009/c47c55ee/attachment.html>
###############################################################
END
###############################################################

###############################################################
Centurylink MPLS outage in Indianapolis
###############################################################
 We are experiencing an outage on our MPLS circuit in Indianapolis.  Is
 anyone else experiencing this?  We have been told it is part of a bigger
 issue with no ETR.
 Regards,
 John Murphy
 Network Engineer
 ExactTarget
 At least person on Twitter is reporting something very similar:
 https://twitter.com/indygwyn/status/255819891083464705
 Frank
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of John Murphy
 Sent: Tuesday, October 09, 2012 7:41 PM
 We are experiencing an outage on our MPLS circuit in Indianapolis.  Is
 anyone else experiencing this?  We have been told it is part of a bigger
 issue with no ETR.
 Regards,
 John Murphy
 Network Engineer
 ExactTarget
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <000601cda697$5e0cebb0$1a26c310$@iname.com>
 Thanks Frank. 
 Our circuit is back up. I'm still waiting for the final RFO. 
 Regards,
 John Murphy
 On Oct 9, 2012, at 11:28 PM, "Frank Bulk" <frnkblk at iname.com> wrote:
 Here is the RFO.
 http://www.telecomramblings.com/2012/10/dual-cable-cuts-take-down-sprint-in
 -the-northwest 
 JS
 On 10/9/12 10:44 PM, "John Murphy" <john.murphy at exacttarget.com> wrote:
 >Thanks Frank. 
 >Our circuit is back up. I'm still waiting for the final RFO.
 >Regards,
 >John Murphy
 >On Oct 9, 2012, at 11:28 PM, "Frank Bulk" <frnkblk at iname.com> wrote:
 >>On
 >_______________________________________________
 >Outages mailing list
 >Outages at outages.org
 >https://puck.nether.net/mailman/listinfo/outages
 Joe,
 You have the wrong outage. What you are thinking about is what took place on the 8th in Oregon. What this outage was for is this
 Outage occurred starting at 10amEST Oct 9th in Indy due to a fiber cut of an OC12 in AT&T territory. This was repaired at 3:30pm EST Oct 9th.
 On Oct 10, 2012, at 12:29 AM, Joe Sanchez <marco207p at gmail.com> wrote:
 >>> At least person on Twitter is reporting something very similar:
 >>> https://twitter.com/indygwyn/status/255819891083464705
 >>> 
 >>> Frank
 >>> 
 >>> -----Original Message-----
 >>> From: outages-bounces at outages.org [mailto:outages-bounces at outages.org]
 >>> On
 >>> Behalf Of John Murphy
 >>> Sent: Tuesday, October 09, 2012 7:41 PM
 >>> To: outages at outages.org
 >>> Subject: [outages] Centurylink MPLS outage in Indianapolis
 >>> 
 >>> We are experiencing an outage on our MPLS circuit in Indianapolis.  Is
 >>> anyone else experiencing this?  We have been told it is part of a bigger
 >>> issue with no ETR.
 >>> 
 >>> Regards,
 >>> 
 >>> John Murphy
 >>> Network Engineer
 >>> ExactTarget
 >>> 
 >>> 
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 >>> 
 >>> 
 >>> 
  <787DF58C-7108-438B-9B6C-1045196C4CE7@digitalrage.org>
 My apologies. 
 Regards,
  Joe Sanchez
 ( please excuse the brevity of this email as it was sent via a mobile device.  Please excuse misspelled words or sentence structure.) 
 On Oct 10, 2012, at 1:01 AM, Elijah Savage <esavage at digitalrage.org> wrote:
 >>> Thanks Frank. 
 >>> 
 >>> Our circuit is back up. I'm still waiting for the final RFO.
 >>> 
 >>> Regards,
 >>> 
 >>> John Murphy
 >>> 
 >>> 
 >>> On Oct 9, 2012, at 11:28 PM, "Frank Bulk" <frnkblk at iname.com> wrote:
 >>> 
 >>>> At least person on Twitter is reporting something very similar:
 >>>> https://twitter.com/indygwyn/status/255819891083464705
 >>>> 
 >>>> Frank
 >>>> 
 >>>> -----Original Message-----
 >>>> From: outages-bounces at outages.org [mailto:outages-bounces at outages.org]
 >>>> On
 >>>> Behalf Of John Murphy
 >>>> Sent: Tuesday, October 09, 2012 7:41 PM
 >>>> To: outages at outages.org
 >>>> Subject: [outages] Centurylink MPLS outage in Indianapolis
 >>>> 
 >>>> We are experiencing an outage on our MPLS circuit in Indianapolis.  Is
 >>>> anyone else experiencing this?  We have been told it is part of a bigger
 >>>> issue with no ETR.
 >>>> 
 >>>> Regards,
 >>>> 
 >>>> John Murphy
 >>>> Network Engineer
 >>>> ExactTarget
 >>>> 
 >>>> 
 >>>> _______________________________________________
 >>>> Outages mailing list
 >>>> Outages at outages.org
 >>>> https://puck.nether.net/mailman/listinfo/outages
 >>> 
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
###############################################################
END
###############################################################

###############################################################
Ubiquity Hosting
###############################################################
 Don't know how many people are using managed dedicated servers, but:
 As of about 14:40 EDT today, servers are unavailable, the website is
 not functioning correctly, and nobody seems to be answering the phone.
 -Mike Fiedler
 Update:
 Services seem to be restored. They responded to my tweet[0] that
 service has been restored, and indeed the servers have never been
 rebooted, etc.
 I suspect that this has something to do with their new website launch
 today[1] - further evidenced with the fact that the new site is no
 longer up, the old one is there instead.
 -Mike
 [0]: https://twitter.com/UbiquityServers/status/256115412419362816
 [1]: https://twitter.com/UbiquityServers/status/256040872280461312
 On Wed, Oct 10, 2012 at 3:33 PM, Mike <miketheman at gmail.com> wrote:
 I'm able to bring up the site, http://www.ubiquityhosting.com/.
 ----- Original Message -----
 From: "Mike" <miketheman at gmail.com>
 Sent: Wednesday, October 10, 2012 12:33:56 PM
 Don't know how many people are using managed dedicated servers, but:
 As of about 14:40 EDT today, servers are unavailable, the website is
 not functioning correctly, and nobody seems to be answering the phone.
 -Mike Fiedler
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
###############################################################
END
###############################################################

###############################################################
Cogent packet loss and jitter
###############################################################
 Unfortunately one of our critical destinations is now advertising a route
 through Cogent, and they are having some problems it seems.  Anyone else?
 --- 66.62.162.31 ping statistics ---
 62 packets transmitted, 40 received, 35% packet loss, time 61016ms
 rtt min/avg/max/mdev = 53.803/57.115/62.127/1.730 ms
 This is at the same time that latency to the last router before cogent is
 perfect (1.7-1.9ms).
 Relevant route:
  3  204.15.220.81 (204.15.220.81)  1.268 ms  1.303 ms  1.289 ms
  4  gi3-12.na41.b022559-0.phx02.atlas.cogentco.com (38.122.88.13)  1.497 ms
  1.881 ms  1.889 ms
  5  vl3810.mag02.phx02.atlas.cogentco.com (66.28.64.209)  12.983 ms  12.979
 ms  12.964 ms
  6  * te7-4.ccr01.phx02.atlas.cogentco.com (154.54.85.85)  195.832 ms *
  7  te0-1-0-7.ccr22.lax01.atlas.cogentco.com (154.54.80.205)  13.472 ms
 te0-3-0-0.mpd22.lax01.atlas.cogentco.com (154.54.29.25)  12.875 ms
 te0-1-0-7.ccr22.lax01.atlas.cogentco.com (154.54.80.205)  13.028 ms
  8  te3-4.ccr02.lax05.atlas.cogentco.com (154.54.3.10)  151.705 ms
 te9-8.ccr02.lax05.atlas.cogentco.com (154.54.44.134)  151.715 ms
 te4-8.ccr02.lax05.atlas.cogentco.com (154.54.30.194)  151.691 ms
  9  xe-1-2-1.mpr1.lax12.us.above.net (64.125.13.169)  23.115 ms  23.105 ms
  23.090 ms
 10  xe-3-0-0.cr1.lax112.us.above.net (64.125.30.17)  13.148 ms  13.090 ms
  13.117 ms
 11  xe-0-2-0.cr1.sjc2.us.above.net (64.125.26.26)  21.132 ms  21.585 ms
  20.958 ms
 12  xe-1-0-1.mpr1.den1.us.above.net (64.125.30.133)  50.248 ms  50.045 ms
  50.001 ms
 13   (208.185.20.58)  50.859 ms  55.178 ms  55.035 ms
 -- 
 Carlos Alvarez
 TelEvolve
 602-889-3003
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121010/8452a8d4/attachment.html>
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
 On Wed, Oct 10, 2012 at 6:23 PM, Brent Jones <brent at brentrjones.com> wrote:
 This right here is frustrating, since they are in the same city and same
 network:
  5  vl3810.mag02.phx02.atlas.cogentco.com (66.28.64.209)  12.983 ms  12.979
 ms  12.964 ms
  6  * te7-4.ccr01.phx02.atlas.cogentco.com (154.54.85.85)  195.832 ms *
 As you might imagine, we have a lot of complaints.
 -- 
 Carlos Alvarez
 TelEvolve
 602-889-3003
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121010/0dc82978/attachment.html>
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
 Carlos,
 How about a return-path traceroute?  The ingress interface may be (and
 probably is) different than the egress.
 It would also help if you could provide source *and* destination IPs of
 the traceroutes.
 Details:
 http://www.nanog.org/meetings/nanog47/presentations/Sunday/RAS_Traceroute_N47_Sun.pdf
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
 On Wed, Oct 10, 2012 at 06:30:04PM -0700, Carlos Alvarez wrote:
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
  <20121011013708.GA29706@icarus.home.lan>
 On Wed, Oct 10, 2012 at 6:37 PM, Jeremy Chadwick <jdc at koitsu.org> wrote:
 I don't have access to that device.  No response from them yet.
 208.86.121.129 to 66.62.162.31
 -- 
 Carlos Alvarez
 TelEvolve
 602-889-3003
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121010/32efb105/attachment.html>
 I saw packet loss on Cogent today as well.
 We have a Boston and NYC site, both saw high latency and some packet
 loss to almost all destination (even to other Cogent on-net POPs)
 It seems to have settled down, but I have not gotten a response to
 support requests.
 On Wed, Oct 10, 2012 at 6:16 PM, Carlos Alvarez <carlos at televolve.com> wrote:
 -- 
 Brent Jones
 brent at brentrjones.com
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
 I take it back, still seeing high latency, and very poor transfer
 performance  :(
 38.122.252.185 to 154.54.0.89 (BOS to PDX, Cogent on-net POPs),
 spiking to 150ms latency.
 On Wed, Oct 10, 2012 at 6:30 PM, Carlos Alvarez <carlos at televolve.com> wrote:
 -- 
 Brent Jones
 brent at brentrjones.com
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
  <CAOC=LuUJOV=-chL0iDz8vMvgO=6Ms63F+rFqbBLC3XmSb8s-5A@mail.gmail.com>
 Internet health report report latency between cogent and Level 3
 http://www.internetpulse.net/
 Ujjval K
 On Oct 10, 2012, at 8:10 PM, Brent Jones <brent at brentrjones.com> wrote:
 >>> 
 >>> (even to other Cogent on-net POPs)
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121010/56eec394/attachment.html>
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
 The latency at hop 6 isn't necessarily related to the end-to-end problem
 (as pointed out in the slides Jeremy sent)- it's not carrying through to
 any later hops, so it could just be a bad asymmetric reverse path from that
 particular router or that router being slow on traceroute responses. That
 hop is perfectly responsive when I ping it from a variety of locations,
 even if the responses are sometimes slow.
 The latency to hop 10 (after Cogent) is about the same as the latency to
 hop 5 (inside Cogent), and the latency doesn't really go up until the hop
 in Denver (when suddenly you have a much longer path). None of my comments
 say anything about the loss, however.
 On Wed, Oct 10, 2012 at 6:30 PM, Carlos Alvarez <carlos at televolve.com>wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121010/f77cef66/attachment.html>
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
  <CAOC=LuUJOV=-chL0iDz8vMvgO=6Ms63F+rFqbBLC3XmSb8s-5A@mail.gmail.com>
 Just a thought have you both ruled out ICMP priortization? Cogent does
 this...
 Also, have you called or just submitted a ticket?
 Everytime, I've opened a ticket....I've gotten a response rather quickly
 and for sure when I call.
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org]
 On Behalf Of Brent Jones
 Sent: Wednesday, October 10, 2012 9:10 PM
 Cc: outages at outages.org
 I take it back, still seeing high latency, and very poor transfer
 performance  :(
 38.122.252.185 to 154.54.0.89 (BOS to PDX, Cogent on-net POPs), spiking
 to 150ms latency.
 On Wed, Oct 10, 2012 at 6:30 PM, Carlos Alvarez <carlos at televolve.com>
 wrote:
 wrote:
 --
 Brent Jones
 brent at brentrjones.com
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
  <CAOC=LuUJOV=-chL0iDz8vMvgO=6Ms63F+rFqbBLC3XmSb8s-5A@mail.gmail.com>
  <5FE1FB6D43B8A647BBC821840C1AEA8B017E78@ocsbs.ocosa.com>
 Sorry Otis for a double response, I hit reply to on accident (getting
 tired).
 I noticed a lot of latency and failure to establish connections about the
 time the OP posted this message. Most of the sites in question were routing
 through cogent as well. I'd bet something happened on their end, but I do
 not see this happening at the moment anymore.
 Ryan
 On Wed, Oct 10, 2012 at 10:43 PM, Otis L. Surratt, Jr. <otis at ocosa.com>wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121010/9b834eee/attachment-0001.html>
  <CAOC=LuU_W1Fu9N-tTw+RV=qcaVJs+cVh6cNNm1_FjzcB3BbwqQ@mail.gmail.com>
  <CAFn1dUHEZmUGxN3Y-+vK6bWj0PpYf64gaECvZGRvUvbh3WAkvQ@mail.gmail.com>
  <CAOC=LuUJOV=-chL0iDz8vMvgO=6Ms63F+rFqbBLC3XmSb8s-5A@mail.gmail.com>
  <5FE1FB6D43B8A647BBC821840C1AEA8B017E78@ocsbs.ocosa.com>
 Otis et al,
 I believe Carlos ruled out ICMP prio as a result of doing a native
 server-to-server ping, from 208.86.121.129 to 66.62.162.31, as
 indicated here:
 ICMP prio doesn't affect src-to-dst RTT or packet loss; it affects
 src-to-administrative-router-IP situations (individual hop probes in
 traceroute, sans the destination, etc.).
 I think it's more likely that there is a saturated network link
 somewhere, given the behaviour shown.  Seeing the return path (not for
 latency or packet loss reasons, but to see the peering points) would be
 useful though.
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
 On Wed, Oct 10, 2012 at 09:43:15PM -0500, Otis L. Surratt, Jr. wrote:
###############################################################
END
###############################################################

###############################################################
Facebook down from
###############################################################
 Any one else experiencing same problem ?
 Sorry, something went wrong.
 We're working on getting this fixed as soon as we can.
 It's not just you! http://www.facebook.com looks down from here.
 Check another site? <http://www.downforeveryoneorjustme.com/>
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121011/6d9f8e97/attachment.html>
 I think this is actually a backbone issue affecting access to many sites:
 http://internetpulse.com/Main.aspx?Period=RH1
 Damian
 On Wed, Oct 10, 2012 at 11:25 PM, arulgobinath emmanuel
 <arulgobi at gmail.com>wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121010/dcd949a6/attachment.html>
  <CABSP1Ofy-hogADxCOG_ULyE2EfasLK6Nd8egD6_wOKu9SNGNUQ@mail.gmail.com>
 I am on a TWTC circuit in Milwaukee, WI and facebook is working normal.
 (note the latency at hop 12 is normally there)
 Tracing route to facebook.com [69.171.237.16]
 over a maximum of 30 hops:
   1     1 ms    <1 ms    <1 ms  x.x.x.x
   2     1 ms    <1 ms    <1 ms  x.x.x.x
   3     1 ms    <1 ms     1 ms  x.x.x.x
   4     2 ms     1 ms     1 ms  x.x.x.x
   5     2 ms     1 ms     1 ms
 207-250-86-49.static.twtelecom.net[207.250.86.49]
   6    18 ms     4 ms     4 ms
 chi2-pr1-xe-0-3-0-0.us.twtelecom.net[66.192.245.166]
   7     5 ms     4 ms     4 ms  12.249.183.5
   8     9 ms     6 ms     5 ms  cr1.cgcil.ip.att.net [12.122.133.198]
   9     5 ms    75 ms     4 ms  ggr3.cgcil.ip.att.net [12.122.132.9]
  10     5 ms     4 ms     4 ms  12.250.28.10
  11     5 ms     4 ms     5 ms  ae1.bb02.ord1.tfbnw.net [31.13.29.2]
  12    77 ms    76 ms    76 ms  ae17.bb04.prn1.tfbnw.net [204.15.20.143]
  13    75 ms    74 ms    74 ms  ae3.dr06.prn1.tfbnw.net [204.15.21.71]
  14    75 ms    75 ms    75 ms  po1021.csw12b.prn1.tfbnw.net [31.13.26.223]
  15    75 ms    75 ms    74 ms  www-slb-10-12-prn1.facebook.com[69.171.237.16]
 Trace complete.
 -Grant
 On Thu, Oct 11, 2012 at 1:32 AM, Damian Menscher <damian at google.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121011/3b002ee9/attachment.html>
  <CABSP1Ofy-hogADxCOG_ULyE2EfasLK6Nd8egD6_wOKu9SNGNUQ@mail.gmail.com>
  <CAPiURgUu2iijuNz45pwzkS3RP2N1b4UDeEy0qMR+_CyypRvBXg@mail.gmail.com>
 Just so nobody wastes time continuing to investigate, the outage appears to
 have been from ~23:13-23:32 pacific (it's been over for 45 minutes).
 Damian
 On Thu, Oct 11, 2012 at 12:05 AM, Grant Ridder <shortdudey123 at gmail.com>wrote:
 >>>  Any one else experiencing same problem ?
 >>> Sorry, something went wrong.
 >>>
 >>> We're working on getting this fixed as soon as we can.
 >>>
 >>>
 >>> It's not just you! http://www.facebook.com looks down from here.
 >>>
 >>> Check another site? <http://www.downforeveryoneorjustme.com/>
 >>>
 >>>
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 >>>
 >>>
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121011/424e3c78/attachment-0001.html>
 ----- Original Message -----
 Nope.
 For me, this morning, www.facebook.com resolves to c10r.facebook.com, which
 is 69.171.242.74, and I can't even get the first hop on a traceroute to
 there; I am assuming, though my shitty FiOS Westell router doesn't bother
 to say, that FiOS's core hasn't a route to that network at the moment.
 I saw intermittent outages on it last night as well.  FiOS St Pete FL.
 I've been seeing this since around 0930EDTish.  Saw it some yesterday
 afternoon as well, intermittently.  chat.facebook.com, their Jabber server
 (actually jabber-03-01-snc6.tfbnw.net (66.220.151.99)) is up fine.
 Cheers,
 -- jra
 -- 
 Jay R. Ashworth                  Baylink                       jra at baylink.com
 Designer                     The Things I Think                       RFC 2100
 Ashworth & Associates     http://baylink.pitas.com         2000 Land Rover DII
 St Petersburg FL USA               #natog                      +1 727 647 1274
###############################################################
END
###############################################################

###############################################################
Integra Telecom outage
###############################################################
 It was mentioned on a phone call and confirmed in Twitter that Integra
 Telecom is having issues.  As of 50 minutes ago there was a 1 hour ETR.
 Frank
 On Fri, Oct 12, 2012 at 9:15 AM, Frank Bulk <frnkblk at iname.com> wrote:
 Area?  Type of service impacted?  Integra is a big company offering a lot
 of services.
 -- 
 Carlos Alvarez
 TelEvolve
 602-889-3003
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121012/a8be9cc9/attachment.html>
  <CAFn1dUH6nngD5FEKzVd_g523HLGqim178iba+XMQ2A__avH_VA@mail.gmail.com>
 Sorry about that - from twitter:
 Looks like @Integra_Telecom DSL is down in all of 
 Minnesota and North Dakota. They have identified 
 the issue. 1 Hour ETA.
 Frank
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Carlos Alvarez
 Sent: Friday, October 12, 2012 11:32 AM
 On Fri, Oct 12, 2012 at 9:15 AM, Frank Bulk <frnkblk at iname.com> wrote:
 It was mentioned on a phone call and confirmed in Twitter that Integra
 Telecom is having issues.  As of 50 minutes ago there was a 1 hour ETR.
 Area?  Type of service impacted?  Integra is a big company offering a lot of
 services.
 -- 
 Carlos Alvarez
 TelEvolve
 602-889-3003
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121012/b9af55e5/attachment.html>
###############################################################
END
###############################################################

###############################################################
cogent <-> verizon catfight?
###############################################################
 Hi,
 I just spoke with a client's ISP, who claims that their issues with 
 connectivity center around a Cogent<->Verizon peering fight.
 Any word on this? Have I been asleep for a few weeks and missed something?
 //jbaltz
 -- 
 jerry b. altzman | jbaltz at altzman.com | www.jbaltz.com | twitter:@lorvax
 thank you for contributing to the heat death of the universe.
 News to me.. 
 ~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*
 Heather Schiller
 Network Security - Verizon Business
 1.800.900.0241    security at verizonbusiness.com 
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Jerry B. Altzman
 Sent: Tuesday, October 16, 2012 4:40 PM
 Hi,
 I just spoke with a client's ISP, who claims that their issues with connectivity center around a Cogent<->Verizon peering fight.
 Any word on this? Have I been asleep for a few weeks and missed something?
 //jbaltz
 --
 jerry b. altzman | jbaltz at altzman.com | www.jbaltz.com | twitter:@lorvax thank you for contributing to the heat death of the universe.
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <B9EBD2474913AD4A995B8C7B8BEF8C0E1597847298@FHDP1LUMXC7V43.us.one.verizon.com>
 Could be, just did some traceroutes to Verizon and they go to Cogent 
 then to L3 and finally into Verizon.  Can't say if they went directly 
 into Verizon before though.
 On 10/16/2012 4:55 PM, Schiller, Heather A wrote:
###############################################################
END
###############################################################

###############################################################
Neustar UltraDNS sporadic resolution failure
###############################################################
 Seeing repeated failures on both udns1.ultradns.net and udns2.ultradns.net.
 Getting some initial corroboration from several folks on twitter, but no
 acknowledgement from Neustar.
 ; <<>> DiG 9.8.3-P1 <<>> @udns2.ultradns.net www.braintreegateway.com
 ; (1 server found)
 ;; global options: +cmd
 ;; connection timed out; no servers could be reached
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121016/5ac4035e/attachment.html>
 In addition to this, we saw a whole variety of "weird" problems at this time.
 Internetpulse reported packet loss between multiple ISPs
 (ATT/Verizon/Sprint/L3 in different directions).
 We saw packet loss on Abovenet, too.
 Reaching AWS was sporadic on multiple ISPs...
 Anyone else see this happen too?
 On Tue, Oct 16, 2012 at 8:35 PM, Paul Hinze <paul.t.hinze at gmail.com> wrote:
  <CAMjP1KkpiS12UapABKp6ehqi0PHN=Qm+ppXek=BNeK2C-qjzPQ@mail.gmail.com>
 Works from Comcast in Boston.
 Where is it down?  Remember, Ultra is massively anycasted.
 -- 
 TTFN,
 patrick
 On Oct 16, 2012, at 22:59 , Avleen Vig <avleen at gmail.com> wrote:
  <CAMjP1KkpiS12UapABKp6ehqi0PHN=Qm+ppXek=BNeK2C-qjzPQ@mail.gmail.com>
  <9054A9C6-1AF1-45E4-A216-DAEBFC3065B1@ianai.net>
 Looks like it was a large scale DDoS attack:
 On Tue, Oct 16, 2012 at 10:03 PM, Patrick W. Gilmore <patrick at ianai.net> wrote:
 >>> Seeing repeated failures on both udns1.ultradns.net and udns2.ultradns.net.
 >>>
 >>> Getting some initial corroboration from several folks on twitter, but no
 >>> acknowledgement from Neustar.
 >>>
 >>> ; <<>> DiG 9.8.3-P1 <<>> @udns2.ultradns.net www.braintreegateway.com
 >>> ; (1 server found)
 >>> ;; global options: +cmd
 >>> ;; connection timed out; no servers could be reached
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 >>>
  <CAMjP1KkpiS12UapABKp6ehqi0PHN=Qm+ppXek=BNeK2C-qjzPQ@mail.gmail.com>
  <9054A9C6-1AF1-45E4-A216-DAEBFC3065B1@ianai.net>
  <CAN=EPwLroqxdx63iMRz72kfVh2Q27y3E2EBPRPQB+nE=Eibc-A@mail.gmail.com>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 On 10/17/2012 07:41 AM, Paul Hinze wrote:
 - --------------------
 Call it coincidence or just simply bad timing, anytime when ultradns
 has tweeted about dos mitigation they somehow wake up sleeping
 gremlins. If my memory serves me correct something similar happened in
 august of this year to their nodes in HK, LA and NY.
 regards,
 /virendra
 >>> In addition to this, we saw a whole variety of "weird" problems
 >>> at this time. Internetpulse reported packet loss between
 >>> multiple ISPs (ATT/Verizon/Sprint/L3 in different directions).
 >>> 
 >>> We saw packet loss on Abovenet, too.
 >>> 
 >>> Reaching AWS was sporadic on multiple ISPs...
 >>> 
 >>> Anyone else see this happen too?
 >>> 
 >>> On Tue, Oct 16, 2012 at 8:35 PM, Paul Hinze
 >>> <paul.t.hinze at gmail.com> wrote:
 >>>> Seeing repeated failures on both udns1.ultradns.net and
 >>>> udns2.ultradns.net.
 >>>> 
 >>>> Getting some initial corroboration from several folks on
 >>>> twitter, but no acknowledgement from Neustar.
 >>>> 
 >>>> ; <<>> DiG 9.8.3-P1 <<>> @udns2.ultradns.net
 >>>> www.braintreegateway.com ; (1 server found) ;; global
 >>>> options: +cmd ;; connection timed out; no servers could be
 >>>> reached _______________________________________________ 
 >>>> Outages mailing list Outages at outages.org 
 >>>> https://puck.nether.net/mailman/listinfo/outages
 >>>> 
 >>> _______________________________________________ Outages mailing
 >>> list Outages at outages.org 
 >>> https://puck.nether.net/mailman/listinfo/outages
 >>> 
###############################################################
END
###############################################################

###############################################################
DurableDNS.com is down. Their name servers are not resolving their zones.
###############################################################
 DJ Conley
 Resolution Center (Tier 3)
 770-874-4856 O
 404-395-7861 M
 dj.conley at cbeyond.net<mailto:dj.conley at cbeyond.net>
 CBEYOND
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121017/84c004bd/attachment.html>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 On 10/17/2012 04:21 AM, DJ Conley wrote:
 - --------------------
 yup, was reported via twitter.
 DurableDNS #unplanned #start 4:41 AM EDT first report #back 8:30 AM EDT
 regards,
 /virendra
###############################################################
END
###############################################################

###############################################################
capitalone.com
###############################################################
 I have had a few clients point out that capitalone.com appears to be down
 DNS resolved to 208.80.48.112 on affected clients on comcast in the
 northeast
 chris
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121017/6bb31dd6/attachment.html>
 Down from a TWTC circuit in Milwaukee, wi also.  The 7th hop is different
 even though the computers are on the same outbound circuit.
 WIndows:
 Tracing route to capitalone.com [208.80.48.112]
 over a maximum of 30 hops:
   1     1 ms    <1 ms    <1 ms  x.x.x.x
   2     1 ms    <1 ms    <1 ms  x.x.x.x
   3     1 ms     1 ms     1 ms  x.x.x.x
   4     1 ms     1 ms     1 ms  x.x.x.x
   5     7 ms     1 ms     1 ms  esc033.escriptconnect.com [64.132.85.33]
   6     4 ms     4 ms     4 ms
 chi2-pr1-xe-2-3-0-0.us.twtelecom.net[66.192.250.154]
   7     5 ms     4 ms     4 ms  12.249.183.5
   8     8 ms     6 ms     5 ms  cr1.cgcil.ip.att.net [12.122.133.198]
   9     4 ms     5 ms     6 ms  12.122.80.113
  10     *        *        *     Request timed out.
  11     *        *        *     Request timed out.
  12     *        *        *     Request timed out.
  13     *        *        *     Request timed out.
  14     *        *        *     Request timed out.
  15     *        *        *     Request timed out.
  16   102 ms   203 ms   207 ms  12.90.2.6
  17     *        *        *     Request timed out.
  18     *        *        *     Request timed out.
  19     *        *        *     Request timed out.
 [etc...]
 Linux:
 traceroute to capitalone.com (208.80.48.112), 30 hops max, 60 byte packets
  1  x.x.x.x (x.x.x.x)  0.946 ms  0.690 ms  3.195 ms
  2  x.x.x.x (x.x.x.x)  3.024 ms  2.792 ms  2.624 ms
  3  x.x.x.x (x.x.x.x)  2.424 ms  2.282 ms  2.124 ms
  4  esc033.escriptconnect.com (64.132.85.33)  4.713 ms  4.550 ms  4.382 ms
  5  chi2-pr1-xe-2-3-0-0.us.twtelecom.net (66.192.250.154)  12.795 ms
  13.176 ms  13.007 ms
  6  12.249.183.5 (12.249.183.5)  4.636 ms  4.543 ms  4.509 ms
  7  cr2.cgcil.ip.att.net (12.122.132.214)  7.285 ms
 cr1.cgcil.ip.att.net(12.122.133.198)  5.742 ms
 cr2.cgcil.ip.att.net (12.122.132.214)  5.582 ms
  8  12.122.80.77 (12.122.80.77)  4.901 ms  5.131 ms 12.122.80.113
 (12.122.80.113)  5.012 ms
  9  * * *
 10  * * *
 [etc...]
 -Grant
 On Wed, Oct 17, 2012 at 11:44 AM, chris <tknchris at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121017/0e89d4c7/attachment.html>
 Resolves to 208.80.50.112 here on the west coast, and is also not
 responding, or possibly intermittently.
 On Wed, Oct 17, 2012 at 9:44 AM, chris <tknchris at gmail.com> wrote:
 -- 
 "Genius might be described as a supreme capacity for getting its possessors
 into trouble of all kinds."
 -- Samuel Butler
  <CAPiURgXjZvHs68i6bxf44Sx0cOVH9=bKiw+JmR6JDpBi=Jt1qQ@mail.gmail.com>
 Works for me here in Colorado through both CenturyLink and Cogent. Resolves 
 to 208.80.48.112 for http://capitalone.com which redirects me to the same IP 
 for https://www.capitalone.com.
 Chris
 On 10/17/2012 10:58 AM, Grant Ridder wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121017/9e95c9bd/attachment.html>
  <CAPiURgXjZvHs68i6bxf44Sx0cOVH9=bKiw+JmR6JDpBi=Jt1qQ@mail.gmail.com>
  <507EE4AB.5050002@axint.net>
 Works on my mobile.  Vzw in Ohio.  Redirected me to the mobile URL.
 On Oct 17, 2012 1:03 PM, "Chris Stone" <cstone at axint.net> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121017/0d9c7c77/attachment-0001.html>
  <CAPiURgXjZvHs68i6bxf44Sx0cOVH9=bKiw+JmR6JDpBi=Jt1qQ@mail.gmail.com>
  <507EE4AB.5050002@axint.net>
  <CAN9qwJ9E3R9fJbJs+bEaJmoqqpHuYPJLN72MmA1Y_bt+Eny3_Q@mail.gmail.com>
 resolving to 208.80.48.112 in san diego on AT&T but timing out
   1    <1 ms    <1 ms    <1 ms x.x.x.x
   2     1 ms     1 ms     1 ms  x.x.x.x
   3     1 ms     1 ms     1 ms  x.x.x.x
   4    55 ms    55 ms    56 ms  cr2.sd2ca.ip.att.net [12.122.109.74]
   5    53 ms    55 ms    55 ms  cr2.la2ca.ip.att.net [12.122.31.10]
   6    68 ms    82 ms    56 ms  cr1.slkut.ip.att.net [12.122.30.29]
   7    54 ms    55 ms    55 ms  cr2.dvmco.ip.att.net [12.122.30.26]
   8    55 ms    55 ms    56 ms  cr1.cgcil.ip.att.net [12.122.31.86]
   9    52 ms    61 ms    52 ms  12.123.7.21
  10     *        *        *     Request timed out.
  11     *        *        *     Request timed out.
  12     *        *        *     Request timed out.
  13     *        *
 james
 On Wed, Oct 17, 2012 at 10:07 AM, Josh Luthman
 <josh at imaginenetworksllc.com> wrote:
 >>>
 >>> I have had a few clients point out that capitalone.com appears to be down
 >>>
 >>> DNS resolved to 208.80.48.112 on affected clients on comcast in the
 >>> northeast
 >>>
 >>> chris
 >>>
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 >>>
  <CAPiURgXjZvHs68i6bxf44Sx0cOVH9=bKiw+JmR6JDpBi=Jt1qQ@mail.gmail.com>
 Traceroute and ping are unreliable for up/down status or troubleshooting, as UDP and ICMP are often filtered.
 --Heather
 ________________________________
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Grant Ridder
 Sent: Wednesday, October 17, 2012 12:58 PM
 Cc: outages at outages.org
 Down from a TWTC circuit in Milwaukee, wi also.  The 7th hop is different even though the computers are on the same outbound circuit.
 WIndows:
 Tracing route to capitalone.com<http://capitalone.com> [208.80.48.112]
 over a maximum of 30 hops:
   1     1 ms    <1 ms    <1 ms  x.x.x.x
   2     1 ms    <1 ms    <1 ms  x.x.x.x
   3     1 ms     1 ms     1 ms  x.x.x.x
   4     1 ms     1 ms     1 ms  x.x.x.x
   5     7 ms     1 ms     1 ms  esc033.escriptconnect.com<http://esc033.escriptconnect.com> [64.132.85.33]
   6     4 ms     4 ms     4 ms  chi2-pr1-xe-2-3-0-0.us.twtelecom.net<http://chi2-pr1-xe-2-3-0-0.us.twtelecom.net> [66.192.250.154]
   7     5 ms     4 ms     4 ms  12.249.183.5
   8     8 ms     6 ms     5 ms  cr1.cgcil.ip.att.net<http://cr1.cgcil.ip.att.net> [12.122.133.198]
   9     4 ms     5 ms     6 ms  12.122.80.113
  10     *        *        *     Request timed out.
  11     *        *        *     Request timed out.
  12     *        *        *     Request timed out.
  13     *        *        *     Request timed out.
  14     *        *        *     Request timed out.
  15     *        *        *     Request timed out.
  16   102 ms   203 ms   207 ms  12.90.2.6
  17     *        *        *     Request timed out.
  18     *        *        *     Request timed out.
  19     *        *        *     Request timed out.
 [etc...]
 Linux:
 traceroute to capitalone.com<http://capitalone.com> (208.80.48.112), 30 hops max, 60 byte packets
  1  x.x.x.x (x.x.x.x)  0.946 ms  0.690 ms  3.195 ms
  2  x.x.x.x (x.x.x.x)  3.024 ms  2.792 ms  2.624 ms
  3  x.x.x.x (x.x.x.x)  2.424 ms  2.282 ms  2.124 ms
  4  esc033.escriptconnect.com<http://esc033.escriptconnect.com> (64.132.85.33)  4.713 ms  4.550 ms  4.382 ms
  5  chi2-pr1-xe-2-3-0-0.us.twtelecom.net<http://chi2-pr1-xe-2-3-0-0.us.twtelecom.net> (66.192.250.154)  12.795 ms  13.176 ms  13.007 ms
  6  12.249.183.5 (12.249.183.5)  4.636 ms  4.543 ms  4.509 ms
  7  cr2.cgcil.ip.att.net<http://cr2.cgcil.ip.att.net> (12.122.132.214)  7.285 ms cr1.cgcil.ip.att.net<http://cr1.cgcil.ip.att.net> (12.122.133.198)  5.742 ms cr2.cgcil.ip.att.net<http://cr2.cgcil.ip.att.net> (12.122.132.214)  5.582 ms
  8  12.122.80.77 (12.122.80.77)  4.901 ms  5.131 ms 12.122.80.113 (12.122.80.113)  5.012 ms
  9  * * *
 10  * * *
 [etc...]
 -Grant
 On Wed, Oct 17, 2012 at 11:44 AM, chris <tknchris at gmail.com<mailto:tknchris at gmail.com>> wrote:
 I have had a few clients point out that capitalone.com<http://capitalone.com> appears to be down
 DNS resolved to 208.80.48.112<tel:208.80.48.112> on affected clients on comcast in the northeast
 chris
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121017/8452f2da/attachment.html>
  <CAPiURgXjZvHs68i6bxf44Sx0cOVH9=bKiw+JmR6JDpBi=Jt1qQ@mail.gmail.com>
  <B9EBD2474913AD4A995B8C7B8BEF8C0E1597847737@FHDP1LUMXC7V43.us.one.verizon.com>
 Which is silly thing to do.
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Schiller, Heather A
 Sent: Wednesday, October 17, 2012 12:23 PM
 Cc: outages at outages.org
 Traceroute and ping are unreliable for up/down status or troubleshooting, as UDP and ICMP are often filtered.
 --Heather
 ________________________________
 From: outages-bounces at outages.org<mailto:outages-bounces at outages.org> [mailto:outages-bounces at outages.org] On Behalf Of Grant Ridder
 Sent: Wednesday, October 17, 2012 12:58 PM
 Cc: outages at outages.org<mailto:outages at outages.org>
 Subject: Re: [outages] capitalone.com
 Down from a TWTC circuit in Milwaukee, wi also.  The 7th hop is different even though the computers are on the same outbound circuit.
 WIndows:
 Tracing route to capitalone.com<http://capitalone.com> [208.80.48.112]
 over a maximum of 30 hops:
   1     1 ms    <1 ms    <1 ms  x.x.x.x
   2     1 ms    <1 ms    <1 ms  x.x.x.x
   3     1 ms     1 ms     1 ms  x.x.x.x
   4     1 ms     1 ms     1 ms  x.x.x.x
   5     7 ms     1 ms     1 ms  esc033.escriptconnect.com<http://esc033.escriptconnect.com> [64.132.85.33]
   6     4 ms     4 ms     4 ms  chi2-pr1-xe-2-3-0-0.us.twtelecom.net<http://chi2-pr1-xe-2-3-0-0.us.twtelecom.net> [66.192.250.154]
   7     5 ms     4 ms     4 ms  12.249.183.5
   8     8 ms     6 ms     5 ms  cr1.cgcil.ip.att.net<http://cr1.cgcil.ip.att.net> [12.122.133.198]
   9     4 ms     5 ms     6 ms  12.122.80.113
  10     *        *        *     Request timed out.
  11     *        *        *     Request timed out.
  12     *        *        *     Request timed out.
  13     *        *        *     Request timed out.
  14     *        *        *     Request timed out.
  15     *        *        *     Request timed out.
  16   102 ms   203 ms   207 ms  12.90.2.6
  17     *        *        *     Request timed out.
  18     *        *        *     Request timed out.
  19     *        *        *     Request timed out.
 [etc...]
 Linux:
 traceroute to capitalone.com<http://capitalone.com> (208.80.48.112), 30 hops max, 60 byte packets
  1  x.x.x.x (x.x.x.x)  0.946 ms  0.690 ms  3.195 ms
  2  x.x.x.x (x.x.x.x)  3.024 ms  2.792 ms  2.624 ms
  3  x.x.x.x (x.x.x.x)  2.424 ms  2.282 ms  2.124 ms
  4  esc033.escriptconnect.com<http://esc033.escriptconnect.com> (64.132.85.33)  4.713 ms  4.550 ms  4.382 ms
  5  chi2-pr1-xe-2-3-0-0.us.twtelecom.net<http://chi2-pr1-xe-2-3-0-0.us.twtelecom.net> (66.192.250.154)  12.795 ms  13.176 ms  13.007 ms
  6  12.249.183.5 (12.249.183.5)  4.636 ms  4.543 ms  4.509 ms
  7  cr2.cgcil.ip.att.net<http://cr2.cgcil.ip.att.net> (12.122.132.214)  7.285 ms cr1.cgcil.ip.att.net<http://cr1.cgcil.ip.att.net> (12.122.133.198)  5.742 ms cr2.cgcil.ip.att.net<http://cr2.cgcil.ip.att.net> (12.122.132.214)  5.582 ms
  8  12.122.80.77 (12.122.80.77)  4.901 ms  5.131 ms 12.122.80.113 (12.122.80.113)  5.012 ms
  9  * * *
 10  * * *
 [etc...]
 -Grant
 On Wed, Oct 17, 2012 at 11:44 AM, chris <tknchris at gmail.com<mailto:tknchris at gmail.com>> wrote:
 I have had a few clients point out that capitalone.com<http://capitalone.com> appears to be down
 DNS resolved to 208.80.48.112<tel:208.80.48.112> on affected clients on comcast in the northeast
 chris
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121017/c022252d/attachment-0001.html>
 On Wed, Oct 17, 2012 at 12:44:06PM -0400, chris wrote:
 down from the two locations I tried from as well.  from both 
 locations I can connect to port 80, but don't get any responce
 to any made http requests.
 traceroute to capitalone.com (208.80.48.112), 30 hops max, 60 byte packets
  1  192.168.0.1 (192.168.0.1)  0.287 ms  0.242 ms  0.629 ms
  2  mnch-co-ls1.gwi.net (66.55.208.34)  54.362 ms  54.382 ms  57.733 ms
  3  mnch-co-r1-mnch-co-ls1.gwi.net (66.55.208.33)  15.709 ms  15.735 ms  17.795 ms
  4  cr01-ptld-po1--mnch-co-r1.gwi.net (207.5.145.245)  20.400 ms  20.421 ms  22.825 ms
  5  xe-8-3-0.edge4.NewYork1.Level3.net (4.28.130.37)  30.629 ms  30.659 ms  33.116 ms
  6  ae-3-80.edge3.NewYork1.Level3.net (4.69.155.145)  33.130 ms  33.467 ms ae-4-90.edge3.NewYork1.Level3.net (4.69.155.209)  64.651 ms
  7  att-level3.newyork1.level3.net (4.68.63.142)  34.764 ms  23.333 ms  23.299 ms
  8  cr1.n54ny.ip.att.net (12.122.131.102)  52.237 ms  49.617 ms  49.583 ms
  9  cr2.cgcil.ip.att.net (12.122.1.2)  48.718 ms  43.816 ms  47.580 ms
 10  12.123.7.145 (12.123.7.145)  44.100 ms  45.040 ms  44.884 ms
 11  * * *
 12  * * *
 [...]
 29  * * *
 30  * * *
 traceroute to capitalone.com (208.80.48.112), 64 hops max, 40 byte packets
  1  gw-g4 (216.177.7.161)  0.948 ms  0.683 ms  0.676 ms
  2  manchester0-8.nh.G4.net (66.211.128.133)  0.356 ms  0.311 ms  0.203 ms
  3  67.208.178.89.nyc.electricfiber.net (67.208.178.89)  1.996 ms  2.172 ms  2.109 ms
  4  xe-0-0-0.bos11.ip4.tinet.net (173.241.129.217)  42.082 ms  1.878 ms  1.857 ms
  5  xe-9-1-0.nyc20.ip4.tinet.net (89.149.183.14)  7.575 ms  7.640 ms  7.491 ms
  6  * * *
  7  cr1.n54ny.ip.att.net (12.122.86.6)  31.400 ms  29.120 ms  31.876 ms
  8  cr2.cgcil.ip.att.net (12.122.1.2)  30.537 ms  28.826 ms  27.607 ms
  9  12.122.80.113 (12.122.80.113)  26.916 ms  27.875 ms  27.049 ms
 10  * * *
 11  * * *
 [...]
 29  * * *
 30  * * *
  <20121017173228.GA5553@rut.org>
 Problems from here as well...
 Tracing route to www.wpex.capitalone.com [208.80.50.112]
 over a maximum of 20 hops:
   1    <1 ms    <1 ms    <1 ms  10.32.136.1
   2     1 ms    <1 ms    <1 ms  174.78.191.1
   3     3 ms     3 ms     3 ms  fed1sysc02-gex0117.sd.sd.cox.net [209.242.143.58
 ]
   4     3 ms     4 ms     4 ms  fed1sysc02-get0007.sd.sd.cox.net [68.6.8.152]
   5     3 ms     3 ms     3 ms  fed1dsrj02-xe130.0.rd.sd.cox.net [68.6.8.4]
   6    28 ms    27 ms    27 ms  paltbprj01-ae2.0.rd.pt.cox.net [68.1.2.98]
   7    16 ms    16 ms    16 ms  te3-8.ccr02.sjc04.atlas.cogentco.com [154.54.10.
 125]
   8    29 ms    29 ms    31 ms  te0-0-0-5.ccr22.sjc03.atlas.cogentco.com [154.54
 .24.142]
   9    29 ms    29 ms    28 ms  154.54.86.105
  10    29 ms    29 ms    28 ms  iij.sjc03.atlas.cogentco.com [154.54.12.170]
  11    53 ms    53 ms    53 ms  0.xe-5-0-1.xt2.lax9.alter.net [152.63.1.141]
  12    42 ms    42 ms    42 ms  24.tengigabitethernet9-2.sa2.lax9.alter.net [152
 .63.112.225]
  13     *        *        *     Request timed out.
  14     *        *        *     Request timed out.
  15     *        *        *     Request timed out.
  16     *        *        *     Request timed out.
  17     *        *        *     Request timed out.
  18     *        *        *     Request timed out.
  19     *        *        *     Request timed out.
  20     *        *        *     Request timed out.
 Trace complete.
 All the best,
 Robert Castillo | Project Manager
 Atlanta Cell: 404.455.5558 |?San Diego: 858.707.5868
 Email:? robert.castillo at tig.com
 Office?: 858.566.1900 |?Fax: 858.790.0042
 7810 Trade Street?7 San Diego, CA 92121
 Website: www.tig.com
 Periodically TIG will update our valued industry contacts and clients through email in an effort to inform them of the latest developments in computer system integration.? TIG is concerned about your privacy.? We do not rent, sell or exchange email addresses and respect the wishes of individuals who do not wish to receive email updates.? To be removed from TIG's distribution list kindly forward this email to remove at tig.com with the word "unsubscribe" in the subject line.
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Robert Henney
 Sent: Wednesday, October 17, 2012 10:32 AM
 Cc: outages at outages.org
 On Wed, Oct 17, 2012 at 12:44:06PM -0400, chris wrote:
 down from the two locations I tried from as well.  from both locations I can connect to port 80, but don't get any responce to any made http requests.
 traceroute to capitalone.com (208.80.48.112), 30 hops max, 60 byte packets
  1  192.168.0.1 (192.168.0.1)  0.287 ms  0.242 ms  0.629 ms
  2  mnch-co-ls1.gwi.net (66.55.208.34)  54.362 ms  54.382 ms  57.733 ms
  3  mnch-co-r1-mnch-co-ls1.gwi.net (66.55.208.33)  15.709 ms  15.735 ms  17.795 ms
  4  cr01-ptld-po1--mnch-co-r1.gwi.net (207.5.145.245)  20.400 ms  20.421 ms  22.825 ms
  5  xe-8-3-0.edge4.NewYork1.Level3.net (4.28.130.37)  30.629 ms  30.659 ms  33.116 ms
  6  ae-3-80.edge3.NewYork1.Level3.net (4.69.155.145)  33.130 ms  33.467 ms ae-4-90.edge3.NewYork1.Level3.net (4.69.155.209)  64.651 ms
  7  att-level3.newyork1.level3.net (4.68.63.142)  34.764 ms  23.333 ms  23.299 ms
  8  cr1.n54ny.ip.att.net (12.122.131.102)  52.237 ms  49.617 ms  49.583 ms
  9  cr2.cgcil.ip.att.net (12.122.1.2)  48.718 ms  43.816 ms  47.580 ms
 10  12.123.7.145 (12.123.7.145)  44.100 ms  45.040 ms  44.884 ms
 11  * * *
 12  * * *
 [...]
 29  * * *
 30  * * *
 traceroute to capitalone.com (208.80.48.112), 64 hops max, 40 byte packets
  1  gw-g4 (216.177.7.161)  0.948 ms  0.683 ms  0.676 ms
  2  manchester0-8.nh.G4.net (66.211.128.133)  0.356 ms  0.311 ms  0.203 ms
  3  67.208.178.89.nyc.electricfiber.net (67.208.178.89)  1.996 ms  2.172 ms  2.109 ms
  4  xe-0-0-0.bos11.ip4.tinet.net (173.241.129.217)  42.082 ms  1.878 ms  1.857 ms
  5  xe-9-1-0.nyc20.ip4.tinet.net (89.149.183.14)  7.575 ms  7.640 ms  7.491 ms
  6  * * *
  7  cr1.n54ny.ip.att.net (12.122.86.6)  31.400 ms  29.120 ms  31.876 ms
  8  cr2.cgcil.ip.att.net (12.122.1.2)  30.537 ms  28.826 ms  27.607 ms
  9  12.122.80.113 (12.122.80.113)  26.916 ms  27.875 ms  27.049 ms
 10  * * *
 11  * * *
 [...]
 29  * * *
 30  * * *
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
###############################################################
END
###############################################################

###############################################################
UUnet cross-USA latency increased
###############################################################
 FYI, the usual 75ms SJC to IAD on UUnet (AS701) backbone has been over
 110ms for about an hour.
   2 0.so-0-2-0.XL1.SJC1.ALTER.NET (152.63.54.18) [AS 701] 0 msec 1 msec 1 msec
   3  * 0.xe-7-0-2.XL3.IAD8.ALTER.NET (152.63.32.230) [AS 701] 163 msec 140 msec
 No end-to-end loss observed.
 -mark
###############################################################
END
###############################################################

###############################################################
Amazon US-EAST-1 Region Down?
###############################################################
 Can?t reach our instances? this is what the Dashboard says:
 10:38 AM PDT We are currently investigating degraded performance for a
 small number of EBS volumes in a single Availability Zone in the US-EAST-1
 Region.
 11:11 AM PDT We can confirm degraded performance for a small number of EBS
 volumes in a single Availability Zone in the US-EAST-1 Region. Instances
 using affected EBS volumes will also experience degraded performance.
 11:26 AM PDT We are currently experiencing degraded performance for EBS
 volumes in a single Availability Zone in the US-EAST-1 Region. New launches
 for EBS backed instances are failing and instances using affected EBS
 volumes will experience degraded performance.
 Best Regards,
 Ivan
 Star Telecom | www.startelecom.ca
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/77725845/attachment.html>
 That probably explains why I've seen access to the IPv6 version of Netflix
 timing out on and off since 12:47 pm Central.
 Frank
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Ivan Kovacevic
 Sent: Monday, October 22, 2012 1:37 PM
 Can't reach our instances. this is what the Dashboard says: 
 10:38 AM PDT We are currently investigating degraded performance for a small
 number of EBS volumes in a single Availability Zone in the US-EAST-1 Region.
 11:11 AM PDT We can confirm degraded performance for a small number of EBS
 volumes in a single Availability Zone in the US-EAST-1 Region. Instances
 using affected EBS volumes will also experience degraded performance.
 11:26 AM PDT We are currently experiencing degraded performance for EBS
 volumes in a single Availability Zone in the US-EAST-1 Region. New launches
 for EBS backed instances are failing and instances using affected EBS
 volumes will experience degraded performance.
 Best Regards,
 Ivan
 Star Telecom | www.startelecom.ca <http://www.startelecom.ca/>  
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/06c326f4/attachment.html>
 On 10/22/2012 2:37 PM, Ivan Kovacevic wrote:
 FWIW Our EBS-backed instances in US-EAST-1C and US-EAST-1D are online 
 and accessible at this time. I can't speak for A or B.
 -- Ben
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/4a9e3376/attachment.html>
  <508595A5.9040609@bencarleton.com>
 The labels 1c, 1d, etc aren't uniform across accounts.  1d for you
 might be 1a for me.
 On Mon, Oct 22, 2012 at 2:51 PM, Ben Carleton <ben at bencarleton.com> wrote:
  <508595A5.9040609@bencarleton.com>
  <CADgTF2CxtDQL1=HqK6x+0dh+LGD0rJ5gMFH8A9gchiBSnfsMvQ@mail.gmail.com>
 I can't access the dashboard, it gives an error, but my instance
 is accessible.  I think it is in 1B however i can not confirm.
 -Grant
 On Mon, Oct 22, 2012 at 1:54 PM, Sean Lally <sean.lally at crownpeak.com>wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/82841781/attachment-0001.html>
  <508595A5.9040609@bencarleton.com>
  <CADgTF2CxtDQL1=HqK6x+0dh+LGD0rJ5gMFH8A9gchiBSnfsMvQ@mail.gmail.com>
  <CAPiURgVVH_guz0w9XPjZgpUmqZ2vY+SPBbADMb1SrRbyQpr9fg@mail.gmail.com>
 On 10/22/12 3:01 PM, Grant Ridder wrote:
 same here 1b down.
  <508595A5.9040609@bencarleton.com>
  <CADgTF2CxtDQL1=HqK6x+0dh+LGD0rJ5gMFH8A9gchiBSnfsMvQ@mail.gmail.com>
  <CAPiURgVVH_guz0w9XPjZgpUmqZ2vY+SPBbADMb1SrRbyQpr9fg@mail.gmail.com>
  <50859A61.6090209@comcast.net>
 As a point of information - my consulting company has many clients,
 many of whom have AWS presence in US-EAST-1, including the client I am
 at right now.
 Our consultants chatting about it are seeing issues throughout
 US-EAST-1, some problems in -1A, -1B, -1C, -1D at least.  Earlier
 reports that it might only be some fraction of those seem wrong.
 -- 
 -george william herbert
 george.herbert at gmail.com
  <508595A5.9040609@bencarleton.com>
  <CADgTF2CxtDQL1=HqK6x+0dh+LGD0rJ5gMFH8A9gchiBSnfsMvQ@mail.gmail.com>
  <CAPiURgVVH_guz0w9XPjZgpUmqZ2vY+SPBbADMb1SrRbyQpr9fg@mail.gmail.com>
  <50859A61.6090209@comcast.net>
  <CAK__KzuiDG8Yy8eRr6jz6ju03KrC1XQEsmRsnLViB9MDtxJtjA@mail.gmail.com>
 Just to remind people, Amazon availability zones are *not* universally
 named. Your -1A is not necessarily the same as mine.
 I.e. it could easily be only one AZ but appearing under every for different
 accounts.
 I don't have an iron-clad cite here but:
 http://aws.amazon.com/ec2/faqs/#How_can_I_make_sure_that_I_am_in_the_same_Availability_Zone_as_another_developer
 Thanks,
 Patrick
 On Mon, Oct 22, 2012 at 4:08 PM, George Herbert <george.herbert at gmail.com>wrote:
 -- 
 Patrick Hahn
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/b7f9272c/attachment.html>
  <508595A5.9040609@bencarleton.com>
  <CADgTF2CxtDQL1=HqK6x+0dh+LGD0rJ5gMFH8A9gchiBSnfsMvQ@mail.gmail.com>
  <CAPiURgVVH_guz0w9XPjZgpUmqZ2vY+SPBbADMb1SrRbyQpr9fg@mail.gmail.com>
  <50859A61.6090209@comcast.net>
  <CAK__KzuiDG8Yy8eRr6jz6ju03KrC1XQEsmRsnLViB9MDtxJtjA@mail.gmail.com>
 http://techcrunch.com/2012/10/22/aws-ec2-issues-in-north-virginia-affect-heroku-reddit-and-others-heroku-still-down/
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of George Herbert
 Sent: Monday, October 22, 2012 4:08 PM
 Cc: outages at outages.org
 As a point of information - my consulting company has many clients, many of whom have AWS presence in US-EAST-1, including the client I am at right now.
 Our consultants chatting about it are seeing issues throughout US-EAST-1, some problems in -1A, -1B, -1C, -1D at least.  Earlier reports that it might only be some fraction of those seem wrong.
 --
 -george william herbert
 george.herbert at gmail.com
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <508595A5.9040609@bencarleton.com>
  <CADgTF2CxtDQL1=HqK6x+0dh+LGD0rJ5gMFH8A9gchiBSnfsMvQ@mail.gmail.com>
  <CAPiURgVVH_guz0w9XPjZgpUmqZ2vY+SPBbADMb1SrRbyQpr9fg@mail.gmail.com>
  <50859A61.6090209@comcast.net>
  <CAK__KzuiDG8Yy8eRr6jz6ju03KrC1XQEsmRsnLViB9MDtxJtjA@mail.gmail.com>
 Not sure if anyone bothered to read my earlier message, but different
 accounts see the same zones with different labels. So zone 'x' will be seen
 as a by some, b by others,  c by some, etc.
 On Oct 22, 2012 4:14 PM, "George Herbert" <george.herbert at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/e6fd709d/attachment.html>
###############################################################
END
###############################################################

###############################################################
Netflix on Apple TV Down?
###############################################################
 Apple TV Netflix movie interrupted in mid play with message 'Service Unavailable.' Attempt to access Netflix menu from Apple TV gives the same error. Netflix website also appears to be unreachable... attempts to connect simply time out.
 Traceroute shows routing loop...
 traceroute www.netflix.com
 traceroute: Warning: www.netflix.com has multiple addresses; using 23.21.117.205
 traceroute to dualstack.wwwservice--frontend-313423742.us-east-1.elb.amazonaws.com (23.21.117.205), 64 hops max, 52 byte packets
  1  (redacted)
  2  (redacted)
  3  (redacted)
  4  72.157.38.25 (72.157.38.25)  30.194 ms  30.465 ms  30.219 ms
  5  12.81.68.48 (12.81.68.48)  30.949 ms  28.153 ms  48.894 ms
  6  12.81.68.58 (12.81.68.58)  26.742 ms  29.772 ms  31.019 ms
  7  ixc01jan-5-0-1.bellsouth.net (65.83.237.89)  29.180 ms  28.781 ms  29.882 ms
  8  12.81.98.50 (12.81.98.50)  30.657 ms  26.810 ms  30.321 ms
  9  ixc01aep-pos-4-0.bellsouth.net (65.83.237.99)  33.822 ms  32.289 ms  50.095 ms
 10  12.81.100.0 (12.81.100.0)  28.420 ms  28.004 ms  44.965 ms
 11  12.81.56.52 (12.81.56.52)  34.758 ms  32.865 ms  44.985 ms
 12  12.81.56.65 (12.81.56.65)  30.243 ms  43.389 ms  28.201 ms
 13  74.175.192.58 (74.175.192.58)  30.299 ms  29.059 ms  30.485 ms
 14  cr2.rlgnc.ip.att.net (12.123.152.110)  42.259 ms  41.007 ms  41.460 ms
 15  cr1.wswdc.ip.att.net (12.122.3.170)  39.498 ms  42.094 ms  39.960 ms
 16  wswdc03jt.ip.att.net (12.122.220.245)  36.170 ms  40.225 ms  34.812 ms
 17  192.205.32.30 (192.205.32.30)  39.632 ms  38.668 ms  40.288 ms
 18  * * *
 19  65.120.78.82 (65.120.78.82)  55.337 ms  41.815 ms  40.946 ms
 20  72.21.220.157 (72.21.220.157)  41.023 ms
     72.21.220.155 (72.21.220.155)  38.581 ms
     72.21.220.153 (72.21.220.153)  38.489 ms
 21  72.21.222.157 (72.21.222.157)  40.268 ms  45.570 ms
     72.21.222.143 (72.21.222.143)  40.980 ms
 22  * 216.182.224.53 (216.182.224.53)  43.835 ms *
 23  72.21.220.157 (72.21.220.157)  44.234 ms
     72.21.220.155 (72.21.220.155)  41.331 ms
     72.21.220.153 (72.21.220.153)  39.768 ms
 24  72.21.222.157 (72.21.222.157)  41.009 ms 
     72.21.222.143 (72.21.222.143)  39.889 ms
     72.21.222.157 (72.21.222.157)  44.337 ms  
 25  * 216.182.224.53 (216.182.224.53)  51.225 ms *
 ^C
 --
 Jon R. Kibler
 +001-843-813-2924
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: signature.asc
 Type: application/pgp-signature
 Size: 841 bytes
 Desc: Message signed with OpenPGP using GPGMail
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/8f8d680c/attachment.sig>
 See the posts on Amazon errors, which is the source for Netflix.
 On Mon, Oct 22, 2012 at 11:52 AM, Jon Kibler <jon.r.kibler at hushmail.com>wrote:
 -- 
 Carlos Alvarez
 TelEvolve
 602-889-3003
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/7b25d26e/attachment.html>
 I cannot access the Netflix website from Oklahoma. I eventually get redirected to
 https://signup.netflix.com, which fails to load.
 My Netflix service is working, but the menuing is "slow".
 On 10/22/12?14:52?-0400, Jon Kibler wrote:
 >Apple TV Netflix movie interrupted in mid play with message 'Service Unavailable.' Attempt to access Netflix menu from Apple TV gives the same error. Netflix website also appears to be unreachable... attempts to connect simply time out.
 >Traceroute shows routing loop...
 >traceroute www.netflix.com
 >traceroute: Warning: www.netflix.com has multiple addresses; using 23.21.117.205
 >traceroute to dualstack.wwwservice--frontend-313423742.us-east-1.elb.amazonaws.com (23.21.117.205), 64 hops max, 52 byte packets
 >10  12.81.100.0 (12.81.100.0)  28.420 ms  28.004 ms  44.965 ms
 >11  12.81.56.52 (12.81.56.52)  34.758 ms  32.865 ms  44.985 ms
 >12  12.81.56.65 (12.81.56.65)  30.243 ms  43.389 ms  28.201 ms
 >13  74.175.192.58 (74.175.192.58)  30.299 ms  29.059 ms  30.485 ms
 >14  cr2.rlgnc.ip.att.net (12.123.152.110)  42.259 ms  41.007 ms  41.460 ms
 >15  cr1.wswdc.ip.att.net (12.122.3.170)  39.498 ms  42.094 ms  39.960 ms
 >16  wswdc03jt.ip.att.net (12.122.220.245)  36.170 ms  40.225 ms  34.812 ms
 >17  192.205.32.30 (192.205.32.30)  39.632 ms  38.668 ms  40.288 ms
 >18  * * *
 >19  65.120.78.82 (65.120.78.82)  55.337 ms  41.815 ms  40.946 ms
 >20  72.21.220.157 (72.21.220.157)  41.023 ms
 >21  72.21.222.157 (72.21.222.157)  40.268 ms  45.570 ms
 >22  * 216.182.224.53 (216.182.224.53)  43.835 ms *
 >23  72.21.220.157 (72.21.220.157)  44.234 ms
 >24  72.21.222.157 (72.21.222.157)  41.009 ms
 >25  * 216.182.224.53 (216.182.224.53)  51.225 ms *
 >^C
 -- 
 Dan White
  <CAFn1dUEQd2Rk2oRk5cbwspB1JVxOfDZCHkGf2OvZy5HsoewZ6Q@mail.gmail.com>
 Agree. Clearly AWS issue. Emails crossed. I was investigating and composing when initial AWS post was made.
 --
 Jon R. Kibler
 +001-843-813-2924
 On Oct 22, 2012, at 15:11 , Carlos Alvarez <carlos at televolve.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/b3d6561a/attachment-0001.html>
  <CAFn1dUEQd2Rk2oRk5cbwspB1JVxOfDZCHkGf2OvZy5HsoewZ6Q@mail.gmail.com>
  <225bbb4df62e8ba2a27006f3387208ae@smtp.hushmail.com>
 http://www.forbes.com/sites/kellyclay/2012/10/22/amazon-aws-goes-down-again-takes-reddit-with-it/
 On Mon, Oct 22, 2012 at 3:20 PM, Jon Kibler <jon.r.kibler at hushmail.com> wrote:
  <CAFn1dUEQd2Rk2oRk5cbwspB1JVxOfDZCHkGf2OvZy5HsoewZ6Q@mail.gmail.com>
  <225bbb4df62e8ba2a27006f3387208ae@smtp.hushmail.com>
  <CAOF0KO_U400svKXwir0O5ve26J-WvQbpv+Srt-UCSpDE0X8z0g@mail.gmail.com>
 Well that explains why my foursquare isn't working. Thanks for the link
 Regards,
 Steve
 On Oct 22, 2012, at 12:53 PM, "Charles Mills" <w3yni1 at gmail.com> wrote:
 >>>
 >>> Apple TV Netflix movie interrupted in mid play with message 'Service
 >>> Unavailable.' Attempt to access Netflix menu from Apple TV gives the same
 >>> error. Netflix website also appears to be unreachable... attempts to connect
 >>> simply time out.
 >>>
 >>> Traceroute shows routing loop...
 >>>
 >>> traceroute www.netflix.com
 >>> traceroute: Warning: www.netflix.com has multiple addresses; using
 >>> 23.21.117.205
 >>> traceroute to
 >>> dualstack.wwwservice--frontend-313423742.us-east-1.elb.amazonaws.com
 >>> (23.21.117.205), 64 hops max, 52 byte packets
 >>> 1  (redacted)
 >>> 2  (redacted)
 >>> 3  (redacted)
 >>> 4  72.157.38.25 (72.157.38.25)  30.194 ms  30.465 ms  30.219 ms
 >>> 5  12.81.68.48 (12.81.68.48)  30.949 ms  28.153 ms  48.894 ms
 >>> 6  12.81.68.58 (12.81.68.58)  26.742 ms  29.772 ms  31.019 ms
 >>> 7  ixc01jan-5-0-1.bellsouth.net (65.83.237.89)  29.180 ms  28.781 ms
 >>> 29.882 ms
 >>> 8  12.81.98.50 (12.81.98.50)  30.657 ms  26.810 ms  30.321 ms
 >>> 9  ixc01aep-pos-4-0.bellsouth.net (65.83.237.99)  33.822 ms  32.289 ms
 >>> 50.095 ms
 >>> 10  12.81.100.0 (12.81.100.0)  28.420 ms  28.004 ms  44.965 ms
 >>> 11  12.81.56.52 (12.81.56.52)  34.758 ms  32.865 ms  44.985 ms
 >>> 12  12.81.56.65 (12.81.56.65)  30.243 ms  43.389 ms  28.201 ms
 >>> 13  74.175.192.58 (74.175.192.58)  30.299 ms  29.059 ms  30.485 ms
 >>> 14  cr2.rlgnc.ip.att.net (12.123.152.110)  42.259 ms  41.007 ms  41.460 ms
 >>> 15  cr1.wswdc.ip.att.net (12.122.3.170)  39.498 ms  42.094 ms  39.960 ms
 >>> 16  wswdc03jt.ip.att.net (12.122.220.245)  36.170 ms  40.225 ms  34.812 ms
 >>> 17  192.205.32.30 (192.205.32.30)  39.632 ms  38.668 ms  40.288 ms
 >>> 18  * * *
 >>> 19  65.120.78.82 (65.120.78.82)  55.337 ms  41.815 ms  40.946 ms
 >>> 20  72.21.220.157 (72.21.220.157)  41.023 ms
 >>>    72.21.220.155 (72.21.220.155)  38.581 ms
 >>>    72.21.220.153 (72.21.220.153)  38.489 ms
 >>> 21  72.21.222.157 (72.21.222.157)  40.268 ms  45.570 ms
 >>>    72.21.222.143 (72.21.222.143)  40.980 ms
 >>> 22  * 216.182.224.53 (216.182.224.53)  43.835 ms *
 >>> 23  72.21.220.157 (72.21.220.157)  44.234 ms
 >>>    72.21.220.155 (72.21.220.155)  41.331 ms
 >>>    72.21.220.153 (72.21.220.153)  39.768 ms
 >>> 24  72.21.222.157 (72.21.222.157)  41.009 ms
 >>>    72.21.222.143 (72.21.222.143)  39.889 ms
 >>>    72.21.222.157 (72.21.222.157)  44.337 ms
 >>> 25  * 216.182.224.53 (216.182.224.53)  51.225 ms *
 >>> ^C
 >>>
 >>>
 >>>
 >>> --
 >>> Jon R. Kibler
 >>> +001-843-813-2924
 >>>
 >>>
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 This message contains confidential information and is intended only for the individual named. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. Any opinions presented in this email are solely those of the author and do not necessarily represent those of the company. E-mail transmission cannot be guaranteed to be secure or error?free; the sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e?mail transmission.
  <CAFn1dUEQd2Rk2oRk5cbwspB1JVxOfDZCHkGf2OvZy5HsoewZ6Q@mail.gmail.com>
  <225bbb4df62e8ba2a27006f3387208ae@smtp.hushmail.com>
  <CAOF0KO_U400svKXwir0O5ve26J-WvQbpv+Srt-UCSpDE0X8z0g@mail.gmail.com>
  <036BCED0-7481-4665-8048-ADCC5306DB2C@FusionStorm.com>
 1:02 PM PDT We continue to work to resolve the issue affecting EBS volumes
 in a single availability zone in the US-EAST-1 region. The AWS Management
 Console for EC2 indicates which availability zone is impaired.
 EC2 instances and EBS volumes outside of this availability zone are
 operating normally. Customers can launch replacement instances in the
 unaffected availability zones but may experience elevated launch latencies
 or receive ResourceLimitExceeded errors on their API calls, which are being
 issued to manage load on the system during recovery. Customers receiving
 this error can retry failed requests.
 On Mon, Oct 22, 2012 at 3:12 PM, Steve Di Bias <SDiBias at fusionstorm.com>wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/a9343b2f/attachment-0001.html>
###############################################################
END
###############################################################

###############################################################
Amazon EC2 issues
###############################################################
 Northern Virginia.  Lots of Twitter traffic, acknowledged on
 http://status.aws.amazon.com/
 Personally saw http error 503 from getpocket.com .
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121022/944996e5/attachment.html>
###############################################################
END
###############################################################

###############################################################
Time Warner Central Texas
###############################################################
 Time Warner  for all of Kerr County Texas is down starting at 1:15pm 
 central time.  Might be regional? No ETA per support.
  <8031B167-A3F3-4FAF-ADC6-3F3298388CE8@gizmopartners.com>
 It is TWCable Business Class and it came up at 3:15pm central time. It 
 was down for three hours here in Kerrville.
 On 10/22/2012 3:13 PM, Chris Boyd wrote:
###############################################################
END
###############################################################

###############################################################
Windstream  in Michigan?
###############################################################
 I just got a call from customer and they tell me all Voice for Windstream is DOWN in Michigan..
 I am not sure if it is just voice or data and voice.....
 No other news... does anyone have details on this?
 Thanks,
 Jim
 Jim McBurnett
 CCNP, CCNP-Voice, CCDA
 Senior Network Engineer
 (864) 473-1200
 jim at tgasolutions.com<mailto:jim at tgasolutions.com>
 [cid:image001.png at 01CDB1CD.F6260030]
 Managing IT with Integrity
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/effd973a/attachment.html>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image001.png
 Type: image/png
 Size: 11187 bytes
 Desc: image001.png
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/effd973a/attachment.png>
 We are experience a voice only issue with windstream at our location in
 Troy, MI. Currently inbound or outbound calls on our Windstream trunks are
 working for us. I am calling into windstream now, and as soon as I talk
 with someone I will send another message out.
 Thanks,
 Dave
 On Wed, Oct 24, 2012 at 9:57 AM, Jim McBurnett <jim at tgasolutions.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/8bf665d3/attachment.html>
  <CAJAMK3SuedSk0bk+Uq+8xy3DJWuVbU344yL3HdyDY4N2BxJHyg@mail.gmail.com>
 On 10/24/2012 08:11 AM, David Bitonti wrote:
 MegaPop is also reporting problems in the Detroit area:
 =====================================================================
 At 08:42 on 2012-10-24 the following was posted to DIAL Network Alerts:
 Problem : Dead Air / Busies
 Location: 008 - Detroit, MI
 Status  : Ongoing
 Event   : Major problem with DialUp
 Detailed Description:
 We are experiencing dead air / busies in numbers serviced out of Detroit. We are investigating to restore servers as quickly as possible.
 ETR:
 This message was posted by: eolson, regarding Trouble Ticket: 122813.
 =====================================================================
 Chris
  <CAJAMK3SuedSk0bk+Uq+8xy3DJWuVbU344yL3HdyDY4N2BxJHyg@mail.gmail.com>
  <5087FB05.6000808@axint.net>
 apparently it's a more severe problem. I received this update less
 than 60 seconds ago:
 Problem : Dead Air / Busies
 Location: 801 - Regional,
 Status  : Ongoing
 Event   : Major problem with the VoIP
 Detailed Description:
 We are experiencing call failures in the following regions:
 Cedar Rapids
 Springfield, IL
 Madison, WI
 Green Bay, WI
 Minneapolis
 Sioux Falls
 Omaha
 Des Moines
 Dubuque
 Fargo
 St. Louis
 Davenport
 Kansas City
 Detroit
 ETR:
 This message was posted by: eolson, regarding Trouble Ticket: 122812.
 On Wed, Oct 24, 2012 at 10:28 AM, Chris Stone <cstone at axint.net> wrote:
  <CAJAMK3SuedSk0bk+Uq+8xy3DJWuVbU344yL3HdyDY4N2BxJHyg@mail.gmail.com>
  <5087FB05.6000808@axint.net>
 We are currently experiencing a voice outage with windstream affecting our customers in Council Bluffs, Iowa all numbers get a fast busy when dialed. I was not able to get to a tech in the windstream NOC due to "high call volume".............left message awaiting their CB. 
 Best Regards,
 Jeff Hanslik
 (813) 933-6767 x2127
 jeff.hanslik at pressone.net
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Chris Stone
 Sent: Wednesday, October 24, 2012 10:28
 On 10/24/2012 08:11 AM, David Bitonti wrote:
 MegaPop is also reporting problems in the Detroit area:
 =====================================================================
 At 08:42 on 2012-10-24 the following was posted to DIAL Network Alerts:
 Problem : Dead Air / Busies
 Location: 008 - Detroit, MI
 Status  : Ongoing
 Event   : Major problem with DialUp
 Detailed Description:
 We are experiencing dead air / busies in numbers serviced out of Detroit. We are investigating to restore servers as quickly as possible.
 ETR:
 This message was posted by: eolson, regarding Trouble Ticket: 122813.
 =====================================================================
 Chris
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <CAJAMK3SuedSk0bk+Uq+8xy3DJWuVbU344yL3HdyDY4N2BxJHyg@mail.gmail.com>
  <5087FB05.6000808@axint.net>
  <4C7341188F8A5F458753105ECAA6696D08BCA501@ponycwsex01.pressone.net>
 At 11:33 [Central] on 2012-10-24 the following was posted to VOIP
 Network Alerts:
 Problem : Dead Air / Busies
 Location: 801 - Regional,
 Status  : Ongoing
 Event   :
 Detailed Description:
 Greetings,
   There are three separate issues affecting our network, one is a
 hardware issues and two fiber cuts.  For now we are grouping them
 together for this service as it has not been determined which issue(s)
 are affecting which part(s) of the VoIP Origination service.
 ###
 On Wed, Oct 24, 2012 at 10:47 AM, Jeff Hanslik
 <Jeff.Hanslik at pressone.net> wrote:
###############################################################
END
###############################################################

###############################################################
Windstream in Michigan?
###############################################################
 This is what we have from them (its mistakenly categorized as dialup):
 Problem : Dead Air / Busies
 Location: 008 - Detroit, MI
 Status  : Ongoing
 Event   : Major problem with DialUp
 Detailed Description:
 We are experiencing dead air / busies in numbers serviced out of Detroit.
 We are investigating to restore servers as quickly as possible.
 ------------------
 Aubrey Wells
 Director | Network Services
 VocalCloud
 678.248.2637
 support at vocalcloud.com
 www.vocalcloud.com
 On Wed, Oct 24, 2012 at 9:57 AM, Jim McBurnett <jim at tgasolutions.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/3b6425f9/attachment-0001.html>
 We're seeing Voice outage via a Windstream SIP trunk being delivered to Milwaukee in Windstream colo.
 I'm also seeing multiple MPLS sites down in North-Central IL and South-Central Wisconsin.  All of it went down around 7:30am CDT.
 ================================
 Nick "Bernie" Bernhardt
 Network Administrator
 Landmark Services Cooperative
 nick.bernhardt at landmark.coop<mailto:nick.bernhardt at landmark.coop>
 ================================
 "We are a COOPERATIVE business dedicated to providing rural and urban customers with the HIGHEST QUALITY products and services.  We will enhance our producers' profitability, EXCEED customer expectations and keep our cooperative financially STRONG."
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/1bf9471b/attachment.html>
 Outage being experienced in Detroit Metro/Willow Run Airport Area. No
 ETA's from Windstream, also heard that fiber was cut.
 Regards,
 Mark 
 System Support Specialist
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/763b5b02/attachment-0001.html>
 Due to a fiber cut 141 DS3's are impacted in Grand Rapids.
 ----- Original Message -----
 From: "Jonathan Nalley" <jnalley at jnalley.com>
 Sent: Wednesday, October 24, 2012 1:02:13 PM
 At 11:33 [Central] on 2012-10-24 the following was posted to VOIP
 Network Alerts:
 Problem : Dead Air / Busies
 Location: 801 - Regional,
 Status  : Ongoing
 Event   :
 Detailed Description:
 Greetings,
   There are three separate issues affecting our network, one is a
 hardware issues and two fiber cuts.  For now we are grouping them
 together for this service as it has not been determined which issue(s)
 are affecting which part(s) of the VoIP Origination service.
 ###
 On Wed, Oct 24, 2012 at 10:47 AM, Jeff Hanslik
 <Jeff.Hanslik at pressone.net> wrote:
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
###############################################################
END
###############################################################

###############################################################
Windstream in Mighican?
###############################################################
 Oh, and I almost forgot, our Sales rep indicated that there was a fiber cut somewhere that was affecting service throughout MI and WI, so that seems consistent with what's being seeing by a lot of people.
 ================================
 Nick "Bernie" Bernhardt
 nick.bernhardt at landmark.coop
 ================================
 "We are a COOPERATIVE business dedicated to providing rural and urban customers with the HIGHEST QUALITY products and services.? We will enhance our producers' profitability, EXCEED customer expectations and keep our cooperative financially STRONG."
###############################################################
END
###############################################################

###############################################################
Windstream Voice Outae in Grand Rapids
###############################################################
 Just to confirm we also have multiple locations with voice outages in
 Grand Rapids. 
   <http://www.grymca.org/> Rob Thompson
 IT Support
 YMCA of Greater Grand Rapids
 475 Lake Michigan Drive NW, Grand Rapids, MI  49504
 616.855.9639 direct I 616.855.9601 fax I  grymca.org
 <http://www.grymca.org/> 
 Strengthening our community through youth development, healthy living,
 and social responsibility.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/9357dffe/attachment-0001.html>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image001.jpg
 Type: image/jpeg
 Size: 54607 bytes
 Desc: image001.jpg
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/9357dffe/attachment-0002.jpg>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image002.jpg
 Type: image/jpeg
 Size: 1835 bytes
 Desc: image002.jpg
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/9357dffe/attachment-0003.jpg>
###############################################################
END
###############################################################

###############################################################
Windstream Outage affecting Illinois
###############################################################
 Others have reported the outages for Windstream in Michigan. Illinois is also affected. We were forced to leave messages with Tech Support and cannot open a case. Our account manager's voicemail indicates a fiber cut in in the Midwest.
 Amy Sass
 CITES Windows Systems Admin
 2531 DCL
 1304 W. Springfield Ave.
 Urbana, IL 61801
 (217)265-0531
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/0d90f3cc/attachment.html>
 >From what I have read it appears there is a fiber cut in Indiana and a
 hardware failure in Wisconsin. Windstream also has an updated messag on the
 NOC number indicating the issue covers the enitre mid-west region and no
 ETR as of yet.
 http://royaloak.patch.com/articles/sporadic-outages-hit-phone-service-throughout-oakland-county-c303fd4a
 Thanks,
 Dave
 On Wed, Oct 24, 2012 at 12:55 PM, Sass, Amy <amysass at illinois.edu> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/48035fa7/attachment.html>
  <CAJAMK3R3eMJPDZvdirOC8juCt+tQE7aJP4X7hjqnC=L0skYhcA@mail.gmail.com>
 More here:
 http://www.freep.com/article/20121024/NEWS03/121024036/Phone-service-outage-
 affects-4-states-causing-problems-metro-Detroiters
 Frank
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of David Bitonti
 Sent: Wednesday, October 24, 2012 12:09 PM
 Cc: outages at outages.org
 >From what I have read it appears there is a fiber cut in Indiana and a
 hardware failure in Wisconsin. Windstream also has an updated messag on the
 NOC number indicating the issue covers the enitre mid-west region and no ETR
 as of yet.
 http://royaloak.patch.com/articles/sporadic-outages-hit-phone-service-throug
 hout-oakland-county-c303fd4a
 Thanks,
 Dave
 On Wed, Oct 24, 2012 at 12:55 PM, Sass, Amy <amysass at illinois.edu> wrote:
 Others have reported the outages for Windstream in Michigan. Illinois is
 also affected. We were forced to leave messages with Tech Support and cannot
 open a case. Our account manager's voicemail indicates a fiber cut in in the
 Midwest.
 Amy Sass
 CITES Windows Systems Admin
 2531 DCL
 1304 W. Springfield Ave.
 Urbana, IL 61801
 (217)265-0531 <tel:%28217%29265-0531> 
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/f2e16656/attachment.html>
  <CAJAMK3R3eMJPDZvdirOC8juCt+tQE7aJP4X7hjqnC=L0skYhcA@mail.gmail.com>
 http://www.freep.com/article/20121024/NEWS03/121024036/Phone-service-outage-affects-4-states-causing-problems-metro-Detroiters
 On Wed, Oct 24, 2012 at 12:09 PM, David Bitonti <dbitonti1 at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/50cdb11c/attachment.html>
###############################################################
END
###############################################################

###############################################################
Windstream Outage Affecting Ohio?
###############################################################
 We out experiencing the following issues at our Columbus, OH facility:
 Inbound Long-Distance and Local Calls - Calls are either routed to the wrong business, ring busy, or the call is completed with no audio at either end.
 Outbound Long-Distance Calls - Calls seem to complete but no audio is heard on either end.
 While these symptoms sound similar to reports from WI and MI, the Windstream rep we spoke with was not sure if the cut fiber was affecting OH as well so a ticket was opened.
 Joe Ghammashi
 Manager, NDS Infrastructure
 Norse Dairy Systems
 1740 Joyce Avenue
 Columbus, Ohio 43219
 United States of America
 Work: +1.614.421.5294
 Fax: +1.614.421.5494
 Email: jghammashi at norse.com
 An engineer from Windstream has confirmed that our outage in Columbus, OH is also related to the larger outage affecting the upper mid-west region.
 Joe Ghammashi
 +1.614.421.5294
 norse.com
 ? Please think before printing this email
 -----Original Message-----
 From: Joe Ghammashi (IBF) 
 Sent: Wednesday, October 24, 2012 1:44 PM
 We out experiencing the following issues at our Columbus, OH facility:
 Inbound Long-Distance and Local Calls - Calls are either routed to the wrong business, ring busy, or the call is completed with no audio at either end.
 Outbound Long-Distance Calls - Calls seem to complete but no audio is heard on either end.
 While these symptoms sound similar to reports from WI and MI, the Windstream rep we spoke with was not sure if the cut fiber was affecting OH as well so a ticket was opened.
 Joe Ghammashi
 Manager, NDS Infrastructure
 Norse Dairy Systems
 1740 Joyce Avenue
 Columbus, Ohio 43219
 United States of America
 Work: +1.614.421.5294
 Fax: +1.614.421.5494
 Email: jghammashi at norse.com
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE81@IBFCOLXCH1.ibfnet.us>
 Just got word from some higher-ups in Windstream that the Voice issue is supposedly on track for resolution around 15:00 CDT.
 Consider me hopeful, yet highly skeptical.
 ================================
 Nick ?Bernie? Bernhardt
  (608) 819-3153
 nick.bernhardt at landmark.coop
 ================================
 ?We are a COOPERATIVE business dedicated to providing rural and urban customers with the HIGHEST QUALITY products and services.? We will enhance our producers? profitability, EXCEED customer expectations and keep our cooperative financially STRONG.?
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Joe Ghammashi (IBF)
 Sent: Wednesday, October 24, 2012 02:10 PM
 An engineer from Windstream has confirmed that our outage in Columbus, OH is also related to the larger outage affecting the upper mid-west region.
 Joe Ghammashi
 +1.614.421.5294
 norse.com
 ? Please think before printing this email
 -----Original Message-----
 From: Joe Ghammashi (IBF) 
 Sent: Wednesday, October 24, 2012 1:44 PM
 We out experiencing the following issues at our Columbus, OH facility:
 Inbound Long-Distance and Local Calls - Calls are either routed to the wrong business, ring busy, or the call is completed with no audio at either end.
 Outbound Long-Distance Calls - Calls seem to complete but no audio is heard on either end.
 While these symptoms sound similar to reports from WI and MI, the Windstream rep we spoke with was not sure if the cut fiber was affecting OH as well so a ticket was opened.
 Joe Ghammashi
 Manager, NDS Infrastructure
 Norse Dairy Systems
 1740 Joyce Avenue
 Columbus, Ohio 43219
 United States of America
 Work: +1.614.421.5294
 Fax: +1.614.421.5494
 Email: jghammashi at norse.com
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE81@IBFCOLXCH1.ibfnet.us>
  <B73793E34A78FE4A8A35710519486D94849AFEB4@ldmk-exch01.landmark.int>
 Just did some testing from a PRI in our Downtown Chicago office and the
 call connects however there is no audio.  This is also affecting a larger
 office in Aurora, IL.  We hare not hearing anything like an ETR from our
 contacts (mostly in the business side of Windstream), just the unhappiness
 that goes with a major outage.
 On Wed, Oct 24, 2012 at 3:32 PM, bernie listsub <
 bernie.listsub at landmark.coop> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/4409ad5f/attachment-0001.html>
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE81@IBFCOLXCH1.ibfnet.us>
  <B73793E34A78FE4A8A35710519486D94849AFEB4@ldmk-exch01.landmark.int>
  <CABaBBjujrH4iv-YofEB_Oy0z06q4BdUcGEwZRSMqGg28HQBcrA@mail.gmail.com>
 Issue appears to be affecting service in several facilities here in Pennsylvania as well.  We are unable to make outgoing calls to Verizon customers.  Long distance service to other vendors is currently working.  Inbound calls from Verizon customers are successful, but outbound calls are not routing properly.  Windstream rep was not sure if this issue was related to the outage in the Midwest.  I was told not to expect an update on this until Friday.
 Lance
 Sullivan County School District
 From: Russell Goings [mailto:russgoings at gmail.com]
 Sent: Wednesday, October 24, 2012 3:59 PM
 Just did some testing from a PRI in our Downtown Chicago office and the call connects however there is no audio.  This is also affecting a larger office in Aurora, IL.  We hare not hearing anything like an ETR from our contacts (mostly in the business side of Windstream), just the unhappiness that goes with a major outage.
 On Wed, Oct 24, 2012 at 3:32 PM, bernie listsub <bernie.listsub at landmark.coop<mailto:bernie.listsub at landmark.coop>> wrote:
 Just got word from some higher-ups in Windstream that the Voice issue is supposedly on track for resolution around 15:00 CDT.
 Consider me hopeful, yet highly skeptical.
 ================================
 Nick ?Bernie? Bernhardt
  (608) 819-3153<tel:%28608%29%20819-3153>
 nick.bernhardt at landmark.coop<mailto:nick.bernhardt at landmark.coop>
 ================================
 ?We are a COOPERATIVE business dedicated to providing rural and urban customers with the HIGHEST QUALITY products and services.  We will enhance our producers? profitability, EXCEED customer expectations and keep our cooperative financially STRONG.?
 -----Original Message-----
 From: outages-bounces at outages.org<mailto:outages-bounces at outages.org> [mailto:outages-bounces at outages.org<mailto:outages-bounces at outages.org>] On Behalf Of Joe Ghammashi (IBF)
 Sent: Wednesday, October 24, 2012 02:10 PM
 An engineer from Windstream has confirmed that our outage in Columbus, OH is also related to the larger outage affecting the upper mid-west region.
 Joe Ghammashi
 +1.614.421.5294<tel:%2B1.614.421.5294>
 norse.com<http://norse.com>
 ? Please think before printing this email
 -----Original Message-----
 From: Joe Ghammashi (IBF)
 Sent: Wednesday, October 24, 2012 1:44 PM
 We out experiencing the following issues at our Columbus, OH facility:
 Inbound Long-Distance and Local Calls - Calls are either routed to the wrong business, ring busy, or the call is completed with no audio at either end.
 Outbound Long-Distance Calls - Calls seem to complete but no audio is heard on either end.
 While these symptoms sound similar to reports from WI and MI, the Windstream rep we spoke with was not sure if the cut fiber was affecting OH as well so a ticket was opened.
 Joe Ghammashi
 Manager, NDS Infrastructure
 Norse Dairy Systems
 1740 Joyce Avenue
 Columbus, Ohio 43219
 United States of America
 Work: +1.614.421.5294<tel:%2B1.614.421.5294>
 Fax: +1.614.421.5494<tel:%2B1.614.421.5494>
 Email: jghammashi at norse.com<mailto:jghammashi at norse.com>
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/1cbfe651/attachment.html>
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE81@IBFCOLXCH1.ibfnet.us>
  <B73793E34A78FE4A8A35710519486D94849AFEB4@ldmk-exch01.landmark.int>
  <CABaBBjujrH4iv-YofEB_Oy0z06q4BdUcGEwZRSMqGg28HQBcrA@mail.gmail.com>
 Looks like we are coming back online here in Columbus, OH.  I?ve been able to places and receive test calls in the last 30 minutes.
 Joe Ghammashi
 +1.614.421.5294
 norse.com<http://norse.com/>
 [cid:image001.png at 01CDB206.6C9319A0]
 P Please think before printing this email
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Russell Goings
 Sent: Wednesday, October 24, 2012 3:59 PM
 Just did some testing from a PRI in our Downtown Chicago office and the call connects however there is no audio.  This is also affecting a larger office in Aurora, IL.  We hare not hearing anything like an ETR from our contacts (mostly in the business side of Windstream), just the unhappiness that goes with a major outage.
 On Wed, Oct 24, 2012 at 3:32 PM, bernie listsub <bernie.listsub at landmark.coop<mailto:bernie.listsub at landmark.coop>> wrote:
 Just got word from some higher-ups in Windstream that the Voice issue is supposedly on track for resolution around 15:00 CDT.
 Consider me hopeful, yet highly skeptical.
 ================================
 Nick ?Bernie? Bernhardt
  (608) 819-3153<tel:%28608%29%20819-3153>
 nick.bernhardt at landmark.coop<mailto:nick.bernhardt at landmark.coop>
 ================================
 ?We are a COOPERATIVE business dedicated to providing rural and urban customers with the HIGHEST QUALITY products and services.  We will enhance our producers? profitability, EXCEED customer expectations and keep our cooperative financially STRONG.?
 -----Original Message-----
 From: outages-bounces at outages.org<mailto:outages-bounces at outages.org> [mailto:outages-bounces at outages.org<mailto:outages-bounces at outages.org>] On Behalf Of Joe Ghammashi (IBF)
 Sent: Wednesday, October 24, 2012 02:10 PM
 An engineer from Windstream has confirmed that our outage in Columbus, OH is also related to the larger outage affecting the upper mid-west region.
 Joe Ghammashi
 +1.614.421.5294<tel:%2B1.614.421.5294>
 norse.com<http://norse.com>
 ? Please think before printing this email
 -----Original Message-----
 From: Joe Ghammashi (IBF)
 Sent: Wednesday, October 24, 2012 1:44 PM
 We out experiencing the following issues at our Columbus, OH facility:
 Inbound Long-Distance and Local Calls - Calls are either routed to the wrong business, ring busy, or the call is completed with no audio at either end.
 Outbound Long-Distance Calls - Calls seem to complete but no audio is heard on either end.
 While these symptoms sound similar to reports from WI and MI, the Windstream rep we spoke with was not sure if the cut fiber was affecting OH as well so a ticket was opened.
 Joe Ghammashi
 Manager, NDS Infrastructure
 Norse Dairy Systems
 1740 Joyce Avenue
 Columbus, Ohio 43219
 United States of America
 Work: +1.614.421.5294<tel:%2B1.614.421.5294>
 Fax: +1.614.421.5494<tel:%2B1.614.421.5494>
 Email: jghammashi at norse.com<mailto:jghammashi at norse.com>
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/454e2063/attachment-0001.html>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image001.png
 Type: image/png
 Size: 15909 bytes
 Desc: image001.png
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/454e2063/attachment-0001.png>
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE81@IBFCOLXCH1.ibfnet.us>
  <B73793E34A78FE4A8A35710519486D94849AFEB4@ldmk-exch01.landmark.int>
  <CABaBBjujrH4iv-YofEB_Oy0z06q4BdUcGEwZRSMqGg28HQBcrA@mail.gmail.com>
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE88@IBFCOLXCH1.ibfnet.us>
 Our T1 in Appleton WI has come back online as well.
 On Wed, Oct 24, 2012 at 4:41 PM, Joe Ghammashi (IBF)
 <jghammashi at norse.com> wrote:
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE81@IBFCOLXCH1.ibfnet.us>
  <B73793E34A78FE4A8A35710519486D94849AFEB4@ldmk-exch01.landmark.int>
  <CABaBBjujrH4iv-YofEB_Oy0z06q4BdUcGEwZRSMqGg28HQBcrA@mail.gmail.com>
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE88@IBFCOLXCH1.ibfnet.us>
  <CAPC+kK6T+8oTTQXGH9QR=2TPZ9vRddWrpFFeOz9JyXFDB5rE0w@mail.gmail.com>
 At around 17:00 EDT our long distance came back up for both our Chicago
 office and our Aurora office.  The call quality was at best 4 X 4 with some
 echo and just a little muddy.  I expect that will improve and will check
 things tomorrow morning.
    I am pleased with the level of information I was able to find on this
 list as our friends at Windstream appeared to be just a little busy during
 this time.  I am well aware of how little I like management  asking me
 "How's it going" every few seconds (or so it seems) when things are broken
 and I know I can be just a little short on real info at those times.
 Russell Goings
 Sysadmin - Feld Entertainment, Inc.
 On Wed, Oct 24, 2012 at 4:54 PM, Mitch <mitpatterson at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121024/a49da7ac/attachment.html>
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE81@IBFCOLXCH1.ibfnet.us>
  <B73793E34A78FE4A8A35710519486D94849AFEB4@ldmk-exch01.landmark.int>
  <CABaBBjujrH4iv-YofEB_Oy0z06q4BdUcGEwZRSMqGg28HQBcrA@mail.gmail.com>
  <99A46960531FF94380CFEB59CC0B30B6D10B8BFE88@IBFCOLXCH1.ibfnet.us>
  <CAPC+kK6T+8oTTQXGH9QR=2TPZ9vRddWrpFFeOz9JyXFDB5rE0w@mail.gmail.com>
  <CABaBBjs8C5ZyGqQvUcPWtLjyaLBoqbN8GKa-ri9HAUZjUWFu5w@mail.gmail.com>
 Anyone else seeing things back down? i just had 4 t1's go down in the
 WI area same as last time.... going to call Patec/windstream.
 On Wed, Oct 24, 2012 at 6:34 PM, Russell Goings <russgoings at gmail.com> wrote:
###############################################################
END
###############################################################

###############################################################
Windstream Outage affecting Oregon
###############################################################
 We seem to be suffering from dropped calls and audio issues as well.  Our SIP provider, Vitelity (based in Denver), is blaming it their upstream provider Paetec (who it appears is now part of Windstream, who I'd never heard of until today), so this issue seems to be affecting much more than the Midwest states as both us and Paetec are based in Portland Oregon.
 Rhiannon Ball?| Systems Administrator | NVoicePay
 10250 SW Greenburg Rd, Suite 112 | Portland, OR 97223
 office 503.974.1770 |?fax 971.925.4173
 rhiannon.ball at nvoicepay.com
 www.nvoicepay.com
###############################################################
END
###############################################################

###############################################################
gblx issues Europe to US
###############################################################
 Anyone experiences issues on GBLX. Cannot traverse from a GBLX port in Europe to a GBLX port in US. Also tried Level3 and Limelight out of Europe with no success.
 Works from the US
 Tracing the route to IP node (206.165.73.78) from 1 to 30 hops
   1    <1 ms   <1 ms   <1 ms TenGigabitEthernet7-3.ar2.MAD1.gblx.net [64.215.82.125]
   2    *       *       *     ?
   3    *       *       *     ?
   4    *       *       *     ?
   5    *       *       *     ?
 Tracing the route to IP node (206.165.73.78) from 1 to 30 hops
   1     1 ms   <1 ms   <1 ms tge8-4.fr3.mad1.llnw.net [87.248.204.193]
   2     3 ms    1 ms    1 ms gigabitethernet1-0-2.madcr3.Madrid.opentransit.net [193.251.248.77]
   3    24 ms   23 ms   23 ms po1-101-10G.ar2.MAD1.gblx.net [64.215.195.9]
   4    *       *       *     ?
   5    *    ^C
 EC
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121025/837a8d28/attachment.html>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 On 10/25/2012 08:17 AM, Erick Caldera wrote:
 - ---------------------
 Don't have a node off gblx but I'm able to hit certain gblx device(s)
 off Interxion DC traversing gblx-level3-ae.amsterdam1.Level3.net /
 limelight-gw.ip4.tinet.net  just fine.
 Do you have specifics?
 regards,
 /virendra
 Hi,
 On Thu, Oct 25, 2012 at 03:17:26PM +0000, Erick Caldera wrote:
 Yeah, this is exactly why we terminated our contract with GBLX.
 Frequent black holes in their MPLS network, and no traceroute capability to
 be able to pinpoint the point of brokenness.
 (Worse, it might even be the customer egress router on the other side
 that's missing a return route(!), but you can't see whether it does inside
 GBLX or not)
 gert
 -- 
 USENET is *not* the non-clickable part of WWW!
                                                            //www.muc.de/~gert/
 Gert Doering - Munich, Germany                             gert at greenie.muc.de
 fax: +49-89-35655025                        gert at net.informatik.tu-muenchen.de
  <20121025173231.GR742@greenie.muc.de>
 On Thu, Oct 25, 2012 at 07:32:31PM +0200, Gert Doering wrote:
 Some clarification: I've seen two types of MPLS in use: layer 2 and
 layer 3.
 Layer 2 MPLS (ex. Abovenet "long-haul" setups) behaves like what's
 described above; you have no visibility into the MPLS network via a
 traceroute -- even if done on the device where the circuit terminates;
 thus naturally traceroute isn't going to see anything "in between".
 Layer 3 MPLS (ex. AT&T "long-haul" setups) provides visibility as long
 as the traceroute is done from the device where the circuit (Ethernet,
 SONET, etc.) terminates.  In this case, traceroute from the terminating
 device will provide visibility within the MPLS network.  An added bonus
 is when the traceroute utility supports MPLS tag decoding.  :-)
 I had to deal with this ordeal on a near-weekly basis at a past job
 where both types of MPLS were in use simultaneously (separate circuits
 of course).  L2 MPLS requires -- no, *demands* -- the carrier be on the
 ball about monitoring their circuits and being able to very quickly,
 while on the phone, trace everything back to a common point.
 The only advice I can give regarding L2 MPLS is after every outage,
 have a long phone conversation with the carrier and set expectations.
 Do this every single time.  Get network engineers and your account rep
 on the call.  I speak from experience when I say this is the only way
 to get L2 MPLS providers to improve.
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
###############################################################
END
###############################################################

###############################################################
[outage] US - Nationwide - Frontier DSL Service
###############################################################
 I am having some routing issues with my Frontier DSL service (residential)
 and after speaking with technical support at Frontier, they confirmed they
 are having a nationwide routing issue with no ETA currently on the fix.
 Packet loss is intermittent regardless of destination.
 -- 
 - Anthony Hook
 Network Engineer
 Northern Wisconsin
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121025/76c62b70/attachment.html>
 Thanks -- that explains why our email server queues are backed up for both frontiernet.net and frontier.com destinations.
 Frank
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Anthony Hook
 Sent: Thursday, October 25, 2012 10:05 PM
 I am having some routing issues with my Frontier DSL service (residential) and after speaking with technical support at Frontier, they confirmed they are having a nationwide routing issue with no ETA currently on the fix.
 Packet loss is intermittent regardless of destination.
 -- 
 - Anthony Hook
 Network Engineer
 Northern Wisconsin
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121025/11389251/attachment.html>
  <004601cdb328$e42c88c0$ac859a40$@iname.com>
 Also, may be entirely related, and somewhat (read: very) alarming:
 http://www.internettrafficreport.com/namerica.htm
 Those numbers are not pretty.
 -Anthony Hook
 Network Engineer
 Northern Wisconsin
 On Thu, Oct 25, 2012 at 10:20 PM, Frank Bulk <frnkblk at iname.com> wrote:
 -- 
 - Anthony Hook
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121025/03205e11/attachment.html>
 That explains the down/slow response alerts im getting my residential DSL I
 am using for my pbx in Ohio, I just got home and was going to investigate
 On Oct 25, 2012 11:10 PM, "Anthony Hook" <anthony.hook3 at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121025/3d4d28c7/attachment-0001.html>
  <004601cdb328$e42c88c0$ac859a40$@iname.com>
  <CAAdV5S4FtfF_L_A_cZ_YxMFvqBR_PODzbUeShxi0fbL+LxzvTg@mail.gmail.com>
 Most of those zeroes have been zero for a long time.  The ITR isn?t well-maintained and I wouldn?t use the data as a primary source.
 Frank
 From: Anthony Hook [mailto:anthony.hook3 at gmail.com] 
 Sent: Thursday, October 25, 2012 10:23 PM
 Cc: outages at outages.org; mailop at mailop.org
 Also, may be entirely related, and somewhat (read: very) alarming:
 http://www.internettrafficreport.com/namerica.htm
 Those numbers are not pretty.
 -Anthony Hook
 Network Engineer
 Northern Wisconsin
 On Thu, Oct 25, 2012 at 10:20 PM, Frank Bulk <frnkblk at iname.com <mailto:frnkblk at iname.com> > wrote:
 Thanks -- that explains why our email server queues are backed up for both frontiernet.net <http://frontiernet.net>  and frontier.com <http://frontier.com>  destinations.
 Frank
 From: outages-bounces at outages.org <mailto:outages-bounces at outages.org>  [mailto:outages-bounces at outages.org <mailto:outages-bounces at outages.org> ] On Behalf Of Anthony Hook
 Sent: Thursday, October 25, 2012 10:05 PM
 I am having some routing issues with my Frontier DSL service (residential) and after speaking with technical support at Frontier, they confirmed they are having a nationwide routing issue with no ETA currently on the fix.
 Packet loss is intermittent regardless of destination.
 -- 
 - Anthony Hook
 Network Engineer
 Northern Wisconsin
 -- 
 - Anthony Hook
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121025/18c1b8d9/attachment.html>
  <004601cdb328$e42c88c0$ac859a40$@iname.com>
  <CAAdV5S4FtfF_L_A_cZ_YxMFvqBR_PODzbUeShxi0fbL+LxzvTg@mail.gmail.com>
  <004b01cdb329$9eb9f330$dc2dd990$@iname.com>
 Noted, I wasn't aware.
 Thanks for the protip.
 -Anthony
 On Thu, Oct 25, 2012 at 10:25 PM, Frank Bulk <frnkblk at iname.com> wrote:
 -- 
 - Anthony Hook
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121025/2a255e21/attachment.html>
  <CAPC+kK6CRH8vXV2EjgAhz5zTvMVQG7y2G8D3G5HsjAnwtCmq9g@mail.gmail.com>
 Does anyone know when this cleared up?  I saw my email queues go down before
 midnight Central, so if that's any indicator, there was some kind of
 improvement.
 Frank
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Mitch
 Sent: Thursday, October 25, 2012 10:24 PM
 Cc: outages at outages.org
 That explains the down/slow response alerts im getting my residential DSL I
 am using for my pbx in Ohio, I just got home and was going to investigate
 On Oct 25, 2012 11:10 PM, "Anthony Hook" <anthony.hook3 at gmail.com
 <mailto:anthony.hook3 at gmail.com> > wrote:
 I am having some routing issues with my Frontier DSL service (residential)
 and after speaking with technical support at Frontier, they confirmed they
 are having a nationwide routing issue with no ETA currently on the fix.
 Packet loss is intermittent regardless of destination.
 -- 
 - Anthony Hook
 Network Engineer
 Northern Wisconsin
 _______________________________________________
 Outages mailing list
 Outages at outages.org <mailto:Outages at outages.org> 
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/0851767a/attachment.html>
  <CAPC+kK6CRH8vXV2EjgAhz5zTvMVQG7y2G8D3G5HsjAnwtCmq9g@mail.gmail.com>
  <005a01cdb375$f47a8c70$dd6fa550$@iname.com>
 I just got off the phone with customer service, it appears that everything
 is resolved at this time. They reporting no outages right now.
 Thanks,
 Anthony
 On Oct 26, 2012 7:36 AM, "Frank Bulk" <frnkblk at iname.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/8c7ce2a3/attachment-0001.html>
###############################################################
END
###############################################################

###############################################################
Major Internet Outage Takes Down Dropbox, Google App Engine
###############################################################
 http://thenextweb.com/insider/2012/10/26/major-sites-and-platforms-experienc
 ing-outages-today-including-dropbox-and-google-app-engine/
 FYI
 The article states "uplink providers"
 I wonder what provider it was with all of the other repercussions.
 On 10/26/12 2:54 PM, "Frank Bulk" <frnkblk at iname.com> wrote:
 >ing-outages-today-including-dropbox-and-google-app-engine/
###############################################################
END
###############################################################

###############################################################
Verizon Wireless - Backup Assiatant is down not syncing
###############################################################
 https://community.verizonwireless.com/thread/784836
 Ephesians 4:32  &  Cheers!!!
 A password is like a... toothbrush  ;^) 
 Choose a good one, change it regularly and don't share it.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/4df93e6f/attachment.html>
 Perhaps it's irony, but I'm unable to load that page.
 Is there a quick summary you can provide?
 Thanks,
 Anthony
 On Oct 26, 2012 2:40 PM, "Network IPdog" <network.ipdog at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/0b4318d0/attachment.html>
###############################################################
END
###############################################################

###############################################################
AT&T DNS problems?
###############################################################
 We are the primary DNS servers for the ben.edu domain. We seem to be having an issue with an AT&T server that is responding  with incorrect A records for www.ben.edu<http://www.ben.edu> and ben.edu.
 What it SHOULD be the response:
 nslookup www.ben.edu
 Server:         63.250.224.66
 Address:        63.250.224.66#53
 www.ben.edu     canonical name = ben.edu.
 Name:   ben.edu
 Address: 38.100.120.100
 What 12.127.17.83 is responding with:
 Server:  tbru.br.rs.els-gms.att.net
 Address:  12.127.17.83
 Non-authoritative answer:
 Name:    www.ben.edu
 Address:  208.91.197.132
 This appears to be affecting only iPhones and iPads on the AT&T network. Is anybody else having problems with this? Are there any AT&T people on this list that can help?
 Tim Huffman
 Business Only Broadband
 777 Oakmont Lane, Suite 2000, Westmont, IL 60559
 Direct: 630.590.6012 | Main: 630.590.6000 | Fax: 630.986.2496
 thuffman at bobbroadband.com<mailto:thuffman at bobbroadband.com>  |  http://www.bobbroadband.com/
 Cell:  630.340.1925 | Toll-Free Customer Support:  877.262.4553
 [https://staticapp.icpsc.com/icp/loadimage.php/mogile/933825/747f0f3e66a4e0ce7633ff898bfc5121/image/png]  Follow Us on LinkedIn<http://www.linkedin.com/company/business-only-broadband>  |  [https://files.icontact.com/templates/v2/CleanAndSimple/images/twitter.gif]   Follow Us on Twitter<https://twitter.com/#%21/BOBbroadband>
 P please consider the environment prior to printing
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121027/2fd25c49/attachment-0001.html>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image001.png
 Type: image/png
 Size: 2480 bytes
 Desc: image001.png
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121027/2fd25c49/attachment-0001.png>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image002.gif
 Type: image/gif
 Size: 1287 bytes
 Desc: image002.gif
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121027/2fd25c49/attachment-0001.gif>
 208.91.197.132 doesn't have a PTR record associated with it, but a Whois
 query shows that it's owned by Confluence Networks. However, check out what
 happens when you go to that IP address:
 $ nc -v 208.91.197.132 80
 Connection to 208.91.197.132 80 port [tcp/http] succeeded!
 GET / HTTP/1.1
 Host: ben.edu
 HTTP/1.1 200 OK
 Date: Sat, 27 Oct 2012 01:14:43 GMT
 Server: Apache/2.2.3 (Red Hat)
 X-Powered-By: PHP/5.3.16
 Vary: Accept-Encoding,User-Agent
 Content-Length: 712
 Content-Type: text/html; charset=UTF-8
 <frameset rows="100%,*" frameborder="no" border="0" framespacing="0">
         <frame
 src="http://ben.edu/?fp=Jg2bOCRGpmyIHeO3rTIpYJil8%2FmPB1JibWwClQntyhm4NkwKKu
 Ck1tgtON7LOnmXFywl8MRjELrKlXFXgOfhOw%3D%3D&prvtof=lJY3O5r6C%2F4Iypq21CJp7a1L
 uqqIdOWvKdwx5Xsl1x8%3D&poru=S87wfqjj4W%2B%2Fm8dSEqpuWZr20KvK367%2BCoGC%2FHW2
 e9kL6N%2Fl3h3wnDx5AfKbrhlZ&">
 </frameset>
 <noframes>
         <body bgcolor="#ffffff" text="#000000">
         <a
 href="http://ben.edu/?fp=Jg2bOCRGpmyIHeO3rTIpYJil8%2FmPB1JibWwClQntyhm4NkwKK
 uCk1tgtON7LOnmXFywl8MRjELrKlXFXgOfhOw%3D%3D&prvtof=HFakvtiyy0kNqKrmL%2FCjJLe
 PEMwdGWTZLZa5%2BZpNnP4%3D&poru=9vrhUGVKGCquHB6uFFMUXFNxz1c%2FgIaDOeCSvkLz5HC
 rH2FI%2Fixpxvr8LwjYT7uO&">Click here to proceed</a>.
         </body>
 </noframes>
 I didn't look beyond that, but it already looks fishy. Note that I used
 ben.edu in the hostname on that manual GET request. When I tried it with
 just the IP address, it said to go to searchremagnified.com.
 Mike Phipps
 Media Genesis, Inc.
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On
 Behalf Of Tim Huffman
 Sent: Friday, October 26, 2012 9:04 PM
 We are the primary DNS servers for the ben.edu domain. We seem to be having
 an issue with an AT&T server that is responding  with incorrect A records
 for www.ben.edu and ben.edu.
 What it SHOULD be the response:
 nslookup www.ben.edu
 Server:         63.250.224.66
 Address:        63.250.224.66#53
 www.ben.edu     canonical name = ben.edu.
 Name:   ben.edu
 Address: 38.100.120.100
 What 12.127.17.83 is responding with:
 Server:  tbru.br.rs.els-gms.att.net
 Address:  12.127.17.83
 Non-authoritative answer:
 Name:    www.ben.edu
 Address:  208.91.197.132
 This appears to be affecting only iPhones and iPads on the AT&T network. Is
 anybody else having problems with this? Are there any AT&T people on this
 list that can help?
 Tim Huffman
 Business Only Broadband
 777 Oakmont Lane, Suite 2000, Westmont, IL 60559
 Direct: 630.590.6012 | Main: 630.590.6000 | Fax: 630.986.2496 
 thuffman at bobbroadband.com  |   <http://www.bobbroadband.com/>
 http://www.bobbroadband.com/
 Cell:  630.340.1925 | Toll-Free Customer Support:  877.262.4553
 https://staticapp.icpsc.com/icp/loadimage.php/mogile/933825/747f0f3e66a4e0ce
 7633ff898bfc5121/image/png
 <http://www.linkedin.com/company/business-only-broadband> Follow Us on
 LinkedIn  |
 https://files.icontact.com/templates/v2/CleanAndSimple/images/twitter.gif
 <https://twitter.com/#%21/BOBbroadband> Follow Us on Twitter
 P please consider the environment prior to printing
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/cdd5ca29/attachment.html>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image001.png
 Type: image/png
 Size: 2480 bytes
 Desc: not available
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/cdd5ca29/attachment.png>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image002.gif
 Type: image/gif
 Size: 1287 bytes
 Desc: not available
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/cdd5ca29/attachment.gif>
  <01a401cdb3e0$bd8a8330$389f8990$@mediaG.com>
 Yeah, it appears to be some kind of placeholder site, like what Network Solutions uses.
 What's strange is that the AT&T server appears to be handing out alternating responses:
 # dig @12.127.17.83 www.ben.edu
 ; <<>> DiG 9.5.1-P2 <<>> @12.127.17.83 www.ben.edu
 ; (1 server found)
 ;; global options:  printcmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 35102
 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0
 ;; QUESTION SECTION:
 ;www.ben.edu.                   IN      A
 ;; ANSWER SECTION:
 www.ben.edu.            148     IN      A       208.91.197.132
 ;; Query time: 2 msec
 ;; SERVER: 12.127.17.83#53(12.127.17.83)
 ;; WHEN: Fri Oct 26 20:22:18 2012
 ;; MSG SIZE  rcvd: 45
 [root at venus ~]# dig @12.127.17.83 www.ben.edu
 ; <<>> DiG 9.5.1-P2 <<>> @12.127.17.83 www.ben.edu
 ; (1 server found)
 ;; global options:  printcmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 38198
 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0
 ;; QUESTION SECTION:
 ;www.ben.edu.                   IN      A
 ;; ANSWER SECTION:
 www.ben.edu.            3427    IN      CNAME   ben.edu.
 ben.edu.                3427    IN      A       38.100.120.100
 ;; Query time: 2 msec
 ;; SERVER: 12.127.17.83#53(12.127.17.83)
 ;; WHEN: Fri Oct 26 20:22:23 2012
 ;; MSG SIZE  rcvd: 59
 [root at venus ~]# dig @12.127.17.83 www.ben.edu
 ; <<>> DiG 9.5.1-P2 <<>> @12.127.17.83 www.ben.edu
 ; (1 server found)
 ;; global options:  printcmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 21252
 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0
 ;; QUESTION SECTION:
 ;www.ben.edu.                   IN      A
 ;; ANSWER SECTION:
 www.ben.edu.            142     IN      A       208.91.197.132
 ;; Query time: 1 msec
 ;; SERVER: 12.127.17.83#53(12.127.17.83)
 ;; WHEN: Fri Oct 26 20:22:24 2012
 ;; MSG SIZE  rcvd: 45
 [root at venus ~]# dig @12.127.17.83 www.ben.edu
 ; <<>> DiG 9.5.1-P2 <<>> @12.127.17.83 www.ben.edu
 ; (1 server found)
 ;; global options:  printcmd
 ;; Got answer:
 ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 59907
 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0
 ;; QUESTION SECTION:
 ;www.ben.edu.                   IN      A
 ;; ANSWER SECTION:
 www.ben.edu.            3425    IN      CNAME   ben.edu.
 ben.edu.                3425    IN      A       38.100.120.100
 ;; Query time: 2 msec
 ;; SERVER: 12.127.17.83#53(12.127.17.83)
 ;; WHEN: Fri Oct 26 20:22:25 2012
 ;; MSG SIZE  rcvd: 59
 Tim Huffman
 Director of Engineering
 Business Only Broadband
 777 Oakmont Lane, Suite 2000, Westmont, IL 60559
 Direct: 630.590.6012 | Main: 630.590.6000 | Fax: 630.986.2496
 thuffman at bobbroadband.com<mailto:thuffman at bobbroadband.com>  |  http://www.bobbroadband.com/
 Cell:  630.340.1925 | Toll-Free Customer Support:  877.262.4553
 [https://staticapp.icpsc.com/icp/loadimage.php/mogile/933825/747f0f3e66a4e0ce7633ff898bfc5121/image/png]  Follow Us on LinkedIn<http://www.linkedin.com/company/business-only-broadband>  |  [https://files.icontact.com/templates/v2/CleanAndSimple/images/twitter.gif]   Follow Us on Twitter<https://twitter.com/#%21/BOBbroadband>
 P please consider the environment prior to printing
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Mike Phipps
 Sent: Friday, October 26, 2012 8:17 PM
 208.91.197.132 doesn't have a PTR record associated with it, but a Whois query shows that it's owned by Confluence Networks. However, check out what happens when you go to that IP address:
 $ nc -v 208.91.197.132 80
 Connection to 208.91.197.132 80 port [tcp/http] succeeded!
 GET / HTTP/1.1
 Host: ben.edu
 HTTP/1.1 200 OK
 Date: Sat, 27 Oct 2012 01:14:43 GMT
 Server: Apache/2.2.3 (Red Hat)
 X-Powered-By: PHP/5.3.16
 Vary: Accept-Encoding,User-Agent
 Content-Length: 712
 Content-Type: text/html; charset=UTF-8
 <frameset rows="100%,*" frameborder="no" border="0" framespacing="0">
         <frame src="http://ben.edu/?fp=Jg2bOCRGpmyIHeO3rTIpYJil8%2FmPB1JibWwClQntyhm4NkwKKuCk1tgtON7LOnmXFywl8MRjELrKlXFXgOfhOw%3D%3D&prvtof=lJY3O5r6C%2F4Iypq21CJp7a1LuqqIdOWvKdwx5Xsl1x8%3D&poru=S87wfqjj4W%2B%2Fm8dSEqpuWZr20KvK367%2BCoGC%2FHW2e9kL6N%2Fl3h3wnDx5AfKbrhlZ&">
 </frameset>
 <noframes>
         <body bgcolor="#ffffff" text="#000000">
         <a href="http://ben.edu/?fp=Jg2bOCRGpmyIHeO3rTIpYJil8%2FmPB1JibWwClQntyhm4NkwKKuCk1tgtON7LOnmXFywl8MRjELrKlXFXgOfhOw%3D%3D&prvtof=HFakvtiyy0kNqKrmL%2FCjJLePEMwdGWTZLZa5%2BZpNnP4%3D&poru=9vrhUGVKGCquHB6uFFMUXFNxz1c%2FgIaDOeCSvkLz5HCrH2FI%2Fixpxvr8LwjYT7uO&">Click here to proceed</a>.
         </body>
 </noframes>
 I didn't look beyond that, but it already looks fishy. Note that I used ben.edu in the hostname on that manual GET request. When I tried it with just the IP address, it said to go to searchremagnified.com.
 Mike Phipps
 Media Genesis, Inc.
 From: outages-bounces at outages.org<mailto:outages-bounces at outages.org> [mailto:outages-bounces at outages.org] On Behalf Of Tim Huffman
 Sent: Friday, October 26, 2012 9:04 PM
 We are the primary DNS servers for the ben.edu domain. We seem to be having an issue with an AT&T server that is responding  with incorrect A records for www.ben.edu<http://www.ben.edu> and ben.edu.
 What it SHOULD be the response:
 nslookup www.ben.edu<http://www.ben.edu>
 Server:         63.250.224.66
 Address:        63.250.224.66#53
 www.ben.edu<http://www.ben.edu>     canonical name = ben.edu.
 Name:   ben.edu
 Address: 38.100.120.100
 What 12.127.17.83 is responding with:
 Server:  tbru.br.rs.els-gms.att.net
 Address:  12.127.17.83
 Non-authoritative answer:
 Name:    www.ben.edu<http://www.ben.edu>
 Address:  208.91.197.132
 This appears to be affecting only iPhones and iPads on the AT&T network. Is anybody else having problems with this? Are there any AT&T people on this list that can help?
 Tim Huffman
 Business Only Broadband
 777 Oakmont Lane, Suite 2000, Westmont, IL 60559
 Direct: 630.590.6012 | Main: 630.590.6000 | Fax: 630.986.2496
 thuffman at bobbroadband.com<mailto:thuffman at bobbroadband.com>  |  http://www.bobbroadband.com/
 Cell:  630.340.1925 | Toll-Free Customer Support:  877.262.4553
 [https://staticapp.icpsc.com/icp/loadimage.php/mogile/933825/747f0f3e66a4e0ce7633ff898bfc5121/image/png]  Follow Us on LinkedIn<http://www.linkedin.com/company/business-only-broadband>  |  [https://files.icontact.com/templates/v2/CleanAndSimple/images/twitter.gif]   Follow Us on Twitter<https://twitter.com/#%21/BOBbroadband>
 P please consider the environment prior to printing
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121027/db15671b/attachment-0001.html>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image001.png
 Type: image/png
 Size: 2480 bytes
 Desc: image001.png
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121027/db15671b/attachment-0001.png>
 -------------- next part --------------
 A non-text attachment was scrubbed...
 Name: image002.gif
 Type: image/gif
 Size: 1287 bytes
 Desc: image002.gif
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121027/db15671b/attachment-0001.gif>
  <01a401cdb3e0$bd8a8330$389f8990$@mediaG.com>
  <A694979C636D1F4B94725CE6B753F62A0E9B1EDC@WNCNAPMAIL01.wncloud.com>
 Hi,
 So I tried in 3 different places:
 Comcast residential service near San Jose, CA: 38.100.120.100
 Multi-homed colo facility near Dallas, TX: 38.100.120.100
 Multi-homed colo facility near London, UK: 208.91.197.32
 Doing a bit of digging on the latter:
 % dig +short @12.127.17.83 www.ben.edu ns
 ns1432.ztomy.com.
 ns2432.ztomy.com.
 % whois -h whois.crsnic.net ztomy.com
 Whois Server Version 2.0
 Domain names in the .com and .net domains can now be registered
 with many different competing registrars. Go to http://www.internic.net
 for detailed information.
    Domain Name: ZTOMY.COM
    Registrar: PDR LTD. D/B/A PUBLICDOMAINREGISTRY.COM
    Whois Server: whois.PublicDomainRegistry.com
    Referral URL: http://www.PublicDomainRegistry.com
    Name Server: USC4.AKAM.NET
    Name Server: USC5.AKAM.NET
    Status: ok
    Updated Date: 23-apr-2012
    Creation Date: 22-nov-2007
    Expiration Date: 22-nov-2014
 [...]
 % whois -h whois.publicdomainregistry.com ztomy.com
 Domain Name: ZTOMY.COM      
  Registrant:                       
      PrivacyProtect.org
     Domain Admin        (contact at privacyprotect.org)
     ID#10760, PO Box 16
     Note - All Postal Mails Rejected, visit Privacyprotect.org
     Nobby Beach
     null,QLD 4218
     AU
     Tel. +45.36946676     
  Creation Date: 22-Nov-2007  
  Expiration Date: 22-Nov-2014  
 [...]
 Doing a google search on ztomy.com suggests that they provide malware/spyware/etc.
 Looking at the address being returned (208.91.197.132):
 % whois -h whois.arin.net 208.91.197.132
 [...]
 NetRange:       208.91.196.0 - 208.91.199.255
 CIDR:           208.91.196.0/22
 OriginAS:       AS40034
 NetName:        CONFLUENCE-NETWORK-INC
 NetHandle:      NET-208-91-196-0-1
 Parent:         NET-208-0-0-0-0
 NetType:        Direct Allocation
 RegDate:        2011-04-15
 Updated:        2012-03-02
 Ref:            http://whois.arin.net/rest/net/NET-208-91-196-0-1
 OrgName:        Confluence Networks Inc
 OrgId:          CN
 Address:        3rd Floor, Omar Hodge Building, Wickhams
 Address:        Cay I, P.O. Box 362
 City:           Road Town
 StateProv:      Tortola
 PostalCode:     VG1110
 Country:        VG
 RegDate:        2011-04-07
 Updated:        2011-07-05
 Ref:            http://whois.arin.net/rest/org/CN
 [...]
 Doing a google search on confluence networks suggests that they host a lot of bad stuff (e.g., 'high yield investment programs' which appear to be yet another form of Ponzi scheme).  I did see some suggestions of ztomy.com engaging in DNS cache poisoning, but no proof.
 Given the inconsistent answers from the AT&T name server, one possibility is that AT&T's resolvers are under a Kaminsky-style DNS cache poisoning attack.  You might want to drop a note to the DNS-OARC (https://www.dns-oarc.net) dns-operations list -- I think there are probably some folks there from AT&T.
 Regards,
 -drc
 On Oct 26, 2012, at 6:26 PM, Tim Huffman <tim at bobbroadband.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121026/ca311348/attachment-0001.html>
###############################################################
END
###############################################################

###############################################################
EasyDNS issues?
###############################################################
 I know EasyDNS is anycasted, so some of this troubleshooting work
 doesn't narrow things down, but something is indeed going on.
 Issue started roughly 2012/10/27 at 06:25 Pacific.
 I'm guessing a DoS attack but that's speculative.
 $ dig ns dslreports.com.
 ;; QUESTION SECTION:
 ;dslreports.com.                        IN      NS
 ;; ANSWER SECTION:
 dslreports.com.         1200    IN      NS      dns3.easydns.org.
 dslreports.com.         1200    IN      NS      dns2.easydns.net.
 dslreports.com.         1200    IN      NS      dns1.easydns.com.
 ;; ADDITIONAL SECTION:
 dns1.easydns.com.       7321    IN      A       64.68.192.210
 dns1.easydns.com.       172734  IN      AAAA    2001:1838:f001::10
 dns2.easydns.net.       157640  IN      A       72.52.2.1
 dns3.easydns.org.       468     IN      A       64.68.195.10
 dns3.easydns.org.       72510   IN      AAAA    2620:49:a::10
 $ dig @ns1.easydns.com a www.dslreports.com.
 ;; connection timed out; no servers could be reached
 $ host ns1.easydns.com
 ns1.easydns.com has address 64.68.192.210
 $ dig @dns2.easydns.net a www.dslreports.com.
 ;; QUESTION SECTION:
 ;www.dslreports.com.            IN      A
 ;; ANSWER SECTION:
 www.dslreports.com.     1200    IN      A       209.123.109.175
 $ host dns2.easydns.net
 dns2.easydns.net has address 72.52.2.1
 $ dig @dns3.easydns.org a www.dslreports.com.
 ; <<>> DiG 9.8.3-P4 <<>> @dns3.easydns.org a www.dslreports.com.
 ; (2 servers found)
 ;; global options: +cmd
 ;; connection timed out; no servers could be reached
 $ host dns3.easydns.org
 dns3.easydns.org has address 64.68.195.10
 dns3.easydns.org has IPv6 address 2620:49:a::10
 $ mtr 64.68.192.210
                                                   Packets               Pings
  Host                                           Loss%   Snt   Rcv  Last   Avg  Best  Wrst
  1. gw.home.lan                                  0.0%    18    18   0.3   0.3   0.3   0.4
  2. c-67-180-84-1.hsd1.ca.comcast.net            0.0%    18    18  25.4  24.4  12.7  31.2
  3. te-0-0-0-12-ur05.santaclara.ca.sfba.comcast  0.0%    18    18  10.8  10.6   8.8  25.5
  4. te-1-1-0-2-ar01.sfsutro.ca.sfba.comcast.net  0.0%    17    17  21.4  16.7  12.7  22.3
  5. he-1-7-0-0-cr01.sanjose.ca.ibone.comcast.ne  0.0%    17    17  23.8  19.9  13.9  24.7
  6. pos-0-12-0-0-cr01.denver.co.ibone.comcast.n  0.0%    17    17  53.9  56.0  53.7  57.7
  7. 68.86.89.41                                  0.0%    17    17  88.5  84.0  78.2  90.8
  8. be-10-pe03.350ecermak.il.ibone.comcast.net   0.0%    17    17  80.2  80.2  77.8  93.7
  9. 173.167.57.126                               0.0%    17    17  82.4  80.7  79.1  84.0
 10. ae1-50g.cr2.ord1.us.nlayer.net               0.0%    17    17  79.5  80.7  77.8 112.0
 11. as23352.ae6-102.cr2.ord1.us.nlayer.net       0.0%    17    17  78.6  79.3  77.9  81.8
 12. 44.po1.ar2.ord1.us.scnet.net                 0.0%    17    17  84.1  82.6  77.8 121.6
 13. ge0-50.aggr4302.ord2.us.scnet.net           68.8%    17     5  80.7  80.5  79.5  81.6
 14. dns1.easydns.com                            76.5%    17     4  77.8  78.6  77.8  79.7
 $ mtr 64.68.195.10
                                                   Packets               Pings
  Host                                           Loss%   Snt   Rcv  Last   Avg  Best  Wrst
  1. gw.home.lan                                  0.0%    22    22   0.3   0.3   0.2   0.4
  2. c-67-180-84-1.hsd1.ca.comcast.net            0.0%    22    22  27.7  23.0  11.4  40.6
  3. te-0-0-0-12-ur05.santaclara.ca.sfba.comcast  0.0%    22    22   9.4   9.9   8.5  10.7
  4. 69.139.198.174                               0.0%    22    22  15.4  16.6  11.5  22.6
  5. he-1-8-0-0-cr01.sanjose.ca.ibone.comcast.ne  0.0%    22    22  22.4  19.5  13.1  39.1
  6. pos-0-3-0-0-pe01.11greatoaks.ca.ibone.comca  0.0%    22    22  16.2  17.8  15.0  20.1
  7. 208.178.58.13                                0.0%    22    22  23.2  19.7  14.2  27.5
  8. ae9-40G.scr4.SNV2.gblx.net                   4.5%    22    21  28.7  26.0  15.8  64.1
  9. po3-20G.ar5.DCA3.gblx.net                    0.0%    21    21  82.2  87.4  81.5 150.8
 10. packet-clearing-house.gigabitethernet9-3.ar 47.6%    21    11  89.5  91.1  89.1  99.3
 11. 64.68.195.10                                95.0%    21     1 261.8 261.8 261.8 261.8
 -- 
 | Jeremy Chadwick                                   jdc at koitsu.org |
 | UNIX Systems Administrator                http://jdc.koitsu.org/ |
 | Mountain View, CA, US                                            |
 | Making life hard for others since 1977.             PGP 4BD6C0CB |
 On 10/27/12 08:43, Jeremy Chadwick wrote:
  From my DNS server logs, they are the subject of a DNS amplification 
 attack.
 Oct 27 08:54:02 linux named[18188]: limit REFUSED responses to 72.52.2.0/24
 Oct 27 08:55:07 linux named[18188]: stop limiting error responses to 
 72.52.2.0/24
 Oct 27 08:56:02 linux named[18188]: limit REFUSED responses to 72.52.2.0/24
 Oct 27 08:57:02 linux named[18188]: stop limiting error responses to 
 72.52.2.0/24
 Oct 27 08:58:02 linux named[18188]: limit REFUSED responses to 72.52.2.0/24
 Oct 27 08:59:02 linux named[18188]: stop limiting error responses to 
 72.52.2.0/24
 Oct 27 09:00:02 linux named[18188]: limit REFUSED responses to 72.52.2.0/24
 Timestamps are CDT.  My DNS servers have been an 'innocent victim' for 
 about three weeks now and I installed the rate limit patches this 
 morning to bind 9.8.4 from http://www.redbarn.org/ratelimits
 Lyle Giese
 LCR Computer Services, Inc.
  <508BEA19.7060005@lcrcomputer.net>
 On 10/27/12 09:05, Lyle Giese wrote:
 Stuff deleted....
 They switched here to going after 67.228.102.243 already.
 Lyle Giese
 LCR Computer Services, Inc.
###############################################################
END
###############################################################

###############################################################
Possible Routing Issues to AT&T
###############################################################
 Is anyone aware of any routing issues in the AT&T network today that just cleared about 20 minutes ago?
 I have a customer that was experiencing issues routing to AT&T that was lasting several hours for them.  By time I was able
 To dig into it they called back stating that it cleared so I was unable to get any information to try to locate a root cause of this
 for them.
 Thanks!
 Matthew Anderson
###############################################################
END
###############################################################

###############################################################
Toronto, Primus Outage - PRI's and DC
###############################################################
 Primus seems to be experiencing a major outage in Toronto at the moment.
 We are seeing all PRI circuits down and a complete loss of network
 connectivity in their 10 Bay St. data centre.  All Primus support
 numbers result in a congestion tone when dialed.  No mention of a major
 outage on their support site:
 http://businesssupport.primus.ca/network-status.php
 Any further information out there?
 Thanks,
 Jake
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/4f37bf80/attachment.html>
 On Oct 29, 2012, at 9:51 PM, "Jake Vandendool" <Jake.Vandendool at DoolSystems.com> wrote:
 I'm sure it's related, hearing reports of 18 foot waves on Lake Erie, snow in Columbus and elsewhere.  I've seen some photos of portions of NYC without power, etc?
 I know areas of Northern Ohio have been having intermittent power outages as well.
 Do hope everyone is safe from the storm.
 - Jared
 (a few links folks may find useful)
 http://www.torontohydro.com/sites/electricsystem/poweroutages/pages/outagemap.aspx
 http://outages.firstenergycorp.com/oh.html
 http://dteenergy.com/map/outage.html
 http://www.consumersenergy.com/outagemap
  <508F4746.6080605@bgpmon.net>
 Service seems to be restored as of roughly 22:40 EDT.
 -----Original Message-----
 From: Andree Toonk // BGPmon.net [mailto:andree at bgpmon.net] 
 Sent: Monday, October 29, 2012 11:20 PM
 Hi Jake,
 I believe it just came back?
 we saw 11 prefixes become unreachable for Primus at 2012-10-30 01:14 UTC
 Details below:
 $ ./create_reachability_report.pl -s 2012-10-29 -e 2012-10-31 -a 6407
 -----------------------------------------------
 AS6407 204.138.111.0/24 (Peer1 route object) Availability 97.465%
 Downtime 73 Minutes
 Events:
 129/130/80 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 207.112.10.0/23 (Primus)
 Availability 97.465%  Downtime 73 Minutes
 Events:
 129/130/80 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 207.112.12.0/22 (Primus)
 Availability 97.465%  Downtime 73 Minutes
 Events:
 130/130/80 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 207.112.9.0/24 (Primus)
 Availability 97.465%  Downtime 73 Minutes
 Events:
 128/130/80 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 209.183.12.0/24 (No valid route object!) Availability 97.465%
 Downtime 73 Minutes
 Events:
 128/130/80 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 209.183.20.0/24 (No valid route object!) Availability 97.465%
 Downtime 73 Minutes
 Events:
 128/143/147 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 216.176.216.0/21 (NetBlock-Madison_Internet) Availability 97.465%
 Downtime 73 Minutes
 Events:
 129/130/80 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 216.254.159.0/24 (No valid route object!) Availability 97.465%
 Downtime 73 Minutes
 Events:
 128/130/80 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 216.254.202.64/29 (No valid route object!) Availability 97.326%
 Downtime 77 Minutes
 Events:
 9/15/16 peers: -- down for 77 minutes	 2012-10-30 01:13 - 2012-10-30
 02:30
 -----------------------------------------------
 AS6407 216.254.209.0/24 (Primus Canada, AS6407, Toronto, Ontario,
 Canada) Availability 97.431%  Downtime 74 Minutes
 Events:
 128/143/147 peers: -- down for 74 minutes	 2012-10-30 01:13 -
 2012-10-30
 02:27
 -----------------------------------------------
 AS6407 216.254.223.0/24 (No valid route object!) Availability 97.465%
 Downtime 73 Minutes
 Events:
 128/145/147 peers: -- down for 73 minutes	 2012-10-30 01:14 -
 2012-10-30
 02:27
 .-- My secret spy satellite informs me that at 2012-10-29 6:51 PM  Jake
 Vandendool wrote:
  <537DE0BA-C47A-48AC-B51F-5A936067C422@puck.nether.net>
 Primus Network Status
 Current Network Status
 Last updated: 29-Oct-12 23:03
 Date: 29-Oct-12 21:10	Updated: 29-Oct-12 23:03
 City: Toronto
 Status: Closed
 Subject: Toronto-10 Bay Data Centre Network Service Outage
 On Monday, October 29, 2012 at 9:10PM EDT, Black Iron Data
 (Primus	Telecommunications) experienced a network service outage that
 impacted customers at the Toronto-10 Bay Data Centre. Services should
 be back up as of 10:35PM EDT. We are still investigating the cause of
 failure. We apologize for the inconvenience this has caused and we
 thank you for your patience.
 Reference Number MT12671.
 Recovered: 29-Oct-12 - 22:35
 On Mon, Oct 29, 2012 at 9:56 PM, Jared Mauch <jared at puck.nether.net> wrote:
###############################################################
END
###############################################################

###############################################################
8x8 outage/111 8th Ave NYC
###############################################################
 Our hosts there are not responding as of 10:58p EDT. 
 We've got no news but are assuming it's Sandy coming to town.
 --j
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/67e64e93/attachment.html>
 Large section of Manhattan is without power currently.
 Flooding too so the generator might be a little waterlogged.
 Chuck
 On Mon, Oct 29, 2012 at 11:18 PM, Jim Meyer <jim at geekdaily.org> wrote:
 There are widespread power outages downtown, with much of Manhattan south
 of 39th st going dark starting at 2200 Eastern.
 (end)
 On Oct 29, 2012 11:31 PM, "Jim Meyer" <jim at geekdaily.org> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/d365bc75/attachment.html>
 They have shut sections of the grid off..
 Lonnie Bozeman
 Operations Manager
 CORESITE
 (NYSE: COR)
 900 N. Alameda St. Suite 200
 Los Angeles, CA 90012 USA
 +1 213.327.1204  | Office
 +1 213.598.1739  | Cell
 +1 213.327.1289  | eFax
 Lonnie.Bozeman at CoreSite.com| www.CoreSite.com
 Jim Meyer <jim at geekdaily.org> wrote:
 Our hosts there are not responding as of 10:58p EDT.
 We've got no news but are assuming it's Sandy coming to town.
 --j
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/7807578e/attachment.html>
 I have no idea what is going on there. However, much of Manhattan is under water, under mandatory evacuation, and certainly no fuel deliveries are being made.
 I am at my house in 07874. Considerable damage and lots of trees down.
 We own datacenters in 07927, which still has utility power; and another in 07054 which is on generator with utility voltage roughly 14% high (about 550 volts).
 We have equipment in 60 Hudson - as of now, it is still up.
 We have lost one span of fiber between Morristown, NJ and Newark, NJ.
 The situation is not great. I am grateful our centers are 100's of feet above sea level.
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Jim Meyer
 Sent: Monday, October 29, 2012 11:19 PM
 Our hosts there are not responding as of 10:58p EDT.
 We've got no news but are assuming it's Sandy coming to town.
 --j
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/b47c39b0/attachment-0001.html>
 If you'd like to "see" the outage, NY Times has a webcam on the 51st floor
 now.
 <
 http://www.nytimes.com/interactive/2012/10/28/nyregion/nyt-webcam.html?smid=tw-nytmetro
 -- Eric (riding out our version of the storm in the Binghamton, NY area)
 On Oct 29, 2012 11:31 PM, "Jim Meyer" <jim at geekdaily.org> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/5b486d55/attachment.html>
  <1d0b5cikjjlbf9gulmiv2w70.1351568335613@email.android.com>
 Because salt water and electricity are a bad combination, NY has shut down large sections of power as a precaution in preparation for expected storm surges that are likely to flood many of the underground facilities. These precautionary outages will very likely make it a whole lot easier to restore power much sooner after Sandy finishes pounding the area.
 It's actually a surprisingly wise thing for them to have done. However, for it to work out well, they would have had to offline the back-up generators and disconnect the battery systems as well. I don't know to what extent that will have happened.
 Owen
 On Oct 29, 2012, at 20:39 , Lonnie Bozeman <Lonnie.Bozeman at coresite.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/53383094/attachment.html>
  <CAMdF1xX2GNTgf43W0_PtA0+KughkYv80RDN14FUydMhzY16gNw@mail.gmail.com>
 Reported at http://www.webhostingtalk.com/showthread.php?t=1205042,
 "Voxel/Internap are down at 111 8th Avenue"
 Ryan
 On Mon, Oct 29, 2012 at 11:57 PM, Eric Adler <eaptech at gmail.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/b8ab2486/attachment.html>
  <1d0b5cikjjlbf9gulmiv2w70.1351568335613@email.android.com>
  <B22F1476-C56B-414D-8B46-885FFC2DE5CA@delong.com>
 There are also unexpected outages. 111 8th was not in the area to be
 intentionally powered down.
 (end)
 On Oct 30, 2012 12:22 AM, "Owen DeLong" <owen at delong.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/56a11eef/attachment.html>
  <1d0b5cikjjlbf9gulmiv2w70.1351568335613@email.android.com>
  <B22F1476-C56B-414D-8B46-885FFC2DE5CA@delong.com>
 Info from Zayo:
 The local power provider in the NY Market, ConEd, has intentionally
 de-energized power systems in the New York metropolitan area to reduce
 system damage as salt water has entered the underground infrastructure.
 Additionally, power outages have been observed in the Newark metropolitan
 area affecting the Zayo facility at 165 Halsey.   All Zayo facilities that
 have sustained a loss of commercial power are currently operating normally
 on generator backup, and refueling arrangements are being made for all Zayo
 owned generators at this time to ensure continuous operation of Zayo
 facilities and equipment.  A current readout by site of our current
 generator runtime is as follows:
     - *60 Hudson (NY)*
          - 1st Floor MMR (Meet Me Room) 18 Hours of generator backup, with
          additional fuel onsite to replenish the generator
          - 12th Floor has 30+ hours or generator back up
          - 15th and 19th Colocation Floor 30+ hours or generator back up
          which is provided by the building
 **Fuel supplier has tankers inside the city of New York to deliver fuel to
 Zayo when necessary.*
     - *111 8th Ave (NY)*
          - Has 90,000 gallons of fuel, which is able to provide up to 4
          days of power
     - *165 Halsey (NJ)*
          - 5th Floor has 17+ hours of generator backup
          - 10th Floor has 30+ hours of generator backup
 At this point, we are experiencing multiple fiber cuts as a result of the
 storm which has resulted in service interruptions to transport services in
 the Pennsylvania, New Jersey and New York markets.
 On Mon, Oct 29, 2012 at 9:07 PM, Owen DeLong <owen at delong.com> wrote:
 -- 
 Chris Sheats
 yawnbox at gmail.com
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/593b04e3/attachment-0001.html>
  <1d0b5cikjjlbf9gulmiv2w70.1351568335613@email.android.com>
  <B22F1476-C56B-414D-8B46-885FFC2DE5CA@delong.com>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 Just received this update by one of Zayo's customer. In preparation
 for this potential power event, here's the readout by site of Zayos
 generator backup capacity is as follows:
 Hopefully this helps if you are located in one of these locations and
 /or floors:
 *	60 Hudson (NY)
 *	8th Floor MMR (Meet Me Room) 18 Hours of generator backup, with
 additional fuel onsite to replenish the generator
 *	12th Floor has 30+ hours or generator back up
 *	19th and 20th Colocation Floors 30+ hours or generator back up which
 is provided by the building
 *Fuel supplier has tankers inside the city of New York to deliver fuel
 to Zayo when necessary.
 *	111 8th Ave (NY)
 *	Has 90,000 gallons of fuel, which is able to provide up to 4 days of
 power
 *	165 Halsey (NJ)
 *	5th Floor has 17+ hours of generator backup
 *	10th Floor has 30+ hours of generator backup
 *	401 N Broad (PA)
 *	2nd Floor has 30+ hours of generator backup
 *	3rd Floor has 50+ hours of generator backup
 *	1 Summer St (CT)
 *	The building has 16+ hours of generator backup
 *	111 Market Place (MD)
 *	Has 36+ hours of generator backup
 *	2100 M St (DC)
 *	The building has 20+ hours of generator backup
 regards,
 /virendra
 On 10/29/2012 09:07 PM, Owen DeLong wrote:
 XO reports they're on generators at 111 8th Ave and are still seeing issues to that data center.
 Internap also has big issues, likely to go dead ~3:30-5:30a EDT 10/30/2012: 
 http://pastebin.com/d9espQRw
 Init7 reports issues, but still has connectivity to NYIIX or Equinix NYC: 
 http://www.init7.net/en/status/&ticket=6088
 Meanwhile, light reading on what folks did to gear up for Sandy:
 http://www.datacenterknowledge.com/archives/2012/10/29/northeast-data-centers-brace-for-sandy/
 It'll be interesting to see what mattered and what didn't.
 --j
 Power outage maps: http://www.governor.ny.gov/poweroutageinfo
 Data center maps: http://www.datacentermap.com/
 ConEd map with outages, weather radar: http://apps.coned.com/stormcenter_external_oru/default.html
 On Oct 29, 2012, at 8:18 PM, Jim Meyer wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121029/e0627bd8/attachment.html>
  <1d0b5cikjjlbf9gulmiv2w70.1351568335613@email.android.com>
  <B22F1476-C56B-414D-8B46-885FFC2DE5CA@delong.com>
  <CAC5E3HWr+ps6qbPA3TqRJ+91BP+d2F6kGC__TmNhe+UaLD-oWQ@mail.gmail.com>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 Tracker was updated as well.
 regards,
 /virendra
 On 10/29/2012 09:25 PM, Chris Sheats wrote:
 Apparently the entire 3rd floor minus Level3 is out. Telx lost conEd power
 around 7:37P, and we saw everything shut down around 10:57P. Currently
 claiming something wrong between building gensets and power infrastructure
 on floor 3. No updates since 12:30AM (all EST). Anyone know more?
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/3454ee4c/attachment.html>
 I saw this on an email chain I am on:
   * *111 8^th Ave (NY)*
       o Has 90,000 gallons of fuel, which is able to provide up to 4
         days of power
       o This facility experienced voltage fluctuations as a result of a
         blown fuse on the main buss feeding several tenants at the
         building.  The fuse replacement in underway and we should return
         to normal operating conditions momentarily.
 --John
 On 10/30/2012 12:44 AM, jeffrey arnold wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/aaee6e4e/attachment-0001.html>
  <508FD396.9050002@gmail.com>
 Understand - 111 8th is a multi-tenant building, with tens and tens of power systems and generator systems, etc. Just because one guy is up does not infer another is down, and vice versa.
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of John Barbieri
 Sent: Tuesday, October 30, 2012 9:18 AM
 I saw this on an email chain I am on:
  *   111 8th Ave (NY)
     *   Has 90,000 gallons of fuel, which is able to provide up to 4 days of power
     *   This facility experienced voltage fluctuations as a result of a blown fuse on the main buss feeding several tenants at the building.  The fuse replacement in underway and we should return to normal operating conditions momentarily.
 --John
 On 10/30/2012 12:44 AM, jeffrey arnold wrote:
 Apparently the entire 3rd floor minus Level3 is out. Telx lost conEd power around 7:37P, and we saw everything shut down around 10:57P. Currently claiming something wrong between building gensets and power infrastructure on floor 3. No updates since 12:30AM (all EST). Anyone know more?
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/c3777c04/attachment.html>
###############################################################
END
###############################################################

###############################################################
NYC Outages
###############################################################
 Hello,
 Nothing to report outage-wise. However, if there is anything NAC can do to help anyone affected by the hurricane, please feel free to email me.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/ff14891a/attachment.html>
 I had to summarize for an internal resource in the last few minutes, figure I would share:
 --
 Of our three datacenters, this is what we saw:
 Parsippany 1 (OCT) - The worst we saw here was several sub-second power hits. UPS's held without problem, and we did not transfer to generator at all yet.
 Parsippany 2 (WBR) - Transferred to generator at about 7:55 PM EST as a precautionary measure due to ongoing utility power hits. However, shortly after transfer, utility voltage went to 0 on all phases; around 10p power returned, but abnormally high (seeing about 550 volts on 480 volt bus). We remain on generator with at least 60 hours of fuel left on site.
 Cedar Knolls 1 (MMU) - Briefly transferred to generator around 7:10, then back to utility. We then force transferred to generator around 8pm and stayed until this morning. Returned to utility and all systems are normal.
 Fuel trucks are stationed at our facilities as of noon yesterday, and remain. Across all centers, consumption would be - in worst case - around 250 gallons per hour. We have 6,880 on site in generator tanks (27 hours), and additional 12,500 gallons (50 hours) on site available for transfer as needed, for a total of run time of 77 hours. However, we are only consuming fuel at one site right now (WBR, rate of 43 gal/hr).
 We have accommodated several customers by allowing them to use our conference rooms and some offices, mainly because they lost power at their buildings, lost access to their buildings, or generators ran out of fuel.
 There has been no service interruption of any sort to any of our datacenter customers, as of this writing.
 We lost one span of fiber optics between MMU and 165 Halsey, Newark (NWR), network healed in less than 1 second. It was imperceptible. That was early though, yesterday afternoon.
 We have sales people onsite who are actively taking sales calls, and there is a measurable amount of customers moving equipment into our facilities as I write this. Many are moving equipment from offices with no power and no ETR in sight. We have electricians onsite to help accommodate.
 The facilities department has been manning all locations around the clock.
 All sites remain accessible by road. There was never a situation where you could not over the last 24 hours.
 We have no equipment in 111 8th, so I cannot offer any telemetry there. However, our gear in 60 Hudson St (Tel-X 9th floor) is still online.
 We saw no interruption at 165 Halsey, except for some very brief utility hits. UPS's held.
 We are seeing hundreds, if not thousands, of DSL / T1 / T3 / Ethernet customers down - presumably mostly power loss on the CPE. We lost our connection to Covad, presumably they have gear in a building which lost power.
 We have seen substantial interruption to the cellular networks; in many cases, ATT Wireless (who NAC uses) is unable to complete a call. In certain areas, there is no signal at all.
 Where I live, in 07874 (Byram), many roads are impassable and most everyone does not have power. Trees are down everywhere. I heard that a Byram squad car had a tree land on it while responding to a call. Schools are closed, Halloween has been "rescheduled" according to our governor. My cable is down, cable modem is down, POTS service is out - yet I still have xDSL (loop by Verizon, IP by NAC) and I run on that successfully. I am unable to get any ATT cell service at my house (usually at least three bars). I am on generator at my house, consuming about 2 gal/hour (propane), with a little over 500 gallons left.
 That is all I have.
 This is the road leading to the Byram Police Dept - I took this earlier this morning:
 https://sphotos-a.xx.fbcdn.net/hphotos-prn1/12696_4311181250657_900557870_n.jpg
 This is typically what Northern NJ looks like:
 https://sphotos-a.xx.fbcdn.net/hphotos-ash3/548544_4311185050752_1011136048_n.jpg
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Alex Rubenstein
 Sent: Tuesday, October 30, 2012 10:07 AM
 Hello,
 Nothing to report outage-wise. However, if there is anything NAC can do to help anyone affected by the hurricane, please feel free to email me.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/9dc5ecf5/attachment.html>
  <2D0AF14BA6FB334988BC1F5D4FC38CB81AE42733CA@EXCHMBX.hq.nac.net>
 Ouch, and RE: Covad/Megapath lines, in NY they have been lighting up
 our email with outage reports, they all end up with a status of:
 Description:
 We are currently experiencing a service interruption due to equipment
 failure at the NYCMNYBS central office in New York, NY.
 UPDATE: Due to hurricane storm Sandy, the city is under full state of
 emergency as roads and bridges are closed. Services will remain down
 during duration of storm as no dispatches can be made. NOC will send
 further update whenever there is change in condition.
 On Tue, Oct 30, 2012 at 11:56 AM, Alex Rubenstein <alex at corp.nac.net> wrote:
 Also reports  AC2 transatlantic cable down and loss of connectivity to NY
 based servers.
 Along with reports on Ausnog about all the fun with the large DCs in
 Manhattan going to gennie power, diesel pumps being flooded and failing
 'cos the tanks are in the basement...
 Will be a massive clearup not just for the IT folks, Subways and road
 tunnels flooded so getting about will be challenging for a while.
 -- 
 Martin Hepworth, CISSP
 Oxford, UK
 On 30 October 2012 14:06, Alex Rubenstein <alex at corp.nac.net> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/37685aeb/attachment.html>
  <CAGDKorK10KUA_LfQQVWmz3DrmEsHgRn0nS8E=WV0JuAH65j=qg@mail.gmail.com>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 Internap reporting via http://pastebin.com/9Fr2eW6U
 "The flooding has submerged and destroyed the site's diesel pumps and
 is preventing fuel from being pumped to the generators on the
 mezzanine level. The available fuel reserves on the mezzanine level
 are estimated to support customer loads for approximately 5-7 hours.
 Once this fuel supply has been exhausted the generator will no longer
 be able to sustain operation and critical customer power loads will be
 lost. The building itself is being evacuated and no remote hands
 support will be available to assist in any equipment shutdown."
 75 Broad Street in Manhattan, where both Internap and Peer1 Hosting
 are shutting down operations.
 peer1 status page:
 http://forums.peer1.com/viewtopic.php?f=37&t=7532&p=9463%23p9463
 regards,
 /virendra
 On 10/30/2012 09:59 AM, Martin Hepworth wrote:
  <CAGDKorK10KUA_LfQQVWmz3DrmEsHgRn0nS8E=WV0JuAH65j=qg@mail.gmail.com>
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 Hi,
 On 10/30/2012 09:59 AM, Martin Hepworth wrote:
 - --------------------------
 Unless I 'm off, US AC-2 landing station is in Bellport, New York,
 while another is in Tuckerton, NJ. From I gather both areas have heavy
 storm damage since they were on the north side of Sandy's land fall.
 They are reporting a storm surge at 13 feet above flood stage in NYC.
 Can you run a traceroute, would be interested in seeing the path its
 traversing. Just curious.
 regards,
 /virendra
  <CAGDKorK10KUA_LfQQVWmz3DrmEsHgRn0nS8E=WV0JuAH65j=qg@mail.gmail.com>
  <509012C2.9000004@outages.org>
 I know some people were offering help for people effected by the storm in
 NYC and just saw the below in my Twitter feed.
 ?===========?
 Need someone adept at Cisco servers to assist @HumanityRoad in NYC.
 https://mobile.twitter.com/GWOBorg/status/263338521559969792
 ?===========?
 On 30 Oct 2012 17:57, "virendra rode" <virendra.rode at outages.org> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/9156a54c/attachment.html>
 If your interested info from Internap IRT NYC datacenters
 NYM008
 111 8th avenue /76 9th avenue on generator power with approx 103 hours also
 fuel truck expected to replenish
 NYMTEXT1
 75 Broadstreet is completely down not ETR for obvious reasons
 Tks
 On Tue, Oct 30, 2012 at 7:06 AM, Alex Rubenstein <alex at corp.nac.net> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/bc8621bc/attachment.html>
 Who is reporting AC-2 down? Is that from the UK side? Can't find anything on it from Level 3
 http://blog.level3.com/level-3-network/official-level-3-statement-hurricane-sandy-preparation/
 Carl Brooks
 From: Martin Hepworth <maxsec at gmail.com<mailto:maxsec at gmail.com>>
 Date: Tue, 30 Oct 2012 11:59:10 -0500
 Cc: "outages at outages.org<mailto:outages at outages.org>" <outages at outages.org<mailto:outages at outages.org>>
 Also reports  AC2 transatlantic cable down and loss of connectivity to NY based servers.
 Along with reports on Ausnog about all the fun with the large DCs in Manhattan going to gennie power, diesel pumps being flooded and failing 'cos the tanks are in the basement...
 Will be a massive clearup not just for the IT folks, Subways and road tunnels flooded so getting about will be challenging for a while.
 --
 Martin Hepworth, CISSP
 Oxford, UK
 On 30 October 2012 14:06, Alex Rubenstein <alex at corp.nac.net<mailto:alex at corp.nac.net>> wrote:
 Hello,
 Nothing to report outage-wise. However, if there is anything NAC can do to help anyone affected by the hurricane, please feel free to email me.
 _______________________________________________
 Outages mailing list
 Outages at outages.org<mailto:Outages at outages.org>
 https://puck.nether.net/mailman/listinfo/outages
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/733995be/attachment.html>
###############################################################
END
###############################################################

###############################################################
If anyone needs anything...
###############################################################
 We were lucky in Philly. Power and connectivity has remained up.  If anyone
 needs servers turned up, rack space or anything else we can help with
 please don't hesitate to contact us.  We are just a hop skip and a jump.
 Matt Kelly
 Razor, Inc.
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121030/8105d1e2/attachment.html>
###############################################################
END
###############################################################

###############################################################
bandwidth.com
###############################################################
 Does anyone know the status of the bandwidth.com SIP trunk outage?
 Dan English 
 Plexicomm - Internet Solutions 
 dan at plexicomm.net | 1.866.759.4678 x103 
 Fax: 1.866.852.4688 | Emergency Support: 1.866.759.9713
 Are you configured properly to fail over to their LA site?
 I've been seeing some issues with one-way audio on origination with them 
 toay, but no hard outage for sure. The one-way audio issue was far worse 
 until we manually flipped to using the LA site as primary instead of the 
 NY site.
 On Tue, 30 Oct 2012, Plexicomm Admin wrote:
 We use VoIP Innovations and all of our DIDs with network code BW (bandwidth.com) ring "all circuits are busy". VoIP Innovations tells us it is a NYC outage and we have to wait it out. But based on the information you just provided it sounds like VoIP Innovations dropped the ball switching over to the LA proxy.
 Dan English 
 Plexicomm - Internet Solutions 
 dan at plexicomm.net | 1.866.759.4678 x103 
 Fax: 1.866.852.4688 | Emergency Support: 1.866.759.9713
 -----Original Message----- 
 FYI, I had a ticket opened for the occasional one-way audio on outbound 
 calls.. they finally replied and said that it's due to the hurricane. 
 Which seems odd, since we're entirely central.. if it was incoming I could 
 understand it.. but for outbound I'd expect it to be easily fixed. *sigh*. 
 Time to route outbound via Vitelity for awhile..
 On Tue, 30 Oct 2012, Plexicomm Admin wrote:
 >>> Does anyone know the status of the bandwidth.com SIP trunk outage?
 >>>
 >>> Dan English
 >>> Plexicomm - Internet Solutions
 >>> dan at plexicomm.net | 1.866.759.4678 x103
 >>> Fax: 1.866.852.4688 | Emergency Support: 1.866.759.9713
 >>>
 >>>
 >>>
 >>>
 >>>
 >>> _______________________________________________
 >>> Outages mailing list
 >>> Outages at outages.org
 >>> https://puck.nether.net/mailman/listinfo/outages
 >>>
###############################################################
END
###############################################################

###############################################################
Google Voice problems
###############################################################
 >From Twitter:
 Google Voice ?@googlevoice
 Due to Hurricane Sandy, some of our carriers are experiencing
 disruptions which are affecting both inbound and outbound calls.
 >From the web:
 https://productforums.google.com/forum/#!category-topic/voice/O1zHgpbimTc
 The east coast power outages are affecting some coverage including
 inbound calls.
 We appreciate your patience.
 It's hard to be more vague than that, but I can report that it's
 affecting my GV number.
 -- 
 Edward Vielmetti +1 734 330 2465
 edward.vielmetti at gmail.com
###############################################################
END
###############################################################

###############################################################
111 8th
###############################################################
 Woke up to BGPmon... anyone know how many tenants affected by the fuel pump
 issue at 111 8th?
 Or is just Equinix?
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121031/cf4dc151/attachment.html>
 On Oct 31, 2012, at 7:35 AM, Christopher J. Pilkington wrote:
 I saw a notice from Equinix saying they repaired their generator, etc.
 LOCATION:	 NY METRO AREA
 PRODUCTS:	 Equinix Internet Exchange, Metro Connect
 SR#:	 6445883
 Date and Time of Occurrence:	 31-OCT-2012 05:34 Site Local Time
 INCIDENT SUMMARY: Network Service Issue
 UPDATE:
 Network services have been restored. Backup generator repairs were completed and power has been restored to customer loads.
 This issue is now resolved and service returned to normal as of 31-OCT-2012 07:55 Site Local Time
  <410078ED-C834-436F-8D69-17AB7C6F6E31@puck.nether.net>
 Internap was dead for a few hours as well.
 On Wed, Oct 31, 2012 at 9:59 AM, Jared Mauch <jared at puck.nether.net> wrote:
 -- 
 Jeremy Stinson
 VP of Network Operations
 <http://www.meetme.com/>
 100 Union Square Drive
 New Hope, PA 18938
 215.862.1162 x238
 meetme.com
 <https://www.facebook.com/pages/MeetMe/21931227129>
 <https://twitter.com/meetme>
    <http://www.youtube.com/user/MeetMeVideos>
 The public market leader in social discovery. (NYSE MKT: MEET)
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121031/55bf47e3/attachment-0001.html>
###############################################################
END
###############################################################

###############################################################
Level 3 Statement Response on AC2
###############################################################
 AC-2 was not cut but Level 3 did see some bumps in the road.
 -------- Original Message --------
 Subject: Level 3 Statement Response on AC2
 From: "McLeary, Jon Paul" <JonPaul.McLeary at Level3.com>
 Hi Carl,
 We saw your inquiry regarding AC2 on twitter and wanted to clarify the rumor you heard. I?m providing you a company statement below, which will hopefully help provide a little more context.
 Level 3 Statement Regarding AC2
 We made extensive preparations in advance of the storm and have experienced no major service disruptions. All of our subsea cable systems are operating normally. We have experienced a minor fiber cut to one of our diversely routed, secondary backhaul lines which provides connectivity to our AC2 Cable Landing Station, and our technicians are currently working to repair it as quickly as possible. Few customers were affected because most traffic was rerouted through redundant lines. And again, the AC2 subsea cable itself is operating normally.
 Aside from that, I hope that you're having a great evening and that all else is going well.
 Best,
 Jon Paul
 Jon Paul McLeary
 Media Relations
 Level 3 Communications
 Office: 720-888-3244
 Mobile: 619-851-9694
 jonpaul.mcleary at level3.com
###############################################################
END
###############################################################

###############################################################
TDS Internet Maine, NH & VT
###############################################################
 Have not been able to get much information on this, except a tweet confirming the outage.
 Started about 2:47 Eastern on the 30th.
 Traceroute in to one of my static ip dies in NYC. Suspect this is storm/power related?
 1
 <1 ms
 <1 ms
 <1 ms
 10gigabitethernet6-2.core1.nyc4.he.net (72.52.92.49)
 2
 *
 <1 ms
 <1 ms
 NYCMNY83brd01.network.tds.net (198.32.118.31)
 3
 *
 *
 *
 ?
 4
 *
 *
 *
 ?
 5
 *
 *
 *
 ?
 6
 *
 *
 *
 ?
 If anyone can shed some light on this, it would be appreciated.
 -Keith
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121031/2f01e727/attachment.html>
 We lost a Sidera 10G NYC-BOS wave through Western Massachusetts about the
 same time and it sounds like it is parallel to your TDS circuit. It's been
 down overnight.
 Sidera NOC guys are flat out on the phones this morning, no specific
 details available, but it looked like one of their DWDM regen nodes on the
 route lost its generator and utility power. Could even be more than one
 site on the route, not sure. Lots of carnage closer to NYC.
 On Wed, Oct 31, 2012 at 10:03 AM, Wallace Keith
 <kwallace at pcconnection.com>wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121031/17c64916/attachment.html>
 Latest tweet-
 @tdstelecom<https://twitter.com/tdstelecom> has a double failure on two diverse routes into NY city impacting NH data customers.No new ETA. #SandyNH<https://twitter.com/search?q=%23SandyNH&src=hash>
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Wallace Keith
 Sent: Wednesday, October 31, 2012 10:04 AM
 Have not been able to get much information on this, except a tweet confirming the outage.
 Started about 2:47 Eastern on the 30th.
 Traceroute in to one of my static ip dies in NYC. Suspect this is storm/power related?
 1
 <1 ms
 <1 ms
 <1 ms
 10gigabitethernet6-2.core1.nyc4.he.net (72.52.92.49)
 2
 *
 <1 ms
 <1 ms
 NYCMNY83brd01.network.tds.net (198.32.118.31)
 3
 *
 *
 *
 ?
 4
 *
 *
 *
 ?
 5
 *
 *
 *
 ?
 6
 *
 *
 *
 ?
 If anyone can shed some light on this, it would be appreciated.
 -Keith
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121031/113ea9ad/attachment.html>
 Hi Wallace,
 Due to Hurricane Sandy TDS customers in NH are experiencing Internet outage.
 TDS has a double failure on two diverse routes of our 10G network.   One connection point in New York City is in a building that has no power and is flooded and a second connection point is on alternate route that has a fiber cut on a line just outside of New York City. 
 TDS has escalated this issue with our interconnect carriers and Point of Presence (POP) vendors, they are aware of our issue and working to fix them, but as we all know these are extraordinary circumstances for New York City residents and contractors alike who we need to assist us.  
 If either of these routes is repaired service will be restored in what we refer to as Simplex mode (one of two optional routes.)   TDS was in Simplex mode following the storm and the second route dropped yesterday afternoon to cause the full outage.  
 TDS Long Distance is affected in some areas as well. Landline customers in NH do have dial tone and can make local calls.  Customers on IP phone services do not have phone service as it requires the IP/data connection and should use alternate phone lines.  When service is restored we recommend customers reboot their ManagedIP phones.
 TDS does not have an ETA at this time.   We will provide another update at 3:00 CST today.  In these unprecedented times we all need to be patient and await the necessary repairs.   Please bear with us. 
 TDS Internet customers do not need to call in to report their outages.  
 Best Regards,
 TDS Telecom IP Network Operations
  <B92E4A692F0F6B419EE79045D420F72A2F90A81B00@MKA176.pcc.int>
 Service  has been restored. Thanks TDS!
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org] On Behalf Of Wallace Keith
 Sent: Wednesday, October 31, 2012 11:30 AM
 Latest tweet-
 @tdstelecom<https://twitter.com/tdstelecom> has a double failure on two diverse routes into NY city impacting NH data customers.No new ETA. #SandyNH<https://twitter.com/search?q=%23SandyNH&src=hash>
 From: outages-bounces at outages.org<mailto:outages-bounces at outages.org> [mailto:outages-bounces at outages.org]<mailto:[mailto:outages-bounces at outages.org]> On Behalf Of Wallace Keith
 Sent: Wednesday, October 31, 2012 10:04 AM
 Have not been able to get much information on this, except a tweet confirming the outage.
 Started about 2:47 Eastern on the 30th.
 Traceroute in to one of my static ip dies in NYC. Suspect this is storm/power related?
 1
 <1 ms
 <1 ms
 <1 ms
 10gigabitethernet6-2.core1.nyc4.he.net (72.52.92.49)
 2
 *
 <1 ms
 <1 ms
 NYCMNY83brd01.network.tds.net (198.32.118.31)
 3
 *
 *
 *
 ?
 4
 *
 *
 *
 ?
 5
 *
 *
 *
 ?
 6
 *
 *
 *
 ?
 If anyone can shed some light on this, it would be appreciated.
 -Keith
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121031/0fa4066c/attachment.html>
  <9FD362844B11AF4BBFE6DBFE0B5619511BC0AB20@cmailbox3>
 TDS Internet Update #4 for Super Storm Sandy - Oct. 31 1:12 p.m. CST
 10G connection from Contoocook NH to NY City has been restored! We are in Simplex mode on one of our two routes as described in earlier post. Thank you for your understanding during this outage. We do still have other markets with some isolated outages, but things are looking good now with this major connection restored.
 http://www.tdstelecom.com/MediaRoom/Article.aspx?id=2a82b2ab-3536-43bf-bde9-eb4e5c72d321
 Regards,
 TDS IP Network Operations
###############################################################
END
###############################################################

###############################################################
Windstream fiber cut(s) between Wilmington and Philly?
###############################################################
 We had some fiber go down yesterday at 3:33PMEDT. Last I heard from Windstream
 (was City Signal, Cavalier, Paetec, now Windstream) was a cut in "Delaware" and
 a tech en route to shoot with a 6:15PM ETA. This was at 5:30PM and I haven't
 heard anything since. Support seems to be in infinite hold mode.
 I know there's a lot going on but has anyone here been in touch with Windstream
 regarding cuts in the area?
 -Mike
 We're in west central Florida using Windstream (Paetec) voice, and are 
 unable to make long distance calls at this time from multiple PRIs.
 Support ticket system is barely functioning-- taking 2+ minutes per page 
 load, with sporadic timeouts.  I get the feeling we're not alone.
 ----- Original Message ----- 
 From: "Michael Morgan" <mmorgan at dca.net>
 Sent: Wednesday, October 31, 2012 12:02 PM
 We've seen many PAETEC/Windstream voice PRI down in Manhattan. 
 Nicholas J. D?Attilo
 Manager ? Network Operations Center
 Rockefeller Group Technology Solutions, Inc.
 1221 Avenue of the Americas Concourse
 New York, NY 10020
 Phone:1.212.282.2304
 http://www.linkedin.com/in/nickdattilo
 On Oct 31, 2012, at 12:10, "Michael Morgan" <mmorgan at dca.net> wrote:
 We had some fiber go down yesterday at 3:33PMEDT. Last I heard from Windstream
 (was City Signal, Cavalier, Paetec, now Windstream) was a cut in "Delaware" and
 a tech en route to shoot with a 6:15PM ETA. This was at 5:30PM and I haven't
 heard anything since. Support seems to be in infinite hold mode.
 I know there's a lot going on but has anyone here been in touch with Windstream
 regarding cuts in the area?
 -Mike
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 We had Tollfree's down out here in SF Bay Area. First reported about
 6:15p PST, we are up as of 9a PST. When calling support at 9p last night
 it took 50 mins to get thru- 
 Our PRIs stayed up though
 Ken Goldenberg
 Direct Line TeleResponse
 President
 ATSI Award of Excellence DIAMOND PLUS Award 2002-2012 
 CAMX Award of Excellence 2006-2011
 ATSI 24/7 GOLD SITE CERTIFIED
 510-843-3900 
 -----Original Message-----
 From: outages-bounces at outages.org [mailto:outages-bounces at outages.org]
 On Behalf Of Michael Morgan
 Sent: Wednesday, October 31, 2012 9:02 AM
 Subject: [outages] Windstream fiber cut(s) between Wilmington and Philly?
 We had some fiber go down yesterday at 3:33PMEDT. Last I heard from
 Windstream (was City Signal, Cavalier, Paetec, now Windstream) was a cut
 in "Delaware" and a tech en route to shoot with a 6:15PM ETA. This was
 at 5:30PM and I haven't heard anything since. Support seems to be in
 infinite hold mode.
 I know there's a lot going on but has anyone here been in touch with
 Windstream regarding cuts in the area?
 -Mike
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
###############################################################
END
###############################################################

###############################################################
SIP services down?
###############################################################
 Hey guys,
 Curious if anyone is seeing SIP service outages beyond the bandwidth issues from yesterday. I know call centric is having issues still, but is anyone experiencing any other disconnects?
 Cheers,
 Joshua 
 Sent from my iPad
 Call centric is fubared more or less. I will be surprised if they have any
 customers left after this (no redundancy) and the recent DDOS.
 On Wed, Oct 31, 2012 at 1:34 PM, Joshua Goldbard <j at 2600hz.com> wrote:
 -------------- next part --------------
 An HTML attachment was scrubbed...
 URL: <https://puck.nether.net/pipermail/outages/attachments/20121031/5e4dace7/attachment.html>
 All issues we were seeing with one-way audio on outbound calls have 
 cleared up. No new reports today.
 I cannot say if people who have numbers from Bandwidth in the affected 
 geographic areas have working numbers again yet..
 On Wed, 31 Oct 2012, Joshua Goldbard wrote:
  <alpine.DEB.2.02.1210311258470.11636@admin.chi.technicality.org>
 We are seeing sporadic issues with bandwidth.com SIP today.
 Dan English 
 Plexicomm - Internet Solutions 
 dan at plexicomm.net | 1.866.759.4678 x103 
 Fax: 1.866.852.4688 | Emergency Support: 1.866.759.9713
 -----Original Message----- 
  <CAPC+kK56yDQaSGjf=j4wQhUrjw==heaipN0s6QRMSSR2okE69g@mail.gmail.com>
 TATA was down for a bit in NYC (NJ GSX was up), Reliance is down,
 Telia is down, Telstra just came back up, BICS was down for a bit.
 Hypercube was down for a little bit out of the NY pop but their
 Atlanta and LA switches worked fine for us.
 On Wed, Oct 31, 2012 at 1:47 PM, Mitch <mitpatterson at gmail.com> wrote:
 We're seeing intermittent 20 second post-dial delay and occasional dropped calls outbound through Dash/Inetwork/Bandwidth, starting 30 minutes ago. We just moved outbound away from them.
 Regards,
 ------------
 Owen Roth
 Snr Network Engineer
 Impulse Advanced Communications
 owen at impulse.net
 805-884-6332
 ----- Original Message -----
 From: "Plexicomm Admin" <admin at plexicomm.net>
 Sent: Wednesday, October 31, 2012 11:08:42 AM
 We are seeing sporadic issues with bandwidth.com SIP today.
 Dan English 
 Plexicomm - Internet Solutions 
 dan at plexicomm.net | 1.866.759.4678 x103 
 Fax: 1.866.852.4688 | Emergency Support: 1.866.759.9713
 -----Original Message----- 
 _______________________________________________
 Outages mailing list
 Outages at outages.org
 https://puck.nether.net/mailman/listinfo/outages
 On 10/31/2012 01:24 PM, Owen Roth wrote:
 We use them out of Denver and Atlanta and are not seeing any problems or 
 call delays.
 Chris
 --
 AxisInternet, Inc.
 www.axint.net
 We are seeing tremendous post-dial delay issues. We emailed them as such.
 It's been kind of up and down since the storm actually. Calls, when they
 complete, seem to stay up, but then again customers may just not be
 complaining as loudly because they are aware of the circumstances...
 --
 Darren Schreiber
 CEO / Co-Founder
 2600hz
 On 10/31/12 12:59 PM, "Chris Stone" <cstone at axint.net> wrote:
 >On 10/31/2012 01:24 PM, Owen Roth wrote:
 >>dropped calls outbound through Dash/Inetwork/Bandwidth, starting 30
 >>minutes ago. We just moved outbound away from them.
 >We use them out of Denver and Atlanta and are not seeing any problems or
 >call delays.
 >Chris
 >--
 >AxisInternet, Inc.
 >www.axint.net
 >_______________________________________________
 >Outages mailing list
 >Outages at outages.org
 >https://puck.nether.net/mailman/listinfo/outages
###############################################################
END
###############################################################

###############################################################
[admin] Sandy Volunteers
###############################################################
 -----BEGIN PGP SIGNED MESSAGE-----
 Hash: SHA256
 Hello All,
 I have updated tracker w/ names of the volunteers who are willing to
 help. In my eyes they are unsung heroes who are willing to share their
 time, talents, and energy to help specially as times as such.
 If interested, please e-mail me your contact information & the nature
 of help you're willing to render and I'll be happy to post your
 information to tracker roster.
 For more information, please visit:
 http://tracker.outages.org/reports/index/?c=12&sw=-77.036366,38.895112&ne=-74.005973,40.714353
 As part of my gratitude and appreciation, I will be giving out
 (outages.org) t-shirts to those who are willing to post their name(s)
 to tracker roster.
 If I can be of any assistance (w/ clean up, racking/un-racking,
 pulling cables, routing, switching, wifi, monitoring, etc) I'll be
 happy to help provided mother nature lets me through since I'm located
 in southern california. Just let me know.
 The best I can do is tell you how much I appreciate your continued
 support not only with outages.org but during times of crisis such as
 this. We hope we can continue to demonstrate to others that we value
 everyone's help/support and that we use it wisely to provide the help
 that people in crisis need.
 With sincere appreciation,
 regards,
 /virendra
###############################################################
END
###############################################################

